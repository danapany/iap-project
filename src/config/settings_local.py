import os
from dotenv import load_dotenv

class AppConfigLocal:
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì • í´ë˜ìŠ¤"""
    
    def __init__(self):
        load_dotenv()
        
        # Azure OpenAI ì„¤ì •
        self.azure_openai_endpoint = os.getenv("OPENAI_ENDPOINT")
        self.azure_openai_key = os.getenv("OPENAI_KEY")
        self.azure_openai_model = os.getenv("CHAT_MODEL", "iap-gpt-4o-mini")
        self.azure_openai_api_version = os.getenv("OPENAI_API_VERSION", "2024-02-01")
        
        # Azure Search ì„¤ì •
        self.search_endpoint = os.getenv("SEARCH_ENDPOINT")
        self.search_key = os.getenv("SEARCH_API_KEY")
        self.search_index = os.getenv("INDEX_REBUILD_NAME")
        
        # LangSmith ì„¤ì •
        self.langchain_api_key = os.getenv("LANGCHAIN_API_KEY")
        self.langsmith_tracing = os.getenv("LANGSMITH_TRACING", "false").lower() == "true"
        self.langchain_project = os.getenv("LANGCHAIN_PROJECT", "trouble-chaser-chatbot")
        
        # ê¸°ë³¸ ê²€ìƒ‰ í’ˆì§ˆ ì„ê³„ê°’ ì„¤ì •
        self.search_score_threshold = 0.20
        self.reranker_score_threshold = 1.8
        self.hybrid_score_threshold = 0.35
        self.semantic_score_threshold = 0.25
        self.max_initial_results = 50
        self.max_final_results = 15
    
    def validate_config(self):
        """í•„ìˆ˜ ì„¤ì •ê°’ ê²€ì¦"""
        required_vars = [
            self.azure_openai_endpoint,
            self.azure_openai_key,
            self.search_endpoint,
            self.search_key,
            self.search_index
        ]
        return all(required_vars)
    
    def get_env_status(self):
        """í™˜ê²½ë³€ìˆ˜ ìƒíƒœ ë°˜í™˜"""
        return {
            "OPENAI_ENDPOINT": "âœ…" if self.azure_openai_endpoint else "âŒ",
            "OPENAI_KEY": "âœ…" if self.azure_openai_key else "âŒ",
            "SEARCH_ENDPOINT": "âœ…" if self.search_endpoint else "âŒ",
            "SEARCH_API_KEY": "âœ…" if self.search_key else "âŒ",
            "INDEX_REBUILD_NAME": "âœ…" if self.search_index else "âŒ",
            "LANGCHAIN_API_KEY": "âœ…" if self.langchain_api_key else "âŒ",
            "LANGSMITH_TRACING": "âœ…" if self.langsmith_tracing else "âŒ",
            "LANGCHAIN_PROJECT": "âœ…" if self.langchain_project else "âŒ"
        }
    
    def setup_langsmith(self):
        """LangSmith í™˜ê²½ ì„¤ì •"""
        if self.langchain_api_key and self.langsmith_tracing:
            os.environ["LANGCHAIN_API_KEY"] = self.langchain_api_key
            os.environ["LANGCHAIN_TRACING_V2"] = "true"
            os.environ["LANGCHAIN_PROJECT"] = self.langchain_project
            return True
        return False
    
    def get_langsmith_status(self):
        """LangSmith ì„¤ì • ìƒíƒœ ë°˜í™˜"""
        return {
            "enabled": self.langsmith_tracing and bool(self.langchain_api_key),
            "api_key_set": bool(self.langchain_api_key),
            "tracing_enabled": self.langsmith_tracing,
            "project_name": self.langchain_project
        }
    
    def get_dynamic_thresholds(self, query_type, query_text):
        """ì¿¼ë¦¬ íƒ€ì…ê³¼ ë‚´ìš©ì— ë”°ë¼ ë™ì ìœ¼ë¡œ ì„ê³„ê°’ ì¡°ì •"""
        
        # íŠ¹ìˆ˜ í‚¤ì›Œë“œ ê°ì§€
        year_keywords = ['ë…„ë„', 'ë…„', 'ì›”ë³„', 'ê¸°ê°„', 'í˜„í™©', 'í†µê³„', 'ê±´ìˆ˜', 'ë°œìƒ', 'ë°œìƒì¼ì', 'ì–¸ì œ']
        is_statistical_query = any(keyword in query_text for keyword in year_keywords)
        
        # ë³µì¡í•œ ì¥ì•  í‚¤ì›Œë“œ ê°ì§€
        complex_keywords = ['ë³´í—˜', 'ê°€ì…', 'ë¶ˆê°€', 'ì ‘ì†', 'ë‹¨ë§', 'íœ´ëŒ€í°', 'ì‹¤íŒ¨', 'ì•ˆë¨', 'ì˜¤ë¥˜', 'ì‚¬ìš©ì', 'ë¡œê·¸ì¸', 'ê²°ì œ']
        is_complex_query = any(keyword in query_text for keyword in complex_keywords)
        
        # ê¸°ë³¸ ì„ê³„ê°’ ì„¤ì •
        base_thresholds = {
            'search_threshold': self.search_score_threshold,
            'reranker_threshold': self.reranker_score_threshold,
            'hybrid_threshold': self.hybrid_score_threshold,
            'semantic_threshold': self.semantic_score_threshold,
            'max_results': self.max_final_results
        }
        
        # ì¿¼ë¦¬ íƒ€ì…ë³„ ìµœì í™”ëœ ì„ê³„ê°’ ì ìš©
        if query_type == "repair":
            # ë³µêµ¬ë°©ë²• ì¿¼ë¦¬ - ì •í™•ì„± ìµœìš°ì„ 
            if is_complex_query:
                return {
                    'search_threshold': 0.30,
                    'reranker_threshold': 2.5,
                    'hybrid_threshold': 0.50,
                    'semantic_threshold': 0.35,
                    'max_results': 8,
                    'processing_mode': 'accuracy_first',
                    'description': 'ë³µêµ¬ë°©ë²• ì •í™•ì„± ìµœìš°ì„  - LLM ê´€ë ¨ì„± ê²€ì¦'
                }
            else:
                return {
                    'search_threshold': 0.25,
                    'reranker_threshold': 2.2,
                    'hybrid_threshold': 0.45,
                    'semantic_threshold': 0.30,
                    'max_results': 10,
                    'processing_mode': 'accuracy_first',
                    'description': 'ë³µêµ¬ë°©ë²• ì •í™•ì„± ìš°ì„  - LLM ê´€ë ¨ì„± ê²€ì¦'
                }
                
        elif query_type == "cause":
            # ì¥ì• ì›ì¸ ì¿¼ë¦¬ - ì •í™•ì„±ê³¼ ë¶„ì„ í’ˆì§ˆ ì¤‘ì‹œ
            return {
                'search_threshold': 0.28,
                'reranker_threshold': 2.3,
                'hybrid_threshold': 0.48,
                'semantic_threshold': 0.32,
                'max_results': 8,
                'processing_mode': 'accuracy_first',
                'description': 'ì¥ì• ì›ì¸ ì •í™•ì„± ìš°ì„  - í‚¤ì›Œë“œ ë§¤ì¹­ ê°•í™”'
            }
            
        elif query_type == "similar":
            # ìœ ì‚¬ì‚¬ë¡€ ì¿¼ë¦¬ - í¬ê´„ì„±ê³¼ ì˜ë¯¸ì  ìœ ì‚¬ì„± ì¤‘ì‹œ
            return {
                'search_threshold': 0.15,
                'reranker_threshold': 1.5,
                'hybrid_threshold': 0.30,
                'semantic_threshold': 0.20,
                'max_results': 15,
                'processing_mode': 'coverage_first',
                'description': 'ìœ ì‚¬ì‚¬ë¡€ í¬ê´„ì„± ìš°ì„  - ì˜ë¯¸ì  ìœ ì‚¬ì„± ê¸°ë°˜'
            }
        
        elif query_type == "statistics":
            # ğŸ†• í†µê³„ ì¿¼ë¦¬ - ì™„ì „ì„±ê³¼ ì •í™•ì„± ìµœìš°ì„ 
            return {
                'search_threshold': 0.10,  # ë§¤ìš° ë‚®ì€ ì„ê³„ê°’ìœ¼ë¡œ ëª¨ë“  ê´€ë ¨ ë°ì´í„° ìˆ˜ì§‘
                'reranker_threshold': 1.0,  # ë‚®ì€ ì¬ì •ë ¬ ì„ê³„ê°’
                'hybrid_threshold': 0.20,   # ë‚®ì€ í•˜ì´ë¸Œë¦¬ë“œ ì„ê³„ê°’
                'semantic_threshold': 0.15,  # ë‚®ì€ ì‹œë§¨í‹± ì„ê³„ê°’
                'max_results': 50,  # í†µê³„ ì§‘ê³„ë¥¼ ìœ„í•´ ë§ì€ ê²°ê³¼ í•„ìš”
                'processing_mode': 'statistics_complete',
                'description': 'í†µê³„ ì™„ì „ì„± ìš°ì„  - ëª¨ë“  ê´€ë ¨ ë°ì´í„° ìˆ˜ì§‘ ë° ì •í™•í•œ ì§‘ê³„'
            }
            
        elif query_type == "default" or is_statistical_query:
            # ì¼ë°˜/í†µê³„ ì¿¼ë¦¬ - í¬ê´„ì„±ê³¼ ì™„ì „ì„± ì¤‘ì‹œ
            return {
                'search_threshold': 0.12,
                'reranker_threshold': 1.3,
                'hybrid_threshold': 0.25,
                'semantic_threshold': 0.18,
                'max_results': 20,
                'processing_mode': 'coverage_first',
                'description': 'ì¼ë°˜/í†µê³„ í¬ê´„ì„± ìš°ì„  - ê´‘ë²”ìœ„í•œ ê²€ìƒ‰'
            }
        else:
            # ê¸°ë³¸ ê· í˜• ì„¤ì •
            base_thresholds.update({
                'processing_mode': 'balanced',
                'description': 'ê· í˜•ì¡íŒ ì²˜ë¦¬'
            })
            return base_thresholds
    
    def get_query_optimization_config(self, query_type):
        """ì¿¼ë¦¬ íƒ€ì…ë³„ ìµœì í™” ì„¤ì • ë°˜í™˜"""
        optimizations = {
            "repair": {
                "use_llm_validation": True,
                "keyword_relevance_weight": 0.3,
                "semantic_boost_factor": 0.4,
                "quality_over_quantity": True,
                "strict_service_matching": True
            },
            "cause": {
                "use_llm_validation": True,
                "keyword_relevance_weight": 0.4,
                "semantic_boost_factor": 0.3,
                "quality_over_quantity": True,
                "strict_service_matching": True
            },
            "similar": {
                "use_llm_validation": False,
                "keyword_relevance_weight": 0.1,
                "semantic_boost_factor": 0.6,
                "quality_over_quantity": False,
                "strict_service_matching": False
            },
            "statistics": {  # ğŸ†• í†µê³„ ì „ìš© ìµœì í™” ì„¤ì •
                "use_llm_validation": False,
                "keyword_relevance_weight": 0.05,  # í‚¤ì›Œë“œ ê´€ë ¨ì„± ë‚®ê²Œ (ëª¨ë“  ë°ì´í„° í¬í•¨)
                "semantic_boost_factor": 0.2,       # ì‹œë§¨í‹± ë¶€ìŠ¤íŒ… ë‚®ê²Œ
                "quality_over_quantity": False,     # ì–‘ ìš°ì„  (ì™„ì „í•œ í†µê³„ë¥¼ ìœ„í•´)
                "strict_service_matching": False,   # ìœ ì—°í•œ ë§¤ì¹­
                "ensure_completeness": True,        # ì™„ì „ì„± ë³´ì¥
                "aggregate_all_matches": True       # ëª¨ë“  ë§¤ì¹­ í•­ëª© ì§‘ê³„
            },
            "default": {
                "use_llm_validation": False,
                "keyword_relevance_weight": 0.1,
                "semantic_boost_factor": 0.5,
                "quality_over_quantity": False,
                "strict_service_matching": False
            }
        }
        
        return optimizations.get(query_type, optimizations["default"])
    
    def get_processing_mode_info(self):
        """ì²˜ë¦¬ ëª¨ë“œë³„ ìƒì„¸ ì •ë³´ ë°˜í™˜"""
        return {
            'accuracy_first': {
                'name': 'ì •í™•ì„± ìš°ì„ ',
                'description': 'LLM ê´€ë ¨ì„± ê²€ì¦ì„ í†µí•œ ìµœê³  ì •í™•ë„',
                'best_for': ['repair', 'cause'],
                'features': ['LLM ë¬¸ì„œ ê²€ì¦', 'í‚¤ì›Œë“œ ê´€ë ¨ì„± ì ìˆ˜', 'ì—„ê²©í•œ í•„í„°ë§']
            },
            'coverage_first': {
                'name': 'í¬ê´„ì„± ìš°ì„ ', 
                'description': 'ì˜ë¯¸ì  ìœ ì‚¬ì„± ê¸°ë°˜ ê´‘ë²”ìœ„í•œ ê²€ìƒ‰',
                'best_for': ['similar', 'default'],
                'features': ['ì˜ë¯¸ì  ìœ ì‚¬ì„± ë¶€ìŠ¤íŒ…', 'ê´€ëŒ€í•œ í•„í„°ë§', 'í¬ê´„ì  ê²°ê³¼']
            },
            'statistics_complete': {  # ğŸ†• í†µê³„ ì „ìš© ì²˜ë¦¬ ëª¨ë“œ
                'name': 'í†µê³„ ì™„ì „ì„±',
                'description': 'ì •í™•í•œ í†µê³„ ì§‘ê³„ë¥¼ ìœ„í•œ ì™„ì „í•œ ë°ì´í„° ìˆ˜ì§‘',
                'best_for': ['statistics'],
                'features': ['ëª¨ë“  ê´€ë ¨ ë°ì´í„° ìˆ˜ì§‘', 'ì •í™•í•œ ì§‘ê³„', 'ì¼ê´€ì„± ê²€ì¦', 'ì¤‘ë³µ ì œê±°']
            },
            'balanced': {
                'name': 'ê· í˜• ì²˜ë¦¬',
                'description': 'ì •í™•ì„±ê³¼ í¬ê´„ì„±ì˜ ìµœì  ê· í˜•',
                'best_for': ['ëª¨ë“  ì¿¼ë¦¬ íƒ€ì…'],
                'features': ['ì ì‘í˜• í•„í„°ë§', 'ê· í˜•ì¡íŒ ì„ê³„ê°’', 'ì•ˆì •ì  ê²°ê³¼']
            }
        }
    
    def get_performance_metrics(self):
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê¸°ì¤€ê°’ ë°˜í™˜"""
        return {
            'accuracy_targets': {
                'repair': 0.85,
                'cause': 0.80,
                'similar': 0.70,
                'statistics': 0.95,  # ğŸ†• í†µê³„ëŠ” ë§¤ìš° ë†’ì€ ì •í™•ë„ ìš”êµ¬
                'default': 0.75
            },
            'response_time_targets': {
                'accuracy_first': 8.0,
                'coverage_first': 5.0,
                'statistics_complete': 10.0,  # ğŸ†• í†µê³„ëŠ” ë” ê¸´ ì²˜ë¦¬ ì‹œê°„ í—ˆìš©
                'balanced': 6.0
            },
            'result_count_targets': {
                'repair': {'min': 3, 'max': 10, 'optimal': 6},
                'cause': {'min': 3, 'max': 10, 'optimal': 6},
                'similar': {'min': 5, 'max': 20, 'optimal': 12},
                'statistics': {'min': 10, 'max': 100, 'optimal': 50},  # ğŸ†• í†µê³„ëŠ” ë§ì€ ë°ì´í„° í•„ìš”
                'default': {'min': 5, 'max': 25, 'optimal': 15}
            }
        }
    
    def validate_query_processing(self, query_type, processing_mode, result_count):
        """ì¿¼ë¦¬ ì²˜ë¦¬ ê²°ê³¼ ê²€ì¦"""
        performance_metrics = self.get_performance_metrics()
        targets = performance_metrics['result_count_targets'].get(query_type, {'min': 1, 'max': 50, 'optimal': 10})
        
        validation_result = {
            'is_valid': True,
            'warnings': [],
            'recommendations': []
        }
        
        if result_count < targets['min']:
            validation_result['warnings'].append(f"ê²°ê³¼ ìˆ˜ê°€ ìµœì†Œ ê¸°ì¤€({targets['min']}ê°œ)ë³´ë‹¤ ì ìŠµë‹ˆë‹¤.")
            validation_result['recommendations'].append("ê²€ìƒ‰ ì„ê³„ê°’ì„ ë‚®ì¶°ë³´ì„¸ìš”.")
        
        if result_count > targets['max']:
            validation_result['warnings'].append(f"ê²°ê³¼ ìˆ˜ê°€ ìµœëŒ€ ê¸°ì¤€({targets['max']}ê°œ)ì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.")
            validation_result['recommendations'].append("ê²€ìƒ‰ ì„ê³„ê°’ì„ ë†’ì—¬ë³´ì„¸ìš”.")
        
        # ì¿¼ë¦¬ íƒ€ì…ê³¼ ì²˜ë¦¬ ëª¨ë“œ ë§¤ì¹­ ê²€ì¦
        optimization_config = self.get_query_optimization_config(query_type)
        if query_type in ['repair', 'cause'] and processing_mode != 'accuracy_first':
            validation_result['recommendations'].append(f"{query_type} ì¿¼ë¦¬ëŠ” ì •í™•ì„± ìš°ì„  ëª¨ë“œë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.")
        elif query_type in ['similar', 'default'] and processing_mode != 'coverage_first':
            validation_result['recommendations'].append(f"{query_type} ì¿¼ë¦¬ëŠ” í¬ê´„ì„± ìš°ì„  ëª¨ë“œë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.")
        elif query_type == 'statistics' and processing_mode != 'statistics_complete':  # ğŸ†• í†µê³„ ê²€ì¦
            validation_result['recommendations'].append("statistics ì¿¼ë¦¬ëŠ” í†µê³„ ì™„ì „ì„± ëª¨ë“œë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.")
        
        return validation_result