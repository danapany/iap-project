import streamlit as st
from openai import AzureOpenAI
from azure.search.documents import SearchClient
from azure.core.credentials import AzureKeyCredential
import os
import json
import traceback
import datetime
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="íŠ¸ëŸ¬ë¸” ì²´ì´ì„œ ì±—ë´‡",
    page_icon="ğŸ¤–",
    layout="wide"
)

# í™˜ê²½ë³€ìˆ˜ì—ì„œ Azure ì„¤ì • ë¡œë“œ
azure_openai_endpoint = os.getenv("OPENAI_ENDPOINT")
azure_openai_key = os.getenv("OPENAI_KEY")
azure_openai_model = os.getenv("CHAT_MODEL", "iap-gpt-4o-mini")
azure_openai_api_version = os.getenv("OPENAI_API_VERSION", "2024-02-01")

search_endpoint = os.getenv("SEARCH_ENDPOINT")
search_key = os.getenv("SEARCH_API_KEY")
# ì¥ì•  ë° ì´ìƒì§•í›„ ì¸ë±ìŠ¤ ì„¤ì •
incident_index = os.getenv("INDEX_SINGLE_NAME")  # ì¥ì•  ì¸ë±ìŠ¤
sign_index = os.getenv("INDEX_SIGN_NAME")        # ì´ìƒì§•í›„ ì¸ë±ìŠ¤

# Reranker ê¸°ë°˜ ê²€ìƒ‰ í’ˆì§ˆ í–¥ìƒì„ ìœ„í•œ ì„¤ì • - ìˆ˜ì •ëœ ì„ê³„ê°’
SEARCH_SCORE_THRESHOLD = 0.3      # 0.5 â†’ 0.3 (ë” ê´€ëŒ€í•˜ê²Œ)
RERANKER_SCORE_THRESHOLD = 1.5    # 2.0 â†’ 1.5 (ë” ê´€ëŒ€í•˜ê²Œ)  
HYBRID_SCORE_THRESHOLD = 0.5      # 0.7 â†’ 0.5 (ë” ê´€ëŒ€í•˜ê²Œ)
MAX_INITIAL_RESULTS = 20          # ì´ˆê¸° ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ (Reranker ì…ë ¥ìš©)
MAX_FINAL_RESULTS = 8             # 5 â†’ 8 (ìµœì¢… ì„ ë³„ ë¬¸ì„œ ìˆ˜ ì¦ê°€)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (í† ê¸€ ê¸°ë³¸ê°’ ì„¤ì • ë° ì˜¤ë¥˜ ë¡œê·¸ ì¶”ê°€)
if 'search_type' not in st.session_state:
    st.session_state.search_type = "ì¥ì• "  # ê¸°ë³¸ê°’: ì¥ì• 

if 'error_logs' not in st.session_state:
    st.session_state.error_logs = []

if 'show_error_logs' not in st.session_state:
    st.session_state.show_error_logs = False

# ì˜¤ë¥˜ ë¡œê¹… í•¨ìˆ˜
def log_error(error_type, error_message, function_name="", additional_info=""):
    """ì˜¤ë¥˜ë¥¼ ì„¸ì…˜ ìƒíƒœì— ë¡œê·¸ë¡œ ì €ì¥"""
    timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    error_log = {
        "timestamp": timestamp,
        "error_type": error_type,
        "error_message": str(error_message),
        "function_name": function_name,
        "additional_info": additional_info,
        "traceback": traceback.format_exc()
    }
    st.session_state.error_logs.append(error_log)
    
    # ìµœê·¼ 50ê°œ ë¡œê·¸ë§Œ ìœ ì§€
    if len(st.session_state.error_logs) > 50:
        st.session_state.error_logs = st.session_state.error_logs[-50:]

# ì˜¤ë¥˜ ë¡œê·¸ í‘œì‹œ í•¨ìˆ˜
def display_error_logs():
    """ì˜¤ë¥˜ ë¡œê·¸ë¥¼ í‘œì‹œ"""
    if not st.session_state.error_logs:
        st.info("ğŸ“‹ ì €ì¥ëœ ì˜¤ë¥˜ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    st.error(f"ğŸš¨ ì´ {len(st.session_state.error_logs)}ê°œì˜ ì˜¤ë¥˜ ë¡œê·¸ê°€ ìˆìŠµë‹ˆë‹¤.")
    
    for i, log in enumerate(reversed(st.session_state.error_logs)):
        with st.expander(f"âŒ ì˜¤ë¥˜ #{len(st.session_state.error_logs)-i}: {log['error_type']} ({log['timestamp']})", expanded=False):
            col1, col2 = st.columns(2)
            with col1:
                st.write(f"**ì‹œê°„**: {log['timestamp']}")
                st.write(f"**í•¨ìˆ˜**: {log['function_name']}")
                st.write(f"**íƒ€ì…**: {log['error_type']}")
            with col2:
                st.write(f"**ì¶”ê°€ì •ë³´**: {log['additional_info']}")
                
            st.write(f"**ì˜¤ë¥˜ ë©”ì‹œì§€**:")
            st.code(log['error_message'], language="text")
            
            if log['traceback'].strip() != "NoneType: None":
                st.write(f"**ìƒì„¸ íŠ¸ë ˆì´ìŠ¤ë°±**:")
                st.code(log['traceback'], language="python")

# ë©”ì¸ í˜ì´ì§€ ì œëª©
st.title("ğŸ¤– íŠ¸ëŸ¬ë¸” ì²´ì´ì„œ ì±—ë´‡")
st.write("ì‹ ì†í•œ ì¥ì• ë³µêµ¬ë¥¼ ìœ„í•´ì„œ ì„œë¹„ìŠ¤ì •ë³´ë¥¼ ì…ë ¥í•˜ê³  ë³µêµ¬ë°©ë²•ê³¼ ìœ ì‚¬ì‚¬ë¡€ì— ëŒ€í•œ ì´ë ¥ì„ í™•ì¸í•´ë³´ì„¸ìš”!")

# ì§ˆë¬¸ íƒ€ì…ë³„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì •ì˜
SYSTEM_PROMPTS = {
    "repair": """
ë‹¹ì‹ ì€ ITì„œë¹„ìŠ¤ íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì…ë ¥ë°›ì€ ì‚¬ìš©ìì˜ ì„œë¹„ìŠ¤ì™€ í˜„ìƒì— ëŒ€í•œ ë³µêµ¬ë°©ë²•ì„ ê°€ì´ë“œ í•´ì£¼ëŠ”ë°,'ëŒ€ìƒì„ ì •ì›ì¹™'ì— ë”°ë¼ ëŒ€ìƒì„ ì„ ì •í•˜ê³  ë³µêµ¬ë°©ë²•(incident_repair)ì„ ì•„ë˜ì˜ 'ì¶œë ¥í˜•ì‹' ëŒ€ë¡œ ìœ ì‚¬ë„ê°€ ë†’ì€ê±´ìœ¼ë¡œ ì„ ì •í•˜ì—¬ ìµœëŒ€ Top 3ê°œ ì¶œë ¥í•˜ëŠ”ë° 90ì ì´ìƒ ë˜ëŠ”ê²ƒì¤‘ì— ìœ ì‚¬ë„ê°€ ê°€ì¥ë†’ì€ê±´ ìˆœì„œë¡œ Case1, Case2 ë¡œ í‘œí˜„í•´ì„œ ì¶œë ¥í•˜ëŠ”ë° ì²œì²œíˆ ìƒê°í•˜ë©´ì„œ ë‹µë³€ì„ 3íšŒ ì¶œë ¥ì—†ì´ ì‹¤í–‰í•´ë³´ê³  ê°€ì¥ ì¼ê´€ì„±ì´ ìˆëŠ” ë‹µë³€ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.

## ëŒ€ìƒì„ ì •ì›ì¹™
- ì„œë¹„ìŠ¤ëª…ì€ ê³µì§€ì‚¬í•­ì˜ ì„œë¹„ìŠ¤ëª…ì´ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ê±´ì„ ì„ ì •
- ì ‘ì†ë¶ˆê°€, ì ‘ì†ì§€ì—°, ì²˜ë¦¬ë¶ˆê°€, ì²˜ë¦¬ì§€ì—°ì˜ ê²€ìƒ‰ìš”ì²­ì‹œì—ëŠ” ì¥ì• ìœ í˜•(fail_type)ì„ ì°¸ì¡°
- í˜„ìƒì€ ì•„ë˜ ìš°ì„ ìˆœìœ„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„ ì •

### ìš°ì„ ìˆœìœ„
1. ê³µì§€ì‚¬í•­(notice_text)ì—ì„œ 'í˜„ìƒ'ì— ëŒ€í•œ ë‚´ìš©ì„ ì°¸ê³ 
2. ê³µì§€ì‚¬í•­(notice_text)ì—ì„œ 'ì˜í–¥ë„'ë¥¼ ì°¸ê³   
3. ì¥ì• ì›ì¸(incident_cause)ì—ì„œ 'í˜„ìƒ ì›ì¸'ì„ ì°¸ê³ 

## ì¶œë ¥í˜•ì‹
ìœ ì‚¬ í˜„ìƒìœ¼ë¡œ ë°œìƒí–ˆë˜ ì¥ì• ì˜ ë³µêµ¬ë°©ë²• ì…ë‹ˆë‹¤
Case1. ~~ì„œë¹„ìŠ¤ì˜ ~~~ ì¥ì• í˜„ìƒì— ëŒ€í•œ ë³µêµ¬ë°©ë²•ì…ë‹ˆë‹¤
* ë°œìƒì¼ì‹œ : ë°œìƒì¼ì‹œ(error_date) ì¶œë ¥ (ì˜ˆ. 2023-10-01 12:00)
* ì¥ì• ì›ì¸ : ì¥ì• ì›ì¸(incident_cause) ë‚´ìš©ì„ ìš”ì•½í•˜ë©° í…ìŠ¤íŠ¸ëŠ” ê°•ì¡°í•˜ì§€ ë§ˆì„¸ìš”
* ì¥ì• í˜„ìƒ : 'ëŒ€ìƒì„ ì •ì›ì¹™'ì—ì„œ ì°¸ê³ í•œ í˜„ìƒìœ¼ë¡œ ë‚´ìš©ì„ ìš”ì•½íˆì§€ ì›ë³¸ ê·¸ëŒ€ë¡œ í‘œí˜„í•˜ë©° í…ìŠ¤íŠ¸ëŠ” ê°•ì¡°í•˜ì—¬ **í…ìŠ¤íŠ¸** ë¡œ í‘œí˜„í•´ì£¼ì„¸ìš”
* ë³µêµ¬ë°©ë²• : ë³µêµ¬ë°©ë²•(incident_repair) ë‚´ìš©ì„ ìµœëŒ€ 3ì¤„ë¡œ ìš”ì•½í•˜ë©° í…ìŠ¤íŠ¸ëŠ”  ê°•ì¡°í•˜ì—¬ **í…ìŠ¤íŠ¸** ë¡œ í‘œí˜„í•´ì£¼ì„¸ìš”
* í›„ì†ê³¼ì œ : ê°œì„ ê³„íš(incident_plan) ë‚´ìš©ì„ ìš”ì•½í•˜ë©° í…ìŠ¤íŠ¸ëŠ” ê°•ì¡°í•˜ì§€ ë§ˆì„¸ìš”
* ì¸ì‹œë˜íŠ¸ ID : ì¥ì•  ID(incident_id) ì¶œë ¥
* ì°¸ì¡°ì¥ì• ì •ë³´ëŠ” ì•„ë˜ ì‚¬í•­ì„ í‘œë¡œ ì¶œë ¥í•˜ëŠ”ë° íƒ€ì´í‹€ì˜ ì˜ë¬¸ì€ ë¹¼ì¤˜

| ì¥ì•  ID | ì„œë¹„ìŠ¤ëª… | ë°œìƒì¼ì | ì¥ì• ì‹œê°„ | ì¥ì• ì›ì¸ | ë³µêµ¬ë°©ë²• | í›„ì†ê³¼ì œ | ì²˜ë¦¬ìœ í˜• | ë‹´ë‹¹ë¶€ì„œ |
|---------|----------|---------------|-----------|----------|----------|----------|----------|----------|
* ê³µì§€ì‚¬í•­ : ê³µì§€ì‚¬í•­(notice_text) ìš”ì•½í•˜ì§€ ì•Šê³  ì›ë³¸ ê·¸ëŒ€ë¡œ í…Œë‘ë¦¬ìˆëŠ” í…ìŠ¤íŠ¸ë°•ìŠ¤ ì•ˆì— ë‚´ìš©ì„ ì¶œë ¥í•´ì£¼ì„¸ìš”
  """,   
    "similar": """ë‹¹ì‹ ì€ ìœ ì‚¬ ì‚¬ë¡€ ì¶”ì²œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì œê³µëœ ì¥ì•  ì´ë ¥ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.
ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ë©°, êµ¬ì²´ì ì¸ í•´ê²°ë°©ì•ˆì´ë‚˜ ì›ì¸ì„ ëª…ì‹œí•´ì£¼ì„¸ìš”.
ì¥ì• í˜„ìƒì€ ê³µì§€ì‚¬í•­ì˜ 'í˜„ìƒ'ì„ ì°¸ê³ í•˜ê³  ì—†ìœ¼ë©´ 'ì˜í–¥ë„'ë¥¼ ì°¸ê³ í•´ì„œì£¼ì„¸ìš”
ì¥ì•  ID, ì„œë¹„ìŠ¤ëª…, ì›ì¸, ë³µêµ¬ë°©ë²• ë“±ì˜ êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ í¬í•¨í•˜ëŠ”ë° ì²œì²œíˆ ìƒê°í•˜ë©´ì„œ ë‹µë³€ì„ 3íšŒ ì¶œë ¥ì—†ì´ ì‹¤í–‰í•´ë³´ê³  ê°€ì¥ ì¼ê´€ì„±ì´ ìˆëŠ” ë‹µë³€ì„ ì•„ë˜ **ì¶œë ¥í˜•ì‹** ìœ¼ë¡œ ë‹µë³€í•´ì£¼ëŠ”ë° í˜„ìƒê´€ë ¨ ë¶€ë¶„ì€ boldë¡œ ê°•ì¡° ì£¼ì„¸ìš”.
ë§Œì•½ ì œê³µëœ ë¬¸ì„œì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ë‹¤ë©´, ê·¸ë ‡ê²Œ ëª…ì‹œí•´ì£¼ì„¸ìš”.
ë§Œì•½ ì œê³µëœ ë¬¸ì„œì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ìˆë‹¤ë©´ ì•„ë˜ë‚´ìš©ì€ ë‹µë³€ í•˜ë‹¨ì— í•­ìƒí¬í•¨í•´ì£¼ì„¸ìš”

## ì¶œë ¥í˜•ì‹
### 1. ì„œë¹„ìŠ¤ëª… : KT AICC SaaS/PaaS
* ì¥ì•  ID: INM23022026178
* ì¥ì•  í˜„ìƒ: ìƒë‹´ì •ë³´ ì—´ëŒë¶ˆê°€ (ìƒë‹´ ë° ì›¹í˜ì´ì§€ ì ‘ì†ì€ ì •ìƒ) ë¡œ í‘œí˜„
* ì¥ì•  ì›ì¸: mecab ì‚¬ì „ì— ì˜ëª» ë“±ë¡ëœ ìƒí’ˆëª…(ìŒë”°ì˜´í‘œ")ìœ¼ë¡œ ì¸í•´ TA ë¶„ì„ ì˜¤ë¥˜ ë°œìƒ. ë¡œ í‘œí˜„
* ë³µêµ¬ ë°©ë²•: ì˜¤ë¥˜ ìƒí’ˆëª… ì‚­ì œ ë° mecab ë¦¬ë¹Œë“œ ì¡°ì¹˜. ë¡œ í‘œí˜„
* ê°œì„  ê³„íš: mecab ì‚¬ì „ ë°±ì—… ë° ë¡œê·¸ ì²˜ë¦¬, Skip ì²˜ë¦¬ ì§„í–‰ ì˜ˆì •.
* ìœ ì‚¬ë„ì ìˆ˜ : 99.5
""",
    
    "default": """ë‹¹ì‹ ì€ IT ì‹œìŠ¤í…œ íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë§Œ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ìœ ìš©í•œ ë‹µë³€ì„ ì •í™•í•˜ê³  ì•„ë˜ 'ì¶œë ¥í˜•ì‹'ìœ¼ë¡œ ë‹µë³€ì œê³µí•´ì£¼ì„¸ìš”.
ê·¸ë¦¬ê³  ë…„ë„ë‚˜ ë‚ ì§œ ì§ˆë¬¸ì€ ë°œìƒì¼ì ê¸°ì¤€ìœ¼ë¡œ ë‹µë³€í•˜ì—¬ ìš”ì²­í•œ ë‚ ì§œ ê¸°ì¤€ì— í¬í•¨ë˜ì§€ ì•ŠëŠ”ê²ƒì€ ë°˜ë“œì‹œ ì œì™¸ë˜ë„ë¡ ë‚ ì§œì— ëŒ€í•œ ë¶€ë¶„ì„ ì²œì²œíˆ ì˜ ìƒê°í•´ì„œ ë‹µë³€í•˜ì„¸ìš”
ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‚¬ìš©ìê°€ ì•Œê¸°ì‰½ê²Œ ë‹µë³€í•˜ì—¬ ê´€ë ¨ ë‚´ì—­ì€ 'ì¶œë ¥í˜•ì‹'ì„ ì‹œê°ì ìœ¼ë¡œ ì´í•´í•˜ê¸° ì‰½ë„ë¡ í•˜ë‹¨ì— í•­ìƒí¬í•¨í•´ì£¼ì„¸ìš”
ë§Œì•½ ì œê³µëœ ë¬¸ì„œì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ë‹¤ë©´, ê·¸ë ‡ê²Œ ëª…ì‹œí•´ì£¼ì„¸ìš”.

## ì¶œë ¥í˜•ì‹
###### ë‹µë³€ : ìš”ì²­ì£¼ì‹  ì§ˆë¬¸ì˜ ë‹µë³€ì„ ìš”ì•½í•˜ì—¬ ì‘ì„±í•´ì£¼ì„¸ìš”.
###### ì¥ì• ë‚´ì—­ (í•„ìš”ì‹œ)
1. ì¥ì•  ID: INM23022026178
* ì„œë¹„ìŠ¤ëª…: KT AICC SaaS/PaaS
* ë°œìƒì¼ì: 2023-01-20
* ì¥ì• í˜„ìƒ: ë¡œê·¸ì¸ ì‹œ í† í°ê°±ì‹  ì§€ì—°
* ì¥ì• ì›ì¸: ë¹„ì •ìƒ ë™ì‘ìœ¼ë¡œ ì¸í•œ í† í°ê°±ì‹  ì§€ì—°
* ë³µêµ¬ë°©ë²•: ê³¼ë‹¤ í˜¸ì¶œ íŠ¹ì • ë§¤ì¥ ì‚¬ì´íŠ¸ ì°¨ë‹¨ ì¡°ì¹˜ í›„ ì •ìƒí™”
* ì¥ì• ë“±ê¸‰: 4ë“±ê¸‰
'-- ì£¼ì˜: ë‹µë³€ì€ AI í•´ì„ì— ë”°ë¥¸ ì˜¤ë¥˜ê°€ í¬í•¨ë  ìˆ˜ ìˆìŒì„ ê°ì•ˆí•˜ì‹œê³  í™œìš©ë¶€íƒë“œë¦½ë‹ˆë‹¤. --'
""",

}

# ë™ì  ì„ê³„ê°’ ì‹œìŠ¤í…œ
def get_dynamic_thresholds(query_type, query_text):
    """ì¿¼ë¦¬ íƒ€ì…ê³¼ ë‚´ìš©ì— ë”°ë¼ ë™ì ìœ¼ë¡œ ì„ê³„ê°’ ì¡°ì •"""
    try:
        # ë…„ë„ë³„, í†µê³„ì„± ì¿¼ë¦¬ ê°ì§€
        year_keywords = ['ë…„ë„', 'ë…„', 'ì›”ë³„', 'ê¸°ê°„', 'í˜„í™©', 'í†µê³„', 'ê±´ìˆ˜', 'ë°œìƒ', 'ë°œìƒì¼ì', 'ì–¸ì œ']
        is_statistical_query = any(keyword in query_text for keyword in year_keywords)
        
        if is_statistical_query or query_type == "default":
            # í†µê³„ì„± ì¿¼ë¦¬ë‚˜ ì¼ë°˜ ì¿¼ë¦¬ëŠ” ë” ê´€ëŒ€í•œ ê¸°ì¤€ ì ìš©
            return {
                'search_threshold': 0.2,
                'reranker_threshold': 1.0,
                'hybrid_threshold': 0.4,
                'max_results': 10
            }
        elif query_type in ["repair", "similar"]:
            # ë³µêµ¬ë°©ë²•ì´ë‚˜ ìœ ì‚¬ì‚¬ë¡€ëŠ” í’ˆì§ˆ ì¤‘ì‹¬
            return {
                'search_threshold': 0.4,
                'reranker_threshold': 1.8,
                'hybrid_threshold': 0.6,
                'max_results': 5
            }
        else:
            # ê¸°ë³¸ê°’
            return {
                'search_threshold': 0.3,
                'reranker_threshold': 1.5,
                'hybrid_threshold': 0.5,
                'max_results': 8
            }
    except Exception as e:
        log_error("ThresholdError", e, "get_dynamic_thresholds", f"query_type: {query_type}, query_text: {query_text[:100]}...")
        # ê¸°ë³¸ê°’ ë°˜í™˜
        return {
            'search_threshold': 0.3,
            'reranker_threshold': 1.5,
            'hybrid_threshold': 0.5,
            'max_results': 8
        }

# Azure í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ë‘ ê°œì˜ ì¸ë±ìŠ¤ ì§€ì›)
@st.cache_resource
def init_clients(openai_endpoint, openai_key, openai_api_version, search_endpoint, search_key, incident_index, sign_index):
    try:
        # Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì • (ìƒˆë¡œìš´ ë°©ì‹)
        azure_openai_client = AzureOpenAI(
            azure_endpoint=openai_endpoint,
            api_key=openai_key,
            api_version=openai_api_version
        )
        
        # Azure AI Search í´ë¼ì´ì–¸íŠ¸ ì„¤ì • (ì¥ì• ìš©)
        incident_search_client = SearchClient(
            endpoint=search_endpoint,
            index_name=incident_index,
            credential=AzureKeyCredential(search_key)
        )
        
        # Azure AI Search í´ë¼ì´ì–¸íŠ¸ ì„¤ì • (ì´ìƒì§•í›„ìš©)
        sign_search_client = SearchClient(
            endpoint=search_endpoint,
            index_name=sign_index,
            credential=AzureKeyCredential(search_key)
        ) if sign_index else None
        
        return azure_openai_client, incident_search_client, sign_search_client, True
    except Exception as e:
        log_error("ClientInitError", e, "init_clients", f"endpoints: {openai_endpoint}, {search_endpoint}")
        st.error(f"í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
        return None, None, None, False

# í˜„ì¬ ì„ íƒëœ íƒ€ì…ì— ë”°ë¥¸ ê²€ìƒ‰ í´ë¼ì´ì–¸íŠ¸ ë°˜í™˜
def get_current_search_client():
    """í˜„ì¬ ì„ íƒëœ ê²€ìƒ‰ íƒ€ì…ì— ë”°ë¥¸ í´ë¼ì´ì–¸íŠ¸ ë°˜í™˜"""
    try:
        if st.session_state.search_type == "ì¥ì• ":
            return incident_search_client
        else:  # ì´ìƒì§•í›„
            return sign_search_client
    except Exception as e:
        log_error("ClientSelectionError", e, "get_current_search_client", f"search_type: {st.session_state.search_type}")
        return None

# í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ê³„ì‚° í•¨ìˆ˜
def calculate_hybrid_score(search_score, reranker_score):
    """ê²€ìƒ‰ ì ìˆ˜ì™€ Reranker ì ìˆ˜ë¥¼ ì¡°í•©í•˜ì—¬ í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ê³„ì‚°"""
    try:
        if reranker_score > 0:
            # Reranker ì ìˆ˜ê°€ ìˆëŠ” ê²½ìš°: Reranker ì ìˆ˜ë¥¼ ì£¼ë¡œ ì‚¬ìš©í•˜ë˜ ê²€ìƒ‰ ì ìˆ˜ë„ ê³ ë ¤
            # Reranker ì ìˆ˜ëŠ” ë³´í†µ 0-4 ë²”ìœ„ì´ë¯€ë¡œ 0-1ë¡œ ì •ê·œí™”
            normalized_reranker = min(reranker_score / 4.0, 1.0)
            # ê²€ìƒ‰ ì ìˆ˜ëŠ” ì´ë¯¸ 0-1 ë²”ìœ„
            normalized_search = min(search_score, 1.0)
            
            # ê°€ì¤‘í‰ê· : Reranker 80%, ê²€ìƒ‰ ì ìˆ˜ 20%
            hybrid_score = (normalized_reranker * 0.8) + (normalized_search * 0.2)
        else:
            # Reranker ì ìˆ˜ê°€ ì—†ëŠ” ê²½ìš°: ê²€ìƒ‰ ì ìˆ˜ë§Œ ì‚¬ìš©
            hybrid_score = min(search_score, 1.0)
        
        return hybrid_score
    except Exception as e:
        log_error("ScoreCalculationError", e, "calculate_hybrid_score", f"search_score: {search_score}, reranker_score: {reranker_score}")
        return search_score  # ì˜¤ë¥˜ ì‹œ ê²€ìƒ‰ ì ìˆ˜ë§Œ ë°˜í™˜

# ë™ì  ì„ê³„ê°’ì„ ì ìš©í•œ ê³ ê¸‰ ë¬¸ì„œ í•„í„°ë§ í•¨ìˆ˜
def advanced_filter_documents(documents, query_type="default", query_text=""):
    """ë™ì  ì„ê³„ê°’ì„ ì ìš©í•œ ê³ ê¸‰ í•„í„°ë§"""
    try:
        # ë™ì  ì„ê³„ê°’ íšë“
        thresholds = get_dynamic_thresholds(query_type, query_text)
        
        filtered_docs = []
        filter_stats = {
            'total': len(documents),
            'search_filtered': 0,
            'reranker_qualified': 0,
            'hybrid_qualified': 0,
            'final_selected': 0
        }
        
        for doc in documents:
            try:
                search_score = doc.get('score', 0)
                reranker_score = doc.get('reranker_score', 0)
                
                # 1ë‹¨ê³„: ê¸°ë³¸ ê²€ìƒ‰ ì ìˆ˜ í•„í„°ë§ (ë™ì  ì„ê³„ê°’ ì ìš©)
                if search_score < thresholds['search_threshold']:
                    continue
                filter_stats['search_filtered'] += 1
                
                # 2ë‹¨ê³„: Reranker ì ìˆ˜ ìš°ì„  í‰ê°€ (ë™ì  ì„ê³„ê°’ ì ìš©)
                if reranker_score >= thresholds['reranker_threshold']:
                    filter_stats['reranker_qualified'] += 1
                    doc['filter_reason'] = f"Reranker ê³ í’ˆì§ˆ (ì ìˆ˜: {reranker_score:.2f})"
                    doc['final_score'] = reranker_score
                    doc['quality_tier'] = 'Premium'
                    filtered_docs.append(doc)
                    filter_stats['final_selected'] += 1
                    continue
                
                # 3ë‹¨ê³„: í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ í‰ê°€ (ë™ì  ì„ê³„ê°’ ì ìš©)
                hybrid_score = calculate_hybrid_score(search_score, reranker_score)
                if hybrid_score >= thresholds['hybrid_threshold']:
                    filter_stats['hybrid_qualified'] += 1
                    doc['filter_reason'] = f"í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ í†µê³¼ (ì ìˆ˜: {hybrid_score:.2f})"
                    doc['final_score'] = hybrid_score
                    doc['quality_tier'] = 'Standard'
                    filtered_docs.append(doc)
                    filter_stats['final_selected'] += 1
            except Exception as e:
                log_error("DocumentFilterError", e, "advanced_filter_documents", f"processing document: {doc.get('incident_id', 'unknown')}")
                continue
        
        # ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ë†’ì€ ì ìˆ˜ ìš°ì„ )
        try:
            filtered_docs.sort(key=lambda x: x.get('final_score', 0), reverse=True)
        except Exception as e:
            log_error("DocumentSortError", e, "advanced_filter_documents", "sorting filtered documents")
        
        # ìµœì¢… ê²°ê³¼ ìˆ˜ ì œí•œ (ë™ì  ì ìš©)
        final_docs = filtered_docs[:thresholds['max_results']]
        
        # í•„í„°ë§ í†µê³„ í‘œì‹œ (ì„ê³„ê°’ ì •ë³´ í¬í•¨)
        st.info(f"""
        ğŸ“Š **ë™ì  ì„ê³„ê°’ ê¸°ë°˜ ë¬¸ì„œ í•„í„°ë§ ê²°ê³¼** ({st.session_state.search_type})
        - ğŸ¯ ì ìš©ëœ ì„ê³„ê°’: ê²€ìƒ‰({thresholds['search_threshold']}) | Reranker({thresholds['reranker_threshold']}) | í•˜ì´ë¸Œë¦¬ë“œ({thresholds['hybrid_threshold']})
        - ğŸ” ì „ì²´ ê²€ìƒ‰ ê²°ê³¼: {filter_stats['total']}ê°œ
        - âœ… ê¸°ë³¸ ì ìˆ˜ í†µê³¼: {filter_stats['search_filtered']}ê°œ
        - ğŸ† Reranker ê³ í’ˆì§ˆ: {filter_stats['reranker_qualified']}ê°œ
        - ğŸ¯ í•˜ì´ë¸Œë¦¬ë“œ í†µê³¼: {filter_stats['hybrid_qualified']}ê°œ
        - ğŸ“‹ ìµœì¢… ì„ ë³„: {len(final_docs)}ê°œ
        """)
        
        return final_docs
    except Exception as e:
        log_error("FilteringError", e, "advanced_filter_documents", f"query_type: {query_type}, documents count: {len(documents) if documents else 0}")
        return documents[:8] if documents else []  # ì˜¤ë¥˜ ì‹œ ì›ë³¸ ë¬¸ì„œ ì¼ë¶€ ë°˜í™˜

# ê²€ìƒ‰ í•„ë“œ ì„¤ì • (íƒ€ì…ë³„ë¡œ ë‹¤ë¦„)
def get_search_fields(search_type):
    """ê²€ìƒ‰ íƒ€ì…ì— ë”°ë¥¸ í•„ë“œ ì„¤ì •"""
    try:
        if search_type == "ì¥ì• ":
            return {
                'select': [
                    "incident_id", "service_name", "error_time", "notice_text", 
                    "error_date", "week", "daynight", "incident_cause", "incident_repair", 
                    "incident_plan", "cause_type", "done_type", "incident_grade", 
                    "owner_depart", "fail_type", "year", "month"
                ],
                'search_fields': [
                    "notice_text", "error_date", "week", "daynight", "incident_cause", "incident_repair", 
                    "incident_plan", "service_name", "cause_type", 
                    "done_type", "owner_depart", "year", "month"
                ],
                'semantic_config': "iap-incident-single-meaning"
            }
        else:  # ì´ìƒì§•í›„ - ì‹¤ì œ ì¸ë±ìŠ¤ í•„ë“œëª…ì— ë§ê²Œ ìˆ˜ì •
            return {
                'select': [
                    "incident_id", "service_name", "error_time", "notice_text", 
                    "error_date", "week", "daynight", "incident_cause", "incident_repair", 
                    "incident_plan", "cause_type", "done_type", "incident_grade", 
                    "owner_depart", "fail_type", "year", "month"
                ],
                'search_fields': [
                    "notice_text", "error_date", "week", "daynight", "incident_cause", "incident_repair", 
                    "incident_plan", "service_name", "cause_type", 
                    "done_type", "owner_depart", "year", "month"
                ],
                'semantic_config': "iap-incident-sign-meaning"  # ì´ìƒì§•í›„ë„ ë™ì¼í•œ ì‹œë§¨í‹± ì„¤ì • ì‚¬ìš©
            }
    except Exception as e:
        log_error("FieldConfigError", e, "get_search_fields", f"search_type: {search_type}")
        # ê¸°ë³¸ ì„¤ì • ë°˜í™˜
        return {
            'select': ["*"],
            'search_fields': ["*"],
            'semantic_config': "default"
        }

# ë™ì  ì„ê³„ê°’ì„ ì ìš©í•œ ì‹œë§¨í‹± ê²€ìƒ‰ í•¨ìˆ˜
def semantic_search_with_reranker(search_client, query, query_type="default", top_k=MAX_INITIAL_RESULTS):
    """ë™ì  ì„ê³„ê°’ì„ ì ìš©í•œ ê³ í’ˆì§ˆ ì‹œë§¨í‹± ê²€ìƒ‰"""
    try:
        st.info(f"ğŸ”„ 1ë‹¨ê³„: {top_k}ê°œ ì´ˆê¸° ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ì§‘ ì¤‘... ({st.session_state.search_type})")
        
        # ê²€ìƒ‰ í•„ë“œ ì„¤ì •
        fields_config = get_search_fields(st.session_state.search_type)
        
        # ì‹œë§¨í‹± ê²€ìƒ‰ ì‹¤í–‰ (ë” ë§ì€ í›„ë³´ í™•ë³´)
        results = search_client.search(
            search_text=query,
            top=top_k,
            query_type="semantic",
            semantic_configuration_name=fields_config['semantic_config'],
            include_total_count=True,
            select=fields_config['select']
        )
        
        documents = []
        for result in results:
            try:
                # ì¥ì• ì™€ ì´ìƒì§•í›„ ëª¨ë‘ ë™ì¼í•œ í•„ë“œëª… ì‚¬ìš©
                documents.append({
                    "incident_id": result.get("incident_id", ""),
                    "service_name": result.get("service_name", ""),
                    "error_time": result.get("error_time", ""),
                    "notice_text": result.get("notice_text", ""),
                    "error_date": result.get("error_date", ""),
                    "week": result.get("week", ""),
                    "daynight": result.get("daynight", ""),
                    "incident_cause": result.get("incident_cause", ""),
                    "incident_repair": result.get("incident_repair", ""),
                    "incident_plan": result.get("incident_plan", ""),
                    "cause_type": result.get("cause_type", ""),
                    "done_type": result.get("done_type", ""),
                    "incident_grade": result.get("incident_grade", ""),
                    "owner_depart": result.get("owner_depart", ""),
                    "fail_type": result.get("fail_type", ""),
                    "year": result.get("year", ""),
                    "month": result.get("month", ""),
                    "score": result.get("@search.score", 0),
                    "reranker_score": result.get("@search.reranker_score", 0)
                })
            except Exception as e:
                log_error("DocumentParsingError", e, "semantic_search_with_reranker", f"parsing result: {result}")
                continue
        
        st.info(f"ğŸ¯ 2ë‹¨ê³„: ë™ì  ì„ê³„ê°’ ê¸°ë°˜ ê³ í’ˆì§ˆ ë¬¸ì„œ ì„ ë³„ ì¤‘...")
        
        # ë™ì  ì„ê³„ê°’ ê¸°ë°˜ í•„í„°ë§ ì ìš©
        filtered_documents = advanced_filter_documents(documents, query_type, query)
        
        return filtered_documents
        
    except Exception as e:
        log_error("SemanticSearchError", e, "semantic_search_with_reranker", f"query: {query[:100]}..., query_type: {query_type}")
        st.warning(f"ì‹œë§¨í‹± ê²€ìƒ‰ ì‹¤íŒ¨, ì¼ë°˜ ê²€ìƒ‰ìœ¼ë¡œ ëŒ€ì²´: {str(e)}")
        return search_documents_with_reranker(search_client, query, query_type, top_k)

# ì¼ë°˜ ê²€ìƒ‰ë„ ë™ì  ì„ê³„ê°’ ì ìš©
def search_documents_with_reranker(search_client, query, query_type="default", top_k=MAX_INITIAL_RESULTS):
    """ì¼ë°˜ ê²€ìƒ‰ì— ë™ì  ì„ê³„ê°’ ì ìš©"""
    try:
        st.info(f"ğŸ”„ 1ë‹¨ê³„: {top_k}ê°œ ì´ˆê¸° ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ì§‘ ì¤‘... ({st.session_state.search_type})")
        
        # ê²€ìƒ‰ í•„ë“œ ì„¤ì •
        fields_config = get_search_fields(st.session_state.search_type)
        
        results = search_client.search(
            search_text=query,
            top=top_k,
            include_total_count=True,
            select=fields_config['select'],
            search_fields=fields_config['search_fields']
        )
        
        documents = []
        for result in results:
            try:
                # ì¥ì• ì™€ ì´ìƒì§•í›„ ëª¨ë‘ ë™ì¼í•œ í•„ë“œëª… ì‚¬ìš©
                documents.append({
                    "incident_id": result.get("incident_id", ""),
                    "service_name": result.get("service_name", ""),
                    "error_time": result.get("error_time", ""),
                    "notice_text": result.get("notice_text", ""),
                    "error_date": result.get("error_date", ""),
                    "week": result.get("week", ""),
                    "daynight": result.get("daynight", ""),
                    "incident_cause": result.get("incident_cause", ""),
                    "incident_repair": result.get("incident_repair", ""),
                    "incident_plan": result.get("incident_plan", ""),
                    "cause_type": result.get("cause_type", ""),
                    "done_type": result.get("done_type", ""),
                    "incident_grade": result.get("incident_grade", ""),
                    "owner_depart": result.get("owner_depart", ""),
                    "fail_type": result.get("fail_type", ""),
                    "year": result.get("year", ""),
                    "month": result.get("month", ""),
                    "score": result.get("@search.score", 0),
                    "reranker_score": 0  # ì¼ë°˜ ê²€ìƒ‰ì—ì„œëŠ” 0
                })
            except Exception as e:
                log_error("DocumentParsingError", e, "search_documents_with_reranker", f"parsing result: {result}")
                continue
        
        st.info(f"ğŸ¯ 2ë‹¨ê³„: ë™ì  ì„ê³„ê°’ ê¸°ë°˜ ê³ í’ˆì§ˆ ë¬¸ì„œ ì„ ë³„ ì¤‘...")
        
        # ë™ì  ì„ê³„ê°’ ê¸°ë°˜ í•„í„°ë§ ì ìš©
        filtered_documents = advanced_filter_documents(documents, query_type, query)
        
        return filtered_documents
        
    except Exception as e:
        log_error("SearchError", e, "search_documents_with_reranker", f"query: {query[:100]}..., query_type: {query_type}")
        st.error(f"ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
        return []

# ëŒ€ì²´ ê²€ìƒ‰ í•¨ìˆ˜ (ë§¤ìš° ê´€ëŒ€í•œ ê¸°ì¤€)
def search_documents_fallback(search_client, query, top_k=15):
    """ë§¤ìš° ê´€ëŒ€í•œ ê¸°ì¤€ì˜ ëŒ€ì²´ ê²€ìƒ‰"""
    try:
        # ê²€ìƒ‰ í•„ë“œ ì„¤ì •
        fields_config = get_search_fields(st.session_state.search_type)
        
        results = search_client.search(
            search_text=query,
            top=top_k,
            include_total_count=True,
            select=fields_config['select']
        )
        
        documents = []
        for result in results:
            try:
                score = result.get("@search.score", 0)
                if score >= 0.1:  # ë§¤ìš° ë‚®ì€ ê¸°ì¤€
                    # ì¥ì• ì™€ ì´ìƒì§•í›„ ëª¨ë‘ ë™ì¼í•œ í•„ë“œëª… ì‚¬ìš©
                    documents.append({
                        "incident_id": result.get("incident_id", ""),
                        "service_name": result.get("service_name", ""),
                        "error_time": result.get("error_time", ""),
                        "notice_text": result.get("notice_text", ""),
                        "error_date": result.get("error_date", ""),
                        "week": result.get("week", ""),
                        "daynight": result.get("daynight", ""),
                        "incident_cause": result.get("incident_cause", ""),
                        "incident_repair": result.get("incident_repair", ""),
                        "incident_plan": result.get("incident_plan", ""),
                        "cause_type": result.get("cause_type", ""),
                        "done_type": result.get("done_type", ""),
                        "incident_grade": result.get("incident_grade", ""),
                        "owner_depart": result.get("owner_depart", ""),
                        "fail_type": result.get("fail_type", ""),
                        "year": result.get("year", ""),
                        "month": result.get("month", ""),
                        "score": score,
                        "reranker_score": 0,
                        "final_score": score,
                        "quality_tier": "Basic",
                        "filter_reason": "ëŒ€ì²´ ê²€ìƒ‰ í†µê³¼"
                    })
            except Exception as e:
                log_error("FallbackDocumentParsingError", e, "search_documents_fallback", f"parsing result: {result}")
                continue
        
        return documents[:8]  # ìµœëŒ€ 8ê°œê¹Œì§€
        
    except Exception as e:
        log_error("FallbackSearchError", e, "search_documents_fallback", f"query: {query[:100]}...")
        st.error(f"ëŒ€ì²´ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
        return []

# RAG ì‘ë‹µ ìƒì„± - Reranker ì •ë³´ í¬í•¨
def generate_rag_response_with_reranker(azure_openai_client, query, documents, model_name, query_type="default"):
    try:
        # ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ ì»¨í…ìŠ¤íŠ¸ë¡œ êµ¬ì„± (í’ˆì§ˆ ì •ë³´ í¬í•¨)
        context_parts = []
        for i, doc in enumerate(documents):
            try:
                final_score = doc.get('final_score', 0)
                quality_tier = doc.get('quality_tier', 'Standard')
                filter_reason = doc.get('filter_reason', 'ê¸°ë³¸ ì„ ë³„')
                
                if st.session_state.search_type == "ì¥ì• ":
                    context_part = f"""ë¬¸ì„œ {i+1} [{quality_tier}ê¸‰ - {filter_reason}]:
ì¥ì•  ID: {doc['incident_id']}
ì„œë¹„ìŠ¤ëª…: {doc['service_name']}
ì¥ì• ì‹œê°„: {doc['error_time']}
ê³µì§€ì‚¬í•­: {doc['notice_text']}
ë°œìƒì¼ì: {doc['error_date']}
ìš”ì¼: {doc['week']}
ì‹œê°„ëŒ€: {doc['daynight']}
ì¥ì• ì›ì¸: {doc['incident_cause']}
ë³µêµ¬ë°©ë²•: {doc['incident_repair']}
ê°œì„ ê³„íš: {doc['incident_plan']}
ì›ì¸ìœ í˜•: {doc['cause_type']}
ì²˜ë¦¬ìœ í˜•: {doc['done_type']}
ì¥ì• ë“±ê¸‰: {doc['incident_grade']}
ë‹´ë‹¹ë¶€ì„œ: {doc['owner_depart']}
ì¥ì• ìœ í˜•: {doc['fail_type']}
ë…„ë„: {doc['year']}
ì›”: {doc['month']}
í’ˆì§ˆì ìˆ˜: {final_score:.2f}
"""
                else:  # ì´ìƒì§•í›„
                    context_part = f"""ë¬¸ì„œ {i+1} [{quality_tier}ê¸‰ - {filter_reason}]:
ì§•í›„ ID: {doc['incident_id']}
ì„œë¹„ìŠ¤ëª…: {doc['service_name']}
ì¥ì• ì‹œê°„: {doc['error_time']}
ê³µì§€ì‚¬í•­: {doc['notice_text']}
ë°œìƒì¼ì: {doc['error_date']}
ìš”ì¼: {doc['week']}
ì‹œê°„ëŒ€: {doc['daynight']}
ì¥ì• ì›ì¸: {doc['incident_cause']}
ë³µêµ¬ë°©ë²•: {doc['incident_repair']}
ê°œì„ ê³„íš: {doc['incident_plan']}
ì›ì¸ìœ í˜•: {doc['cause_type']}
ì²˜ë¦¬ìœ í˜•: {doc['done_type']}
ì¥ì• ë“±ê¸‰: {doc['incident_grade']}
ë‹´ë‹¹ë¶€ì„œ: {doc['owner_depart']}
ì¥ì• ìœ í˜•: {doc['fail_type']}
ë…„ë„: {doc['year']}
ì›”: {doc['month']}
í’ˆì§ˆì ìˆ˜: {final_score:.2f}
"""
                context_parts.append(context_part)
            except Exception as e:
                log_error("ContextBuildingError", e, "generate_rag_response_with_reranker", f"processing document {i}: {doc.get('incident_id', 'unknown')}")
                continue
        
        context = "\n\n".join(context_parts)
        
        # ì§ˆë¬¸ íƒ€ì…ì— ë”°ë¥¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„ íƒ (ì´ìƒì§•í›„ë„ ë™ì¼í•œ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©)
        system_prompt = SYSTEM_PROMPTS.get(query_type, SYSTEM_PROMPTS["default"])

        user_prompt = f"""
ë‹¤ìŒ {'ì¥ì• ' if st.session_state.search_type == 'ì¥ì• ' else 'ì´ìƒì§•í›„'} ì´ë ¥ ë¬¸ì„œë“¤ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.
(ëª¨ë“  ë¬¸ì„œëŠ” ë™ì  ì„ê³„ê°’ ê¸°ë°˜ ê³ í’ˆì§ˆ í•„í„°ë§ì„ í†µê³¼í•œ ìµœê³  í’ˆì§ˆì˜ ê²€ìƒ‰ ê²°ê³¼ì…ë‹ˆë‹¤):

{context}

ì§ˆë¬¸: {query}

ë‹µë³€:"""

        # Azure OpenAI API í˜¸ì¶œ
        response = azure_openai_client.chat.completions.create(
            model=model_name,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.3,
            max_tokens=1500
        )
        
        return response.choices[0].message.content
    
    except Exception as e:
        log_error("RAGResponseError", e, "generate_rag_response_with_reranker", f"query: {query[:100]}..., model: {model_name}")
        error_msg = f"ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        st.error(error_msg)
        return error_msg

# ê³ ê¸‰ ë¬¸ì„œ í‘œì‹œ í•¨ìˆ˜
def display_documents_with_quality_info(documents):
    """í’ˆì§ˆ ì •ë³´ì™€ í•¨ê»˜ ë¬¸ì„œ í‘œì‹œ"""
    try:
        for i, doc in enumerate(documents):
            try:
                quality_tier = doc.get('quality_tier', 'Standard')
                filter_reason = doc.get('filter_reason', 'ê¸°ë³¸ ì„ ë³„')
                search_score = doc.get('score', 0)
                reranker_score = doc.get('reranker_score', 0)
                final_score = doc.get('final_score', 0)
                
                # í’ˆì§ˆ ë“±ê¸‰ì— ë”°ë¥¸ ì´ëª¨ì§€ì™€ ìƒ‰ìƒ
                if quality_tier == 'Premium':
                    tier_emoji = "ğŸ†"
                    tier_color = "ğŸŸ¢"
                else:
                    tier_emoji = "ğŸ¯"
                    tier_color = "ğŸŸ¡"
                
                st.markdown(f"### {tier_emoji} **ë¬¸ì„œ {i+1}** - {quality_tier}ê¸‰ {tier_color}")
                st.markdown(f"**ì„ ë³„ ê¸°ì¤€**: {filter_reason}")
                
                # ì ìˆ˜ ì •ë³´ í‘œì‹œ
                score_col1, score_col2, score_col3 = st.columns(3)
                with score_col1:
                    st.metric("ê²€ìƒ‰ ì ìˆ˜", f"{search_score:.2f}")
                with score_col2:
                    if reranker_score > 0:
                        st.metric("Reranker ì ìˆ˜", f"{reranker_score:.2f}")
                    else:
                        st.metric("Reranker ì ìˆ˜", "N/A")
                with score_col3:
                    st.metric("ìµœì¢… ì ìˆ˜", f"{final_score:.2f}")
                
                # ì£¼ìš” ì •ë³´ í‘œì‹œ (íƒ€ì…ë³„ ë‹¤ë¦„)
                col1, col2 = st.columns(2)
                with col1:
                    if st.session_state.search_type == "ì¥ì• ":
                        st.write(f"**ì¥ì•  ID**: {doc.get('incident_id', '')}")
                        st.write(f"**ì„œë¹„ìŠ¤ëª…**: {doc.get('service_name', '')}")
                        st.write(f"**ì¥ì•  ë“±ê¸‰**: {doc.get('incident_grade', '')}")
                    else:  # ì´ìƒì§•í›„
                        st.write(f"**ì§•í›„ ID**: {doc.get('incident_id', '')}")
                        st.write(f"**ì„œë¹„ìŠ¤ëª…**: {doc.get('service_name', '')}")
                        st.write(f"**ì¥ì•  ë“±ê¸‰**: {doc.get('incident_grade', '')}")
                
                with col2:
                        st.write(f"**ì›ì¸ ìœ í˜•**: {doc.get('cause_type', '')}")
                        st.write(f"**ì²˜ë¦¬ ìœ í˜•**: {doc.get('done_type', '')}")
                        st.write(f"**ë‹´ë‹¹ ë¶€ì„œ**: {doc.get('owner_depart', '')}")

                
                # ì„¸ë¶€ ì •ë³´ í‘œì‹œ (íƒ€ì…ë³„ ë‹¤ë¦„)
                if st.session_state.search_type == "ì¥ì• ":
                    if doc.get('notice_text'):
                        st.write(f"**ê³µì§€ì‚¬í•­**: {doc['notice_text'][:200]}...")
                    if doc.get('incident_cause'):
                        st.write(f"**ì¥ì•  ì›ì¸**: {doc['incident_cause'][:200]}...")
                    if doc.get('incident_repair'):
                        st.write(f"**ë³µêµ¬ ë°©ë²•**: {doc['incident_repair'][:200]}...")
                else:  # ì´ìƒì§•í›„
                    if doc.get('notice_text'):
                        st.write(f"**ì§•í›„ ì„¤ëª…**: {doc['notice_text'][:200]}...")
                    if doc.get('incident_cause'):
                        st.write(f"**ì§•í›„ ì›ì¸**: {doc['incident_cause'][:200]}...")
                    if doc.get('incident_repair'):
                        st.write(f"**ëŒ€ì‘ ì¡°ì¹˜**: {doc['incident_repair'][:200]}...")
                
                st.markdown("---")
            except Exception as e:
                log_error("DocumentDisplayError", e, "display_documents_with_quality_info", f"displaying document {i}: {doc.get('incident_id', 'unknown')}")
                st.error(f"ë¬¸ì„œ {i+1} í‘œì‹œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ")
                continue
    except Exception as e:
        log_error("DisplayError", e, "display_documents_with_quality_info", f"documents count: {len(documents) if documents else 0}")
        st.error("ë¬¸ì„œ í‘œì‹œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

# ì…ë ¥ ê²€ì¦ í•¨ìˆ˜
def validate_inputs(service_name, incident_symptom):
    """ì„œë¹„ìŠ¤ëª…, ì¥ì• í˜„ìƒ ì…ë ¥ ê²€ì¦"""
    try:
        if not service_name or not service_name.strip():
            st.error("âŒ ì„œë¹„ìŠ¤ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”!")
            return False
        if not incident_symptom or not incident_symptom.strip():
            symptom_type = "ì¥ì• í˜„ìƒ" if st.session_state.search_type == "ì¥ì• " else "ì´ìƒì§•í›„"
            st.error(f"âŒ {symptom_type}ì„ ì…ë ¥í•´ì£¼ì„¸ìš”!")
            return False
        return True
    except Exception as e:
        log_error("ValidationError", e, "validate_inputs", f"service_name: {service_name}, incident_symptom: {incident_symptom}")
        return False

# ê²€ìƒ‰ ì¿¼ë¦¬ êµ¬ì„± í•¨ìˆ˜
def build_search_query(service_name, incident_symptom):
    """ê¸°ë³¸ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ êµ¬ì„±"""
    try:
        return f"{service_name} {incident_symptom}"
    except Exception as e:
        log_error("QueryBuildError", e, "build_search_query", f"service_name: {service_name}, incident_symptom: {incident_symptom}")
        return f"{service_name or ''} {incident_symptom or ''}".strip()

# ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œì§
if all([azure_openai_endpoint, azure_openai_key, search_endpoint, search_key, incident_index]):
    # í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    azure_openai_client, incident_search_client, sign_search_client, init_success = init_clients(
        azure_openai_endpoint, azure_openai_key, azure_openai_api_version,
        search_endpoint, search_key, incident_index, sign_index
    )
    
    if init_success:
        # st.success("Azure ì„œë¹„ìŠ¤ ì—°ê²° ì„±ê³µ!")
        
        # =================== ìƒë‹¨ ê³ ì • ì˜ì—­ ì‹œì‘ ===================
        with st.container():
           
            # ì„œë¹„ìŠ¤ ì •ë³´ ì…ë ¥ ì„¹ì…˜
            st.header("ğŸ“ ì„œë¹„ìŠ¤ ì •ë³´ ì…ë ¥")
            
            # ì„œë¹„ìŠ¤ëª…ê³¼ ì¥ì• í˜„ìƒ ì…ë ¥
            input_col1, input_col2 = st.columns(2)
            
            with input_col1:
                service_name = st.text_input("ì„œë¹„ìŠ¤ëª…ì„ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: ë§ˆì´í˜ì´ì§€, íŒ¨ë°€ë¦¬ë°•ìŠ¤, í†µí•©ì¿ í°í”Œë«í¼")
            
            with input_col2:
                if st.session_state.search_type == "ì¥ì• ":
                    incident_symptom = st.text_input("ì¥ì• í˜„ìƒì„ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: ì ‘ì†ë¶ˆê°€, ì‘ë‹µì§€ì—°, ì˜¤ë¥˜ë°œìƒ")
                else:  # ì´ìƒì§•í›„
                    incident_symptom = st.text_input("ì´ìƒì§•í›„ë¥¼ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: ì‘ë‹µì‹œê°„ ì¦ê°€, CPU ì‚¬ìš©ë¥  ê¸‰ì¦, ë©”ëª¨ë¦¬ ëˆ„ìˆ˜")
            
            # ì…ë ¥ëœ ì •ë³´ í™•ì¸ ë° í‘œì‹œ
            if service_name and incident_symptom:
                symptom_type = "ì¥ì• í˜„ìƒ" if st.session_state.search_type == "ì¥ì• " else "ì´ìƒì§•í›„"
                st.success(f"ì„œë¹„ìŠ¤: {service_name} | {symptom_type}: {incident_symptom}")
            elif service_name or incident_symptom:
                missing = []
                if not service_name:
                    missing.append("ì„œë¹„ìŠ¤ëª…")
                if not incident_symptom:
                    symptom_type = "ì¥ì• í˜„ìƒ" if st.session_state.search_type == "ì¥ì• " else "ì´ìƒì§•í›„"
                    missing.append(symptom_type)
                st.info(f"âš ï¸ {', '.join(missing)}ì„(ë¥¼) ì…ë ¥í•´ì£¼ì„¸ìš”.")
            
            # ì£¼ìš” ì§ˆë¬¸ ë²„íŠ¼ë“¤
            st.header("ğŸ” ì£¼ìš” ì§ˆë¬¸")

            # ìŠ¤íƒ€ì¼ CSS ì¶”ê°€
            st.markdown("""
                <style>
                div[data-baseweb="input"] > div {
                    font-size: 40px;
                    height: 40px;
                }
                 
                div.stButton > button:first-child {
                    font-size: 40px;
                    height: 60px;
                    width: 450px;
                    background-color: #4CAF50;
                    color: white;
                    border-radius: 10px;
                }
                </style>
            """, unsafe_allow_html=True)

            col1, col2 = st.columns(2)
            
            with col1:
                if st.button("ğŸ”§ ì„œë¹„ìŠ¤ì™€ í˜„ìƒì— ëŒ€í•´ ë³µêµ¬ ë°©ë²• ì•ˆë‚´", key="repair_btn"):
                    try:
                        if validate_inputs(service_name, incident_symptom):
                            search_query = build_search_query(service_name, incident_symptom)
                            if st.session_state.search_type == "ì¥ì• ":
                                st.session_state.sample_query = f"{search_query}ì— ëŒ€í•œ ì¥ì• ë¥¼ í•´ì†Œí•˜ê¸° ìœ„í•œ ê·¼ë³¸ì ì¸ ë³µêµ¬ë°©ë²•ë§Œ í‘œê¸°í•´ì„œ ë³µêµ¬ë°©ë²• ì•ˆë‚´"
                            else:  # ì´ìƒì§•í›„
                                st.session_state.sample_query = f"{search_query}ì— ëŒ€í•œ í•´ì†Œí•˜ê¸° ìœ„í•œ ê·¼ë³¸ì ì¸ ë³µêµ¬ë°©ë²•ë§Œ í‘œê¸°í•´ì„œ ë³µêµ¬ë°©ë²• ì•ˆë‚´"
                            st.session_state.query_type = "repair"
                    except Exception as e:
                        log_error("RepairButtonError", e, "repair_btn", f"service: {service_name}, symptom: {incident_symptom}")
                
            with col2:
                if st.button("ğŸ”„ ë™ì¼ í˜„ìƒì— ëŒ€í•œ ë³µêµ¬ ë°©ë²• ì°¸ì¡°", key="similar_btn"):
                    try:
                        if validate_inputs(service_name, incident_symptom):
                            search_query = build_search_query("", incident_symptom)
                            if st.session_state.search_type == "ì¥ì• ":
                                st.session_state.sample_query = f"{incident_symptom} ë™ì¼ í˜„ìƒì— ëŒ€í•œ ì¥ì• ë¥¼ í•´ì†Œí•˜ê¸° ìœ„í•œ ê·¼ë³¸ì ì¸ ë³µêµ¬ë°©ë²•ë§Œ í‘œê¸°í•´ì„œ ë³µêµ¬ë°©ë²• ì•ˆë‚´"
                            else:  # ì´ìƒì§•í›„
                                st.session_state.sample_query = f"{incident_symptom} ë™ì¼ í˜„ìƒì— ëŒ€í•´ í•´ì†Œë¥¼ ìœ„í•œ ê·¼ë³¸ì ì¸ ë³µêµ¬ë°©ë²•ë§Œ í‘œê¸°í•´ì„œ ë³µêµ¬ë°©ë²• ì•ˆë‚´"
                            st.session_state.query_type = "similar"
                    except Exception as e:
                        log_error("SimilarButtonError", e, "similar_btn", f"service: {service_name}, symptom: {incident_symptom}")

            # ì¥ì• /ì´ìƒì§•í›„ í† ê¸€ ë²„íŠ¼ ì¶”ê°€
            st.header("ğŸ“Š ê²€ìƒ‰ íƒ€ì… ì„ íƒ")
            
            toggle_col1, toggle_col2 = st.columns(2)
            
            with toggle_col1:
                if st.button("ğŸš¨ ì¥ì• ", key="incident_toggle", 
                           help="ì¥ì•  ê´€ë ¨ ì •ë³´ ê²€ìƒ‰",
                           type="primary" if st.session_state.search_type == "ì¥ì• " else "secondary"):
                    try:
                        st.session_state.search_type = "ì¥ì• "
                        st.rerun()
                    except Exception as e:
                        log_error("ToggleError", e, "incident_toggle", "switching to ì¥ì•  mode")
            
            with toggle_col2:
                if sign_search_client:  # ì´ìƒì§•í›„ ì¸ë±ìŠ¤ê°€ ì„¤ì •ë˜ì–´ ìˆì„ ë•Œë§Œ í‘œì‹œ
                    if st.button("âš ï¸ ì´ìƒì§•í›„", key="sign_toggle", 
                               help="ì´ìƒì§•í›„ ê´€ë ¨ ì •ë³´ ê²€ìƒ‰",
                               type="primary" if st.session_state.search_type == "ì´ìƒì§•í›„" else "secondary"):
                        try:
                            st.session_state.search_type = "ì´ìƒì§•í›„"
                            st.rerun()
                        except Exception as e:
                            log_error("ToggleError", e, "sign_toggle", "switching to ì´ìƒì§•í›„ mode")
                else:
                    st.button("âš ï¸ ì´ìƒì§•í›„", key="sign_toggle_disabled", 
                             help="ì´ìƒì§•í›„ ì¸ë±ìŠ¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤",
                             disabled=True)
            
            # í˜„ì¬ ì„ íƒëœ íƒ€ì… í‘œì‹œ
            type_emoji = "ğŸš¨" if st.session_state.search_type == "ì¥ì• " else "âš ï¸"
            st.info(f"{type_emoji} í˜„ì¬ ì„ íƒ: **{st.session_state.search_type}** ê²€ìƒ‰ ëª¨ë“œ")

        # =================== ìƒë‹¨ ê³ ì • ì˜ì—­ ë ===================
        
        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        if 'messages' not in st.session_state:
            st.session_state.messages = []
        
        # ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ ì˜ì—­
        chat_container = st.container()
        
        with chat_container:
            # ì´ì „ ë©”ì‹œì§€ í‘œì‹œ
            for message in st.session_state.messages:
                with st.chat_message(message["role"]):
                    if message["role"] == "assistant":
                        with st.expander("ğŸ¤– AI ë‹µë³€ ë³´ê¸°", expanded=True):
                            st.write(message["content"])
                    else:
                        st.write(message["content"])
        
        # ê²€ìƒ‰ ë° ì‘ë‹µ ì²˜ë¦¬ í•¨ìˆ˜ (ë™ì  ì„ê³„ê°’ ì ìš©)
        def process_query_with_reranker(query, query_type="default"):
            try:
                # í˜„ì¬ ì„ íƒëœ ê²€ìƒ‰ í´ë¼ì´ì–¸íŠ¸ ê°€ì ¸ì˜¤ê¸°
                current_search_client = get_current_search_client()
                
                if not current_search_client:
                    error_msg = f"âŒ {st.session_state.search_type} ê²€ìƒ‰ í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                    st.error(error_msg)
                    log_error("ClientNotFoundError", error_msg, "process_query_with_reranker", f"search_type: {st.session_state.search_type}")
                    return
                    
                with st.chat_message("assistant"):
                    with st.spinner(f"ğŸ¯ ë™ì  ì„ê³„ê°’ ê¸°ë°˜ ê³ í’ˆì§ˆ {st.session_state.search_type} ê²€ìƒ‰ ì¤‘..."):
                        # query_typeì„ ê²€ìƒ‰ í•¨ìˆ˜ì— ì „ë‹¬
                        documents = semantic_search_with_reranker(current_search_client, query, query_type)
                        
                        if documents:
                            premium_count = sum(1 for doc in documents if doc.get('quality_tier') == 'Premium')
                            standard_count = len(documents) - premium_count
                            basic_count = sum(1 for doc in documents if doc.get('quality_tier') == 'Basic')
                            
                            st.success(f"ğŸ† {len(documents)}ê°œì˜ ìµœê³ í’ˆì§ˆ {st.session_state.search_type} ë¬¸ì„œ ì„ ë³„ ì™„ë£Œ! (Premium: {premium_count}ê°œ, Standard: {standard_count}ê°œ, Basic: {basic_count}ê°œ)")
                            
                            # ê²€ìƒ‰ëœ ë¬¸ì„œ í‘œì‹œ
                            with st.expander(f"ğŸ” ì„ ë³„ëœ ê³ í’ˆì§ˆ {st.session_state.search_type} ë¬¸ì„œ ë³´ê¸°"):
                                display_documents_with_quality_info(documents)
                            
                            # RAG ì‘ë‹µ ìƒì„±
                            with st.spinner(f"ğŸ’¡ ë™ì  í’ˆì§ˆ ê¸°ë°˜ ì •í™•í•œ {st.session_state.search_type} ë‹µë³€ ìƒì„± ì¤‘..."):
                                response = generate_rag_response_with_reranker(
                                    azure_openai_client, query, documents, azure_openai_model, query_type
                                )
                                
                                with st.expander(f"ğŸ¤– AI {st.session_state.search_type} ë‹µë³€ ë³´ê¸° (ë™ì  í’ˆì§ˆ ê°•í™”)", expanded=True):
                                    st.write(response)
                                    st.info(f"âœ¨ ì´ ë‹µë³€ì€ {st.session_state.search_type} ì¿¼ë¦¬ íŠ¹ì„±ì— ë§ëŠ” ë™ì  í’ˆì§ˆ ê¸°ì¤€ìœ¼ë¡œ ì„ ë³„ëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
                                
                                st.session_state.messages.append({"role": "assistant", "content": response})
                        else:
                            # ëŒ€ì²´ ê²€ìƒ‰ ì‹œë„
                            st.warning(f"ğŸ”„ ë™ì  ì„ê³„ê°’ìœ¼ë¡œë„ {st.session_state.search_type} ê²°ê³¼ê°€ ì—†ì–´ ë” ê´€ëŒ€í•œ ê¸°ì¤€ìœ¼ë¡œ ì¬ê²€ìƒ‰ ì¤‘...")
                            
                            # ë§¤ìš° ê´€ëŒ€í•œ ê¸°ì¤€ìœ¼ë¡œ ì¬ê²€ìƒ‰
                            fallback_documents = search_documents_fallback(current_search_client, query)
                            
                            if fallback_documents:
                                st.info(f"ğŸ“‹ ëŒ€ì²´ ê²€ìƒ‰ìœ¼ë¡œ {len(fallback_documents)}ê°œ {st.session_state.search_type} ë¬¸ì„œ ë°œê²¬")
                                response = generate_rag_response_with_reranker(
                                    azure_openai_client, query, fallback_documents, azure_openai_model, query_type
                                )
                                with st.expander(f"ğŸ¤– AI {st.session_state.search_type} ë‹µë³€ ë³´ê¸° (ëŒ€ì²´ ê²€ìƒ‰)", expanded=True):
                                    st.write(response)
                                    st.warning("âš ï¸ ì´ ë‹µë³€ì€ ê´€ëŒ€í•œ ê¸°ì¤€ìœ¼ë¡œ ì„ ë³„ëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
                                st.session_state.messages.append({"role": "assistant", "content": response})
                            else:
                                error_msg = f"""
                                ğŸ” ëª¨ë“  ê²€ìƒ‰ ê¸°ì¤€ìœ¼ë¡œë„ ê´€ë ¨ {st.session_state.search_type} ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
                                
                                **ê°œì„  ë°©ì•ˆ:**
                                - ë” êµ¬ì²´ì ì¸ í‚¤ì›Œë“œ ì‚¬ìš©
                                - ë‹¤ë¥¸ í‘œí˜„ìœ¼ë¡œ ì¬ê²€ìƒ‰
                                - ê²€ìƒ‰ ë²”ìœ„ í™•ëŒ€
                                - ë‹¤ë¥¸ ê²€ìƒ‰ íƒ€ì…({('ì´ìƒì§•í›„' if st.session_state.search_type == 'ì¥ì• ' else 'ì¥ì• ')}) ì‹œë„
                                """
                                with st.expander("ğŸ¤– AI ë‹µë³€ ë³´ê¸°", expanded=True):
                                    st.write(error_msg)
                                st.session_state.messages.append({"role": "assistant", "content": error_msg})
                                log_error("NoDocumentsFoundError", "No documents found after all search attempts", "process_query_with_reranker", f"query: {query[:100]}...")
            except Exception as e:
                log_error("ProcessQueryError", e, "process_query_with_reranker", f"query: {query[:100]}..., query_type: {query_type}")
                error_msg = f"ğŸš¨ ì¿¼ë¦¬ ì²˜ë¦¬ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                st.error(error_msg)
                with st.chat_message("assistant"):
                    with st.expander("ğŸ¤– AI ë‹µë³€ ë³´ê¸°", expanded=True):
                        st.write(error_msg)
                st.session_state.messages.append({"role": "assistant", "content": error_msg})
        
        # ì‚¬ìš©ì ì…ë ¥
        placeholder_text = "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: " + (
            "ë§ˆì´í˜ì´ì§€ ìµœê·¼ ì¥ì•  ë°œìƒì¼ìì™€ ì¥ì• ì›ì¸ ì•Œë ¤ì¤˜)" if st.session_state.search_type == "ì¥ì• " 
            else "ë§ˆì´í˜ì´ì§€ ìµœê·¼ ì´ìƒì§•í›„ì™€ ëŒ€ì‘ë°©ë²• ì•Œë ¤ì¤˜)"
        )
        user_query = st.chat_input(placeholder_text)
        
        if user_query:
            try:
                st.session_state.messages.append({"role": "user", "content": user_query})
                
                with st.chat_message("user"):
                    st.write(user_query)
                
                process_query_with_reranker(user_query, "default")
            except Exception as e:
                log_error("UserInputError", e, "user_query_processing", f"user_query: {user_query[:100]}...")
                st.error(f"ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

        # ì£¼ìš” ì§ˆë¬¸ ì²˜ë¦¬
        if 'sample_query' in st.session_state:
            try:
                query = st.session_state.sample_query
                query_type = st.session_state.get('query_type', 'default')
                
                del st.session_state.sample_query
                if 'query_type' in st.session_state:
                    del st.session_state.query_type
                
                st.session_state.messages.append({"role": "user", "content": query})
                
                with st.chat_message("user"):
                    st.write(query)
                
                process_query_with_reranker(query, query_type)
                st.rerun()
            except Exception as e:
                log_error("SampleQueryError", e, "sample_query_processing", f"sample_query: {st.session_state.get('sample_query', 'unknown')[:100]}...")
                st.error(f"ì£¼ìš” ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

    else:
        error_msg = "âŒ Azure ì„œë¹„ìŠ¤ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì˜¤ë¥˜ ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
        st.error(error_msg)
        log_error("InitializationError", "Failed to initialize Azure services", "main", "Check environment variables and credentials")

else:
    missing_vars = []
    if not azure_openai_endpoint: missing_vars.append("OPENAI_ENDPOINT")
    if not azure_openai_key: missing_vars.append("OPENAI_KEY")
    if not search_endpoint: missing_vars.append("SEARCH_ENDPOINT")
    if not search_key: missing_vars.append("SEARCH_API_KEY")
    if not incident_index: missing_vars.append("INDEX_SINGLE_NAME")
    
    error_msg = f"í™˜ê²½ë³€ìˆ˜ ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤: {', '.join(missing_vars)}"
    st.error(error_msg)
    log_error("EnvironmentError", error_msg, "main", f"Missing variables: {missing_vars}")

# í•˜ë‹¨ì— ì˜¤ë¥˜ ë¡œê·¸ ìš”ì•½ ì •ë³´ í‘œì‹œ (ì‚¬ì´ë“œë°”)
if st.session_state.error_logs:
    with st.sidebar:
        st.header("ğŸš¨ ì˜¤ë¥˜ ëª¨ë‹ˆí„°ë§")
        recent_errors = st.session_state.error_logs[-5:]  # ìµœê·¼ 5ê°œë§Œ
        
        for i, log in enumerate(reversed(recent_errors)):
            st.error(f"**{log['error_type']}** ({log['timestamp'][-8:]})")
            if st.button(f"ìƒì„¸ë³´ê¸° #{len(recent_errors)-i}", key=f"sidebar_error_{len(recent_errors)-i}"):
                st.session_state.show_error_logs = True
                st.rerun()
        
        if len(st.session_state.error_logs) > 5:
            st.info(f"+ {len(st.session_state.error_logs) - 5}ê°œ ë” ìˆìŒ")
            
        # ì˜¤ë¥˜ í†µê³„
        error_types = {}
        for log in st.session_state.error_logs:
            error_type = log['error_type']
            error_types[error_type] = error_types.get(error_type, 0) + 1
        
        st.write("**ì˜¤ë¥˜ í†µê³„:**")
        for error_type, count in error_types.items():
            st.write(f"- {error_type}: {count}íšŒ")
            
        # ì˜¤ë¥˜ ë¡œê·¸ ë¹ ë¥¸ ì•¡ì…˜
        if st.button("ğŸ”„ í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨", key="sidebar_refresh"):
            st.rerun()
            
        if st.button("ğŸ“‹ ì „ì²´ ë¡œê·¸ ë³´ê¸°", key="sidebar_show_all"):
            st.session_state.show_error_logs = True
            st.rerun()
            
        if st.button("ğŸ—‘ï¸ ë¡œê·¸ ì´ˆê¸°í™”", key="sidebar_clear"):
            st.session_state.error_logs = []
            st.success("âœ… ë¡œê·¸ ì´ˆê¸°í™”ë¨")
            st.rerun()

# ì˜¤ë¥˜ ë¡œê·¸ í‘œì‹œ ì˜ì—­ (ë©”ì¸ í™”ë©´ì— ì¶”ê°€)
if st.session_state.show_error_logs:
    with st.container():
        st.header("ğŸš¨ ì˜¤ë¥˜ ë¡œê·¸ ìƒì„¸ë³´ê¸°")
        
        # ë‹«ê¸° ë²„íŠ¼ ì¶”ê°€
        col1, col2 = st.columns([1, 4])
        with col1:
            if st.button("âŒ ë‹«ê¸°", key="close_error_logs"):
                st.session_state.show_error_logs = False
                st.rerun()
        
        display_error_logs()
        st.markdown("---")