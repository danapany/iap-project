import os
from dotenv import load_dotenv
import streamlit as st
import sqlite3
import email
from email import policy
from email.message import EmailMessage
from azure.storage.blob import BlobServiceClient, generate_blob_sas, BlobSasPermissions
import datetime
import pytz
from io import StringIO
import tempfile
import pandas as pd
from docx import Document
from docx.shared import Pt
from docx.enum.text import WD_PARAGRAPH_ALIGNMENT
from openai import AzureOpenAI
import json
import re
import base64  # ì¶”ê°€ëœ import

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë°ì´í„° ìºì‹œ ë¹„ìš°ê¸°
st.cache_data.clear()
st.cache_resource.clear()

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì„¤ì • ê°’ ì§ì ‘ ê°€ì ¸ì˜¤ê¸°
STORAGE_CONN_STR = os.getenv("STORAGE_CONN_STR")
STORAGE_ACCOUNT_NAME = os.getenv("STORAGE_ACCOUNT_NAME")
EML_CONTAINER_NAME = os.getenv("EML_CONTAINER_NAME")
WORD_CONTAINER_NAME = os.getenv("WORD_CONTAINER_NAME")
DB_BASE_PATH = os.getenv("DB_BASE_PATH")

# ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ ê²½ë¡œ êµ¬ì„±
if DB_BASE_PATH:
    # DB_BASE_PATHê°€ ìˆìœ¼ë©´ í•´ë‹¹ ê²½ë¡œì— eml_reports.db íŒŒì¼ ìƒì„±
    EML_DB_PATH = os.path.join(DB_BASE_PATH, "eml_reports.db")
    # ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
    os.makedirs(DB_BASE_PATH, exist_ok=True)
else:
    # DB_BASE_PATHê°€ ì—†ìœ¼ë©´ í˜„ì¬ ë””ë ‰í† ë¦¬ì— ìƒì„±
    EML_DB_PATH = "eml_reports.db"

# OpenAI ì„¤ì •
openai_endpoint = os.getenv("OPENAI_ENDPOINT")
openai_api_key = os.getenv("OPENAI_KEY")
openai_model = os.getenv("OPENAI_MODEL")
chat_model = os.getenv("CHAT_MODEL3")

# í™˜ê²½ ë³€ìˆ˜ ìœ íš¨ì„± ê²€ì‚¬
required_env_vars = {
    "STORAGE_CONN_STR": STORAGE_CONN_STR,
    "STORAGE_ACCOUNT_NAME": STORAGE_ACCOUNT_NAME,
    "EML_CONTAINER_NAME": EML_CONTAINER_NAME,
    "DB_BASE_PATH": DB_BASE_PATH
}

# í•œêµ­ ì‹œê°„ëŒ€ ì„¤ì •
korea_tz = pytz.timezone('Asia/Seoul')
current_time = datetime.datetime.now(korea_tz)

# ëˆ„ë½ëœ í™˜ê²½ ë³€ìˆ˜ í™•ì¸
missing_vars = [var for var, value in required_env_vars.items() if not value]

def validate_connection_string(connection_string):
    """ì—°ê²° ë¬¸ìì—´ ìœ íš¨ì„± ê²€ì‚¬"""
    if not connection_string:
        return False, "ì—°ê²° ë¬¸ìì—´ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."
    
    # ê¸°ë³¸ì ì¸ Azure Storage ì—°ê²° ë¬¸ìì—´ í˜•ì‹ í™•ì¸
    required_parts = ['AccountName=', 'AccountKey=']
    missing_parts = [part for part in required_parts if part not in connection_string]
    
    if missing_parts:
        return False, f"ì—°ê²° ë¬¸ìì—´ì— í•„ìˆ˜ ìš”ì†Œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {', '.join(missing_parts)}"
    
    return True, "ìœ íš¨í•œ ì—°ê²° ë¬¸ìì—´ì…ë‹ˆë‹¤."

def test_azure_connection():
    """Azure Storage ì—°ê²° í…ŒìŠ¤íŠ¸"""
    if not STORAGE_CONN_STR:
        return False, "ì—°ê²° ë¬¸ìì—´ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    try:
        # ì—°ê²° ë¬¸ìì—´ ìœ íš¨ì„± ê²€ì‚¬
        is_valid, message = validate_connection_string(STORAGE_CONN_STR)
        if not is_valid:
            return False, message
        
        # ì‹¤ì œ ì—°ê²° í…ŒìŠ¤íŠ¸
        blob_service_client = BlobServiceClient.from_connection_string(STORAGE_CONN_STR)
        
        # ì»¨í…Œì´ë„ˆ ì¡´ì¬ í™•ì¸ (ì—†ìœ¼ë©´ ìƒì„±)
        try:
            container_client = blob_service_client.get_container_client(EML_CONTAINER_NAME)
            container_client.get_container_properties()
        except Exception as e:
            if "ContainerNotFound" in str(e):
                # ì»¨í…Œì´ë„ˆê°€ ì—†ìœ¼ë©´ ìƒì„±
                container_client.create_container()
                return True, "ì—°ê²° ì„±ê³µ ë° ì»¨í…Œì´ë„ˆ ìƒì„± ì™„ë£Œ"
            else:
                return False, f"ì»¨í…Œì´ë„ˆ ì ‘ê·¼ ì˜¤ë¥˜: {str(e)}"
        
        return True, "ì—°ê²° ì„±ê³µ"
    except Exception as e:
        return False, f"ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}"

def init_database():
    """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ë° í…Œì´ë¸” ìƒì„±"""
    try:
        conn = sqlite3.connect(EML_DB_PATH)
        cursor = conn.cursor()
        
        # í…Œì´ë¸” ìƒì„± SQL
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS eml_reports (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                original_filename TEXT NOT NULL,
                blob_name TEXT NOT NULL,
                subject TEXT,
                sender TEXT,
                recipient TEXT,
                date_sent TEXT,
                body_text TEXT,
                body_html TEXT,
                attachments TEXT,
                file_size INTEGER,
                upload_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        conn.commit()
        conn.close()
        return True, f"ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì„±ê³µ (ê²½ë¡œ: {EML_DB_PATH})"
    except Exception as e:
        return False, f"ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}"

def insert_eml_data(parsed_data, original_filename, blob_name, file_size):
    """EML ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì‚½ì…"""
    try:
        conn = sqlite3.connect(EML_DB_PATH)
        cursor = conn.cursor()
        
        # ì²¨ë¶€íŒŒì¼ ë¦¬ìŠ¤íŠ¸ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        attachments_str = ', '.join(parsed_data['attachments']) if parsed_data['attachments'] else ''
        
        # ë°ì´í„° ì‚½ì…
        cursor.execute('''
            INSERT INTO eml_reports (
                original_filename, blob_name, subject, sender, recipient, 
                date_sent, body_text, body_html, attachments, file_size
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            original_filename,
            blob_name,
            parsed_data['subject'],
            parsed_data['from'],
            parsed_data['to'],
            parsed_data['date'],
            parsed_data['body_text'],
            parsed_data['body_html'],
            attachments_str,
            file_size
        ))
        
        record_id = cursor.lastrowid
        conn.commit()
        conn.close()
        
        return True, record_id, None
    except Exception as e:
        return False, None, f"ë°ì´í„°ë² ì´ìŠ¤ ì‚½ì… ì‹¤íŒ¨: {str(e)}"

def get_eml_record(record_id):
    """íŠ¹ì • IDì˜ EML ë ˆì½”ë“œ ì¡°íšŒ"""
    try:
        conn = sqlite3.connect(EML_DB_PATH)
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT * FROM eml_reports WHERE id = ?
        ''', (record_id,))
        
        record = cursor.fetchone()
        conn.close()
        
        if record:
            # ì»¬ëŸ¼ëª…ê³¼ í•¨ê»˜ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜
            columns = [desc[0] for desc in cursor.description]
            return dict(zip(columns, record))
        else:
            return None
    except Exception as e:
        st.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        return None

def get_eml_records():
    """EML ë ˆì½”ë“œ ì¡°íšŒ"""
    try:
        conn = sqlite3.connect(EML_DB_PATH)
        cursor = conn.cursor()
        cursor.execute('''
            SELECT id, original_filename, subject, body_text
            FROM eml_reports 
            WHERE body_text IS NOT NULL AND body_text != ''
            ORDER BY upload_time DESC
        ''')
        records = cursor.fetchall()
        conn.close()
        return records
    except Exception as e:
        st.error(f"DB ì˜¤ë¥˜: {e}")
        return []

def display_db_record(record):
    """ë°ì´í„°ë² ì´ìŠ¤ ë ˆì½”ë“œë¥¼ í™”ë©´ì— í‘œì‹œ"""
    st.subheader("ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ ë“±ë¡ ì •ë³´")
    
    # ê¸°ë³¸ ì •ë³´ë¥¼ ë‘ ì»¬ëŸ¼ìœ¼ë¡œ í‘œì‹œ
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**ğŸ“‹ ê¸°ë³¸ ì •ë³´**")
        st.write(f"â€¢ **ID**: {record['id']}")
        st.write(f"â€¢ **ì›ë³¸ íŒŒì¼ëª…**: {record['original_filename']}")
        st.write(f"â€¢ **ì €ì¥ëœ íŒŒì¼ëª…**: {record['blob_name']}")
        st.write(f"â€¢ **íŒŒì¼ í¬ê¸°**: {record['file_size']:,} bytes")
    
    with col2:
        st.write("**ğŸ“§ ì´ë©”ì¼ ì •ë³´**")
        st.write(f"â€¢ **ì œëª©**: {record['subject']}")
        st.write(f"â€¢ **ë°œì‹ ì**: {record['sender']}")
        st.write(f"â€¢ **ìˆ˜ì‹ ì**: {record['recipient']}")
        st.write(f"â€¢ **ë°œì†¡ì¼ì‹œ**: {record['date_sent']}")
    
    # ë³¸ë¬¸ ë‚´ìš©
    if record['body_text']:
        with st.expander("ğŸ“„ ë³¸ë¬¸ ë‚´ìš© ë³´ê¸°"):
            st.text_area("í…ìŠ¤íŠ¸ ë³¸ë¬¸", record['body_text'], height=200, disabled=True)
    
    # ì²¨ë¶€íŒŒì¼ ì •ë³´
    if record['attachments']:
        st.write("**ğŸ“ ì²¨ë¶€íŒŒì¼**")
        attachments = record['attachments'].split(', ')
        for attachment in attachments:
            st.write(f"  â€¢ {attachment}")
    
    # ë“±ë¡ ì‹œê°„
    st.write(f"**ğŸ• ë“±ë¡ ì‹œê°„**: {record['upload_time']}")

# parse_eml_file í•¨ìˆ˜ì˜ HTML ì²˜ë¦¬ ë¶€ë¶„ ìˆ˜ì • (ê¸°ì¡´ ë¼ì¸ 270-290 ë¶€ê·¼)
def parse_eml_file(eml_content):
    """EML íŒŒì¼ ë‚´ìš©ì„ íŒŒì‹±í•˜ì—¬ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë°˜í™˜ (HTML ì¤„ë°”ê¿ˆ ë³´ì¡´ ê°œì„ )"""
    try:
        # EML íŒŒì¼ íŒŒì‹±
        msg = email.message_from_string(eml_content, policy=policy.default)
        
        # ê¸°ë³¸ í—¤ë” ì •ë³´ ì¶”ì¶œ
        parsed_data = {
            'from': msg.get('From', ''),
            'to': msg.get('To', ''),
            'cc': msg.get('Cc', ''),
            'subject': msg.get('Subject', ''),
            'date': msg.get('Date', ''),
            'message_id': msg.get('Message-ID', ''),
            'body_text': '',
            'body_html': '',
            'attachments': []
        }
        
        # ë³¸ë¬¸ ë‚´ìš© ì¶”ì¶œ
        if msg.is_multipart():
            for part in msg.walk():
                content_type = part.get_content_type()
                content_disposition = str(part.get("Content-Disposition", ""))
                
                # ì²¨ë¶€íŒŒì¼ì´ ì•„ë‹Œ ê²½ìš°
                if "attachment" not in content_disposition:
                    if content_type == "text/plain":
                        try:
                            parsed_data['body_text'] = part.get_content()
                        except:
                            payload = part.get_payload(decode=True)
                            if payload:
                                parsed_data['body_text'] = payload.decode('utf-8', errors='ignore')
                    elif content_type == "text/html":
                        try:
                            parsed_data['body_html'] = part.get_content()
                        except:
                            payload = part.get_payload(decode=True)
                            if payload:
                                parsed_data['body_html'] = payload.decode('utf-8', errors='ignore')
                else:
                    # ì²¨ë¶€íŒŒì¼ ì •ë³´
                    filename = part.get_filename()
                    if filename:
                        parsed_data['attachments'].append(filename)
        else:
            # ë‹¨ì¼ íŒŒíŠ¸ ë©”ì‹œì§€ (Base64 UTF-8 ì²˜ë¦¬ ê°œì„ )
            content_type = msg.get_content_type()
            encoding = msg.get('Content-Transfer-Encoding', '').lower()
            
            if content_type == "text/plain":
                try:
                    parsed_data['body_text'] = msg.get_content()
                except Exception as e:
                    print(f"get_content() ì‹¤íŒ¨, ìˆ˜ë™ ë””ì½”ë”© ì‹œë„: {e}")
                    try:
                        if encoding == 'base64':
                            # Base64 í˜ì´ë¡œë“œ ì¶”ì¶œ ë° ì •ì œ
                            payload = msg.get_payload()
                            if payload:
                                # ì¤„ë°”ê¿ˆê³¼ ê³µë°± ì œê±°
                                clean_payload = payload.replace('\n', '').replace('\r', '').replace(' ', '')
                                # Base64 ë””ì½”ë”©
                                decoded_bytes = base64.b64decode(clean_payload)
                                # UTF-8ë¡œ ë””ì½”ë”©
                                parsed_data['body_text'] = decoded_bytes.decode('utf-8', errors='ignore')
                        else:
                            payload = msg.get_payload(decode=True)
                            if payload:
                                parsed_data['body_text'] = payload.decode('utf-8', errors='ignore')
                    except Exception as decode_error:
                        print(f"í…ìŠ¤íŠ¸ ë””ì½”ë”© ì˜¤ë¥˜: {decode_error}")
                        parsed_data['body_text'] = str(msg.get_payload())
                        
            elif content_type == "text/html":
                try:
                    parsed_data['body_html'] = msg.get_content()
                except Exception as e:
                    print(f"HTML get_content() ì‹¤íŒ¨, ìˆ˜ë™ ë””ì½”ë”© ì‹œë„: {e}")
                    try:
                        if encoding == 'base64':
                            # Base64 í˜ì´ë¡œë“œ ì¶”ì¶œ ë° ì •ì œ
                            payload = msg.get_payload()
                            if payload:
                                # ì¤„ë°”ê¿ˆê³¼ ê³µë°± ì œê±° (ë” ê°•ë ¥í•œ ì •ì œ)
                                clean_payload = payload.replace('\n', '').replace('\r', '').replace(' ', '')
                                # Base64 ë””ì½”ë”©
                                decoded_bytes = base64.b64decode(clean_payload)
                                # UTF-8ë¡œ ë””ì½”ë”©
                                parsed_data['body_html'] = decoded_bytes.decode('utf-8', errors='ignore')
                        else:
                            payload = msg.get_payload(decode=True)
                            if payload:
                                parsed_data['body_html'] = payload.decode('utf-8', errors='ignore')
                    except Exception as decode_error:
                        print(f"HTML ë””ì½”ë”© ì˜¤ë¥˜: {decode_error}")
                        parsed_data['body_html'] = str(msg.get_payload())
        
        # ğŸ¯ í•µì‹¬ ìˆ˜ì •: HTMLì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œ ì¤„ë°”ê¿ˆ ë³´ì¡´ (body_textê°€ ë¹„ì–´ìˆì„ ë•Œ)
        if not parsed_data['body_text'] and parsed_data['body_html']:
            try:
                import re
                html_text = parsed_data['body_html']
                
                # ğŸ”§ ê°œì„ ëœ HTML ì²˜ë¦¬ - ì¤„ë°”ê¿ˆ ë³´ì¡´
                # 1. HTML êµ¬ì¡°ì  ì¤„ë°”ê¿ˆì„ ì‹¤ì œ ì¤„ë°”ê¿ˆìœ¼ë¡œ ë³€í™˜
                html_text = re.sub(r'</p>\s*<p[^>]*>', '\n', html_text)  # </p><p> â†’ \n
                html_text = re.sub(r'<br\s*/?>', '\n', html_text)        # <br> â†’ \n
                html_text = re.sub(r'</div>\s*<div[^>]*>', '\n', html_text)  # </div><div> â†’ \n
                html_text = re.sub(r'</span>\s*<span[^>]*>', '\n', html_text)  # </span><span> â†’ \n (ì‹œê°„ êµ¬ë¶„ììš©)
                
                # 2. ê·¸ ë‹¤ìŒì— HTML íƒœê·¸ ì œê±°
                html_text = re.sub(r'<[^>]+>', '', html_text)
                
                # 3. HTML ì—”í‹°í‹° ì²˜ë¦¬
                html_text = html_text.replace('&nbsp;', ' ').replace('&lt;', '<').replace('&gt;', '>').replace('&amp;', '&')
                
                # 4. ì—°ì† ê³µë°±ì„ ë‹¨ì¼ ê³µë°±ìœ¼ë¡œ ë³€ê²½í•˜ë˜ ì¤„ë°”ê¿ˆì€ ë³´ì¡´
                html_text = re.sub(r'[ \t]+', ' ', html_text)  # íƒ­ê³¼ ê³µë°±ë§Œ ì •ë¦¬
                html_text = re.sub(r'\n\s*\n', '\n', html_text)  # ë¹ˆ ì¤„ ì •ë¦¬
                html_text = html_text.strip()
                
                parsed_data['body_text'] = html_text
                print(f"HTMLì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ (ì¤„ë°”ê¿ˆ ë³´ì¡´): {len(html_text)}ì")
                
                # ë””ë²„ê¹…: 14:32, 14:48 ê´€ë ¨ ì¤„ ìˆ˜ í™•ì¸
                debug_lines = [line for line in html_text.split('\n') if '14:32' in line or '14:48' in line]
                if debug_lines:
                    print(f"ğŸ” 14:32/14:48 ê´€ë ¨ ì¤„ ìˆ˜: {len(debug_lines)}")
                    for i, line in enumerate(debug_lines):
                        print(f"  ì¤„ {i+1}: {line[:100]}...")
                        
            except Exception as html_error:
                print(f"HTML í…ìŠ¤íŠ¸ ì¶”ì¶œ ì˜¤ë¥˜: {html_error}")
        
        # ì¶”ì¶œëœ í…ìŠ¤íŠ¸ í™•ì¸ìš© ë¡œê·¸ (ë””ë²„ê¹…ìš©)
        if parsed_data['body_text']:
            print(f"ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(parsed_data['body_text'])}ì")
            print(f"í…ìŠ¤íŠ¸ ì‹œì‘: {parsed_data['body_text'][:200]}...")
        
        return parsed_data, None
    except Exception as e:
        print(f"EML íŒŒì‹± ì „ì²´ ì˜¤ë¥˜: {str(e)}")
        return None, str(e)

def upload_to_azure_eml_blob(file_content, filename):
    """Azure Blob Storageì— íŒŒì¼ ì—…ë¡œë“œ"""
    try:
        if not STORAGE_CONN_STR:
            return False, None, "Azure Storage ì—°ê²° ë¬¸ìì—´ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        
        # ì—°ê²° ë¬¸ìì—´ ìœ íš¨ì„± ê²€ì‚¬
        is_valid, message = validate_connection_string(STORAGE_CONN_STR)
        if not is_valid:
            return False, None, f"ì—°ê²° ë¬¸ìì—´ ì˜¤ë¥˜: {message}"
        
        # Blob Service Client ìƒì„±
        blob_service_client = BlobServiceClient.from_connection_string(STORAGE_CONN_STR)
        
        # íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ í¬í•¨í•œ ê³ ìœ í•œ íŒŒì¼ëª… ìƒì„±
        timestamp = datetime.datetime.now(korea_tz).strftime("%Y%m%d_%H%M%S")
        blob_name = f"{timestamp}_{filename}"
        
        # ì»¨í…Œì´ë„ˆ ì¡´ì¬ í™•ì¸ ë° ìƒì„±
        try:
            container_client = blob_service_client.get_container_client(EML_CONTAINER_NAME)
            container_client.get_container_properties()
        except Exception as e:
            if "ContainerNotFound" in str(e):
                container_client.create_container()
        
        # Blob ì—…ë¡œë“œ
        blob_client = blob_service_client.get_blob_client(
            container=EML_CONTAINER_NAME, 
            blob=blob_name
        )
        
        # íŒŒì¼ ë‚´ìš©ì´ bytesê°€ ì•„ë‹Œ ê²½ìš° ë³€í™˜
        if isinstance(file_content, str):
            file_content = file_content.encode('utf-8')
        
        blob_client.upload_blob(file_content, overwrite=True)
        
        return True, blob_name, None
    except Exception as e:
        error_message = str(e)
        if "Connection string is either blank or malformed" in error_message:
            error_message = "Azure Storage ì—°ê²° ë¬¸ìì—´ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”."
        return False, None, error_message

def display_eml_content(parsed_data):
    """íŒŒì‹±ëœ EML ë°ì´í„°ë¥¼ ì‹œê°ì ìœ¼ë¡œ í‘œì‹œ"""
    st.subheader("ğŸ“§ ì´ë©”ì¼ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°")
    
    # ì œëª©ë§Œ í‘œì‹œ
    st.write("**ì œëª©:**")
    st.text(parsed_data['subject'])
    
    # ë³¸ë¬¸ ë‚´ìš© í‘œì‹œ
    st.write("**ë³¸ë¬¸:**")
    if parsed_data['body_text']:
        st.text_area(
            "í…ìŠ¤íŠ¸ ë³¸ë¬¸", 
            parsed_data['body_text'], 
            height=300,
            disabled=True
        )
    
    if parsed_data['body_html']:
        with st.expander("HTML ë³¸ë¬¸ ë³´ê¸°"):
            st.code(parsed_data['body_html'], language='html')
    
    # ì²¨ë¶€íŒŒì¼ ì •ë³´ í‘œì‹œ
    if parsed_data['attachments']:
        st.write("**ì²¨ë¶€íŒŒì¼:**")
        for attachment in parsed_data['attachments']:
            st.write(f"ğŸ“ {attachment}")

#í˜„ì¬ ì—°ë„ ì§€ì •ì„ ìœ„í•´ ì¶”ê°€
current_year = datetime.datetime.now(korea_tz).year

def extract_precise_data(body_text: str) -> dict:
    """EMLì—ì„œ ì •í™•í•œ ì •ë³´ë§Œ ì¶”ì¶œ (ì¤„ë³„ ì²˜ë¦¬ë¡œ ì¥ì•  ì¡°ì¹˜ ê²°ê³¼ ì¶”ì¶œ ê°•í™”)"""
    try:
        client = AzureOpenAI(
            azure_endpoint=openai_endpoint,
            api_key=openai_api_key,
            api_version="2024-02-15-preview"
        )
        
        # ğŸ¯ ì´ì¥ì‹œê°„ ì¶”ì¶œ ê°œì„  - AI ìš”ì²­ ì „ì— ì •ê·œì‹ìœ¼ë¡œ ë¯¸ë¦¬ ì¶”ì¶œ
        duration_extracted = extract_duration_patterns(body_text)
        
        prompt = f"""
ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ ì •í™•íˆ í™•ì¸í•  ìˆ˜ ìˆëŠ” ì •ë³´ë§Œ ì¶”ì¶œí•˜ì„¸ìš”. ë¶ˆí™•ì‹¤í•œ ì •ë³´ëŠ” "ì •ë³´ì—†ìŒ"ìœ¼ë¡œ í‘œì‹œí•˜ì„¸ìš”.
ì¤‘ìš”: ì—°ë„ê°€ ëª…ì‹œë˜ì§€ ì•Šì€ ëª¨ë“  ë‚ ì§œëŠ” {current_year}ë…„ìœ¼ë¡œ í•´ì„í•˜ì„¸ìš”.

íŠ¹ë³„íˆ ì£¼ì˜í•  ì :
1. "ì¥ì•  ì¡°ì¹˜ ê²°ê³¼" ë¶€ë¶„ì€ ì‹œê°„ìˆœìœ¼ë¡œ ë‚˜ì—´ëœ ëª¨ë“  í•­ëª©ì„ ë¹ ì§ì—†ì´ ì¶”ì¶œí•´ì•¼ í•©ë‹ˆë‹¤.
2. ë™ì¼í•œ ì‹œê°„(ì˜ˆ: 9:59, 12:32)ì— ì—¬ëŸ¬ í•­ëª©ì´ ìˆìœ¼ë©´ ëª¨ë‘ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
3. HH:MM í˜•ì‹ì˜ ì‹œê°„ ë’¤ì— ë‚˜ì˜¤ëŠ” ëª¨ë“  ì¡°ì¹˜ ë‚´ìš©ì„ ì™„ì „íˆ ì¶”ì¶œí•´ì•¼ í•©ë‹ˆë‹¤.

íŠ¹íˆ ë‹¤ìŒ ì •ë³´ë“¤ì„ ì •í™•íˆ ì¶”ì¶œí•˜ì„¸ìš”:
1. "ëŒ€ìƒì„œë¹„ìŠ¤"ë¼ëŠ” í‚¤ì›Œë“œ ë‹¤ìŒì— ë‚˜ì˜¤ëŠ” ì‹œìŠ¤í…œëª…ì„ ì •í™•íˆ ì¶”ì¶œ
2. "ìƒí™©ë°˜ì¥"ì´ë¼ëŠ” í‚¤ì›Œë“œ ë‹¤ìŒì— ë‚˜ì˜¤ëŠ” ë‹´ë‹¹ì ì •ë³´ ì „ì²´ë¥¼ ì¶”ì¶œ
3. "ë³µêµ¬ë°˜ì¥"ì´ë¼ëŠ” í‚¤ì›Œë“œ ë‹¤ìŒì— ë‚˜ì˜¤ëŠ” ë‹´ë‹¹ì ì •ë³´ì—ì„œ:
   - ì†Œì†ë¶€ì„œ (ì˜ˆ : "KTDS ICTì‚¬ì—…ë³¸ë¶€ ICIS Tr ì¶”ì§„ë‹´ë‹¹ ìœ ì„ ì˜¤ë”í†µí•©íŒ€")
   - ë‹´ë‹¹ìëª…ê³¼ ì§ê¸‰ (ì˜ˆ: "ì—¬ì¬ìœ¤ ì±…ì„")
4. "ì¥ì• í˜„ìƒ"ì´ë¼ëŠ” í‚¤ì›Œë“œ ë‹¤ìŒì— ë‚˜ì˜¤ëŠ” ì¥ì•  í˜„ìƒ ì„¤ëª…ê³¼ ìš”ì•½ ì •ë³´
5. "ì¥ì• ì‹œê°„"ì´ë¼ëŠ” í‚¤ì›Œë“œ ë‹¤ìŒì— ë‚˜ì˜¤ëŠ” ê´„í˜¸ ì•ˆì˜ ì‹œê°„ ì •ë³´ (ë‹¤ì–‘í•œ íŒ¨í„´ ì§€ì›)
6. "ì¥ì•  ì¡°ì¹˜ ê²°ê³¼"ë¼ëŠ” í‚¤ì›Œë“œ ë‹¤ìŒì— ë‚˜ì˜¤ëŠ” ì¥ì•  ì¡°ì¹˜ ê²°ê³¼ HH:MM : ë‚´ìš© íŒ¨í„´ì˜ ë°˜ë³µ ì •ë³´ (ë°˜ë“œì‹œ ëˆ„ë½ì—†ì´ ì „ì²´ ì¶”ì¶œí• ê²ƒ)
7. "ì¥ì• ì›ì¸"ì´ë¼ëŠ” í‚¤ì›Œë“œ ë‹¤ìŒì— ë‚˜ì˜¤ëŠ” ì¥ì•  ì›ì¸ ë¶„ì„ ì •ë³´

ğŸ¯ ì´ì¥ì‹œê°„ ì¶”ì¶œ ê°œì„ ì‚¬í•­:
- ë¯¸ë¦¬ ì¶”ì¶œëœ ì´ì¥ì‹œê°„: {duration_extracted}
- ì´ ê°’ì´ ìœ íš¨í•˜ë©´ ìš°ì„  ì‚¬ìš©í•˜ê³ , ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸ì—ì„œ ì¬ì¶”ì¶œ

ì˜ˆì‹œ:
- "ã…‡ ëŒ€ìƒì„œë¹„ìŠ¤ : KOS-ì˜¤ë”(KOS-Internet)" â†’ ì‹œìŠ¤í…œëª…: "KOS-ì˜¤ë”(KOS-Internet)"
- "ìƒí™©ë°˜ì¥ kt ds AXì‚¬ì—…ê°œë°œë³¸ë¶€ BAì»¨ì„¤íŒ…ë‹´ë‹¹ ICTì»¨ì„¤íŒ…íŒ€ ìœ¤ì˜ì˜ ì±…ì„" â†’ ìƒí™©ë°˜ì¥: "ktds AXì‚¬ì—…ê°œë°œë³¸ë¶€ BAì»¨ì„¤íŒ…ë‹´ë‹¹ ICTì»¨ì„¤íŒ…íŒ€ ìœ¤ì˜ì˜ ì±…ì„"
- "ë³µêµ¬ë°˜ì¥ ktds ICTì‚¬ì—…ë³¸ë¶€ ICIS Tr ì¶”ì§„ë‹´ë‹¹ ìœ ì„ ì˜¤ë”í†µí•©íŒ€ ì—¬ì¬ìœ¤ ì±…ì„" â†’ 
  ë³µêµ¬ë°˜ì¥_ì†Œì†: "ktds ICTì‚¬ì—…ë³¸ë¶€ ICIS Tr ì¶”ì§„ë‹´ë‹¹ ìœ ì„ ì˜¤ë”í†µí•©íŒ€"
  ë³µêµ¬ë°˜ì¥: "ì—¬ì¬ìœ¤ ì±…ì„"
  ë³¸ë¶€ì´í•˜_ì†Œì† : "ICTì‚¬ì—…ë³¸ë¶€ ICIS Trì¶”ì§„ë‹´ë‹¹ ìœ ì„ ì˜¤ë”í†µí•©íŒ€"
- "ì¥ì• í˜„ìƒ : KOS-ì˜¤ë” ì„œë¹„ìŠ¤ ì¥ì• " â†’ ì¥ì• í˜„ìƒ: "KOS-ì˜¤ë” ì„œë¹„ìŠ¤ ì¥ì• "
- "ì¥ì• ì‹œê°„ : 04/28 14:16 ~ 15:58 (102ë¶„)" â†’ ì´ì¥ì‹œê°„: "(102ë¶„)" 
- "ì¥ì• í˜„ìƒ : KOS-ì˜¤ë” ì„œë¹„ìŠ¤ ì¥ì• ë¡œ ì¸í•œ ì£¼ë¬¸ ì ‘ìˆ˜ ë¶ˆê°€ í˜„ìƒ ë°œìƒ" â†’ ì¥ì• _ì œëª©: "KOS-ì˜¤ë” ì„œë¹„ìŠ¤ ì¥ì• ë¡œ ì¸í•œ ì£¼ë¬¸ ì ‘ìˆ˜ ë¶ˆê°€"
- ì¥ì•  ì¡°ì¹˜ ê²°ê³¼ì—ì„œ ë‹¤ìŒê³¼ ê°™ì€ íŒ¨í„´ë“¤ì„ ëª¨ë‘ ì°¾ì•„ì„œ ì¶”ì¶œ:
  "09:59 ìµœì´ˆ ë°œê²¬", "10:20 ì˜ì—­ë„ ì„¸ì¢…ì‹œ ì—¬ë¯¼ì „ ì„œë¹„ìŠ¤ ì•± ì ‘ì† ë° ì¶©ì „ ë¶ˆê°€", "11:42 ì¶©ì „ ì¤‘ì§€ì—†ì´ í˜„ìƒíƒœ ìœ ì§€", "12:00 ë³µêµ¬ì˜ˆìƒì‹œê°„ 13:00ë¡œ í˜‘ì˜" ë“±
  â†’ "ì¥ì• _ì¡°ì¹˜_ê²½ê³¼_ë¦¬ìŠ¤íŠ¸": [
    {{"ì‹œê°„": "09:59", "ë‚´ìš©": "ìµœì´ˆ ë°œê²¬", "ë¹„ê³ ": ""}},
    {{"ì‹œê°„": "10:20", "ë‚´ìš©": "ì˜ì—­ë„ ì„¸ì¢…ì‹œ ì—¬ë¯¼ì „ ì„œë¹„ìŠ¤ ì•± ì ‘ì† ë° ì¶©ì „ ë¶ˆê°€", "ë¹„ê³ ": ""}},
    {{"ì‹œê°„": "11:42", "ë‚´ìš©": "ì¶©ì „ ì¤‘ì§€ì—†ì´ í˜„ìƒíƒœ ìœ ì§€í•˜ê¸°ë¡œí•¨(ìœµí•©ì„œë¹„ìŠ¤í”Œë«í¼íŒ€)", "ë¹„ê³ ": ""}},
    {{"ì‹œê°„": "12:00", "ë‚´ìš©": "ë³µêµ¬ì˜ˆìƒì‹œê°„ 13:00ë¡œ ì„¸ì¢…ì‹œì— í˜‘ì˜ë¨(ìœµí•©ì„œë¹„ìŠ¤í”Œë«í¼íŒ€,ê²°ì œ/ì„¼ì‹±ì„œë¹„ìŠ¤íŒ€)", "ë¹„ê³ ": ""}}
]

{body_text}

JSON ì‘ë‹µ:
{{
    "ì¥ì• _ì œëª©": "ì¥ì• í˜„ìƒ ìš”ì•½ ì •ë³´(ë¬¸ì¥ ë’¤ìª½ í˜„ìƒ, ë°œìƒ ë“±ì„ ì œì™¸í•œ ìš”ì•½ ì •ë³´)",
    "ì‹œìŠ¤í…œëª…": "ëŒ€ìƒì„œë¹„ìŠ¤ ë’¤ì— ë‚˜ì˜¤ëŠ” ì •í™•í•œ ì‹œìŠ¤í…œëª…",
    "ì¥ì• _ë“±ê¸‰": "ëª…ì‹œëœ ë“±ê¸‰ë§Œ",
    "ë°œìƒ_ì‹œê°„": "ì •í™•í•œ ë‚ ì§œ/ì‹œê°„ë§Œ ({current_year}ë…„ MMì›” DDì¼ HH:MM í˜•ì‹)",
    "ì¸ì§€_ì‹œê°„": "ì •í™•í•œ ì¸ì§€ ì‹œê°„ë§Œ",
    "ë³µêµ¬_ì‹œê°„": "ì •í™•í•œ ë³µêµ¬ ì‹œê°„ë§Œ ({current_year}ë…„ MMì›” DDì¼ HH:MM í˜•ì‹)",
    "ì´ì¥_ì‹œê°„": "ì •í™•í•œ ì´ì¥ ì‹œê°„ë§Œ - ë¯¸ë¦¬ ì¶”ì¶œëœ ê°’ ìš°ì„  ì‚¬ìš©: {duration_extracted}",
    "ì¥ì• _í˜„ìƒ": "ëª…í™•í•œ í˜„ìƒ ì„¤ëª…ë§Œ",
    "íŒŒê¸‰_ì˜í–¥": "ëª…í™•í•œ ì˜í–¥ ì„¤ëª…ë§Œ",
    "ê·¼ë³¸_ì›ì¸": "ëª…í™•í•œ ì›ì¸ ë¶„ì„ë§Œ",
    "ìƒí™©ë°˜ì¥": "ìƒí™©ë°˜ì¥ ì „ì²´ ì •ë³´",
    "ë³µêµ¬ë°˜ì¥_ì†Œì†": "ë³µêµ¬ë°˜ì¥ì˜ ì†Œì†ë¶€ì„œë§Œ (ë³µêµ¬ë°˜ì¥ì˜ ì´ë¦„ê³¼ ì§ê¸‰ ì œì™¸)",
    "ë³µêµ¬ë°˜ì¥": "ë³µêµ¬ë°˜ì¥ì˜ ì´ë¦„ê³¼ ì§ê¸‰ë§Œ",
    "ë³¸ë¶€ì´í•˜_ì†Œì†": "íšŒì‚¬(KTDS)ë¥¼ ì œì™¸í•œ ë³µêµ¬ë°˜ì¥ ì†Œì† ì •ë³´(ã…‡ã…‡ã…‡ë³¸ë¶€ ã…‡ã…‡ã…‡ë‹´ë‹¹ ã…‡ã…‡ã…‡íŒ€)",
    "ì¥ì• _ì¡°ì¹˜_ê²½ê³¼_ë¦¬ìŠ¤íŠ¸": [
        {{"ì‹œê°„": "HH:MM", "ë‚´ìš©": "ì‘ì—… ë‚´ìš©/í˜„ìƒ", "ë¹„ê³ ": ""}},
        {{"ì‹œê°„": "HH:MM", "ë‚´ìš©": "ì‘ì—… ë‚´ìš©/í˜„ìƒ", "ë¹„ê³ ": ""}}
    ]
}}

ë¶ˆí™•ì‹¤í•˜ë©´ "ì •ë³´ì—†ìŒ"ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”.
"""
        
        response = client.chat.completions.create(
            model=chat_model,
            messages=[
                {"role": "system", "content": "ì •í™•í•œ ì •ë³´ë§Œ ì¶”ì¶œí•˜ëŠ” ì „ë¬¸ê°€. íŠ¹íˆ 'ì¥ì•  ì¡°ì¹˜ ê²°ê³¼' ë¶€ë¶„ì—ì„œ ì‹œê°„ìˆœìœ¼ë¡œ ë‚˜ì—´ëœ ëª¨ë“  í•­ëª©ì„ ë¹ ëœ¨ë¦¬ì§€ ì•Šê³  ì¶”ì¶œí•˜ë©°, ë™ì¼ ì‹œê°„ëŒ€ì˜ ì—¬ëŸ¬ í•­ëª©ë„ ëª¨ë‘ í¬í•¨í•¨. 'ëŒ€ìƒì„œë¹„ìŠ¤', 'ìƒí™©ë°˜ì¥', 'ë³µêµ¬ë°˜ì¥', 'ì¥ì• í˜„ìƒ' ë“± í‚¤ì›Œë“œ ë’¤ì˜ ì •ë³´ë¥¼ ì •í™•íˆ ì°¾ì•„ì„œ ì¶”ì¶œí•¨."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=4000,
            temperature=0.0
        )
        
        result = response.choices[0].message.content.strip()
        if "```json" in result:
            start = result.find("```json") + 7
            end = result.rfind("```")
            result = result[start:end].strip()
        
        extracted_data = json.loads(result)
        
        # ğŸ¯ ì´ì¥ì‹œê°„ í›„ì²˜ë¦¬ - AIê°€ ì¶”ì¶œí•˜ì§€ ëª»í–ˆê±°ë‚˜ ì˜ëª» ì¶”ì¶œí•œ ê²½ìš° ì •ê·œì‹ ê²°ê³¼ë¡œ ë³´ì™„
        if duration_extracted and (not extracted_data.get("ì´ì¥_ì‹œê°„") or extracted_data.get("ì´ì¥_ì‹œê°„") == "ì •ë³´ì—†ìŒ"):
            extracted_data["ì´ì¥_ì‹œê°„"] = duration_extracted
            if 'extract_logs' not in st.session_state:
                st.session_state.extract_logs = []
            st.session_state.extract_logs.append(f"ğŸ¯ ì •ê·œì‹ìœ¼ë¡œ ì´ì¥ì‹œê°„ ë³´ì™„: {duration_extracted}")
        
        # ì •ê·œì‹ì„ ì´ìš©í•œ ê°•í™”ëœ ì¥ì•  ì¡°ì¹˜ ê²°ê³¼ ì¶”ì¶œ (ë°±ì—…) - ğŸ¯ ì¤„ë³„ ì²˜ë¦¬ë¡œ ê°œì„  
        if 'extract_logs' not in st.session_state:
            st.session_state.extract_logs = []
        
        st.session_state.extract_logs = []  # ë¡œê·¸ ì´ˆê¸°í™”
        
        # ì¥ì•  ì¡°ì¹˜ ê²°ê³¼ ì •ê·œì‹ ì¶”ì¶œ (ê°•í™”ëœ ë²„ì „ - ì¤„ë³„ ì²˜ë¦¬)
        action_pattern = r'ì¥ì• \s*ì¡°ì¹˜\s*ê²°ê³¼\s*[:ï¼š]\s*(.+?)(?:\n\n|\n[ê°€-í£]+\s*[:ï¼š]|ì¥ì• ì›ì¸|$)'
        action_match = re.search(action_pattern, body_text, re.DOTALL)
        
        if action_match:
            action_text = action_match.group(1).strip()
            st.session_state.extract_logs.append(f"ğŸ¯ ì¡°ì¹˜ ê²°ê³¼ í…ìŠ¤íŠ¸ ì¶”ì¶œ: {len(action_text)}ì")
            
            # ğŸ”§ ê°œì„ ëœ ì¤„ë³„ ì²˜ë¦¬ ë°©ì‹
            action_list_regex = []
            
            # ì¤„ë°”ê¿ˆìœ¼ë¡œ ë¶„í• í•˜ì—¬ ê° ì¤„ì„ ê°œë³„ ì²˜ë¦¬
            lines = action_text.split('\n')
            cleaned_lines = [line.strip() for line in lines if line.strip()]
            
            st.session_state.extract_logs.append(f"ğŸ” ì „ì²´ ì¤„ ìˆ˜: {len(cleaned_lines)}")
            
            # ê° ì¤„ì—ì„œ ì‹œê°„:ë‚´ìš© íŒ¨í„´ ì°¾ê¸°
            for line_idx, line in enumerate(cleaned_lines):
                # ì‹œê°„ íŒ¨í„´ ë§¤ì¹­ (ì¤„ ì‹œì‘ë¶€í„°)
                time_match = re.match(r'(\d{2}:\d{2})\s*(.+)', line)
                if time_match:
                    time_str = time_match.group(1)
                    content = time_match.group(2).strip()
                    
                    # ë‚´ìš© ì •ë¦¬ (ë¶ˆí•„ìš”í•œ ë¬¸ì ì œê±°)
                    content = content.replace(':', '').replace('ï¼š', '').strip()
                    
                    if content and len(content) > 2:
                        action_list_regex.append({
                            "ì‹œê°„": time_str,
                            "ë‚´ìš©": content,
                            "ë¹„ê³ ": ""
                        })
                        st.session_state.extract_logs.append(f"âœ… ì¤„ {line_idx+1}: {time_str} - {content[:50]}...")
                    else:
                        st.session_state.extract_logs.append(f"âš ï¸ ì¤„ {line_idx+1}: {time_str} - ë‚´ìš© ë¶€ì¡± ({content})")
            
            # 14:32, 14:48 ê´€ë ¨ ë””ë²„ê¹… ì •ë³´
            debug_lines = [line for line in cleaned_lines if '14:32' in line or '14:48' in line]
            if debug_lines:
                st.session_state.extract_logs.append(f"ğŸ” 14:32/14:48 ê´€ë ¨ ì¤„ ìˆ˜: {len(debug_lines)}")
                for i, line in enumerate(debug_lines):
                    st.session_state.extract_logs.append(f"  ë””ë²„ê·¸ ì¤„ {i+1}: {line}")
            
            # AI ì¶”ì¶œ ê²°ê³¼ì™€ ë¹„êµ
            ai_action_count = 0
            if extracted_data.get("ì¥ì• _ì¡°ì¹˜_ê²½ê³¼_ë¦¬ìŠ¤íŠ¸") and extracted_data["ì¥ì• _ì¡°ì¹˜_ê²½ê³¼_ë¦¬ìŠ¤íŠ¸"] != "ì •ë³´ì—†ìŒ":
                ai_action_count = len(extracted_data["ì¥ì• _ì¡°ì¹˜_ê²½ê³¼_ë¦¬ìŠ¤íŠ¸"])
            
            regex_action_count = len(action_list_regex)
            
            st.session_state.extract_logs.append(f"ğŸ” AI ì¶”ì¶œ: {ai_action_count}ê°œ, ì •ê·œì‹ ì¶”ì¶œ (ì¤„ë³„): {regex_action_count}ê°œ")
            
            # ì •ê·œì‹ ê²°ê³¼ê°€ ë” ë§ê±°ë‚˜ ê°™ìœ¼ë©´ ì •ê·œì‹ ê²°ê³¼ ì‚¬ìš©
            if regex_action_count >= ai_action_count:
                extracted_data["ì¥ì• _ì¡°ì¹˜_ê²½ê³¼_ë¦¬ìŠ¤íŠ¸"] = action_list_regex
                st.session_state.extract_logs.append(f"âœ… ì •ê·œì‹ ê²°ê³¼ ì‚¬ìš© (ì¤„ë³„ ì²˜ë¦¬): {regex_action_count}ê°œ í•­ëª©")
        
        # ì¶”ê°€ì ìœ¼ë¡œ ì •ê·œì‹ìœ¼ë¡œ ì§ì ‘ ì¶”ì¶œ (ê¸°ì¡´ ë°±ì—… ì½”ë“œë“¤)
        # ëŒ€ìƒì„œë¹„ìŠ¤ ì¶”ì¶œ
        service_pattern = r'ëŒ€ìƒì„œë¹„ìŠ¤\s*[:ï¼š]\s*(.+?)(?:\n|$)'
        service_match = re.search(service_pattern, body_text)
        if service_match:
            service_name = service_match.group(1).strip()
            if service_name and extracted_data.get("ì‹œìŠ¤í…œëª…") == "ì •ë³´ì—†ìŒ":
                extracted_data["ì‹œìŠ¤í…œëª…"] = service_name
                st.session_state.extract_logs.append(f"ğŸ¯ ì •ê·œì‹ìœ¼ë¡œ ì‹œìŠ¤í…œëª… ì¶”ì¶œ: {service_name}")
        
        # ìƒí™©ë°˜ì¥ ì¶”ì¶œ
        situation_pattern = r'ìƒí™©ë°˜ì¥\s*[:ï¼š]?\s*(.+?)(?:\n|ë³µêµ¬ë°˜ì¥|$)'
        situation_match = re.search(situation_pattern, body_text)
        if situation_match:
            situation_leader = situation_match.group(1).strip()
            if situation_leader and extracted_data.get("ìƒí™©ë°˜ì¥") == "ì •ë³´ì—†ìŒ":
                extracted_data["ìƒí™©ë°˜ì¥"] = situation_leader
                st.session_state.extract_logs.append(f"ğŸ¯ ì •ê·œì‹ìœ¼ë¡œ ìƒí™©ë°˜ì¥ ì¶”ì¶œ: {situation_leader}")
        
        # ë³µêµ¬ë°˜ì¥ ì¶”ì¶œ
        recovery_pattern = r'ë³µêµ¬ë°˜ì¥\s*[:ï¼š]?\s*(.+?)(?:\n|$)'
        recovery_match = re.search(recovery_pattern, body_text)
        if recovery_match:
            recovery_full = recovery_match.group(1).strip()
            if recovery_full:
                # ë³µêµ¬ë°˜ì¥ ì •ë³´ë¥¼ ì†Œì†ê³¼ ë‹´ë‹¹ìë¡œ ë¶„ë¦¬
                # ì¼ë°˜ì ìœ¼ë¡œ ë§ˆì§€ë§‰ ë‘ ë‹¨ì–´ê°€ "ì´ë¦„ ì§ê¸‰" í˜•íƒœ
                words = recovery_full.split()
                if len(words) >= 2:
                    # ë§ˆì§€ë§‰ ë‘ ë‹¨ì–´ë¥¼ ë‹´ë‹¹ìë¡œ, ë‚˜ë¨¸ì§€ë¥¼ ì†Œì†ìœ¼ë¡œ
                    recovery_person = " ".join(words[-2:])
                    recovery_dept = " ".join(words[:-2])
                    
                    if extracted_data.get("ë³µêµ¬ë°˜ì¥_ì†Œì†") == "ì •ë³´ì—†ìŒ":
                        extracted_data["ë³µêµ¬ë°˜ì¥_ì†Œì†"] = recovery_dept
                    if extracted_data.get("ë³µêµ¬ë°˜ì¥") == "ì •ë³´ì—†ìŒ":
                        extracted_data["ë³µêµ¬ë°˜ì¥"] = recovery_person
                    
                    st.session_state.extract_logs.append(f"ğŸ¯ ì •ê·œì‹ìœ¼ë¡œ ë³µêµ¬ë°˜ì¥ ë¶„ë¦¬: ì†Œì†={recovery_dept}, ë‹´ë‹¹ì={recovery_person}")
        
        # ì¥ì• í˜„ìƒ ì¶”ì¶œ
        incident_pattern = r'ì¥ì• í˜„ìƒ\s*[:ï¼š]\s*(.+?)(?:\n|$)'
        incident_match = re.search(incident_pattern, body_text)
        if incident_match:
            incident_symptom = incident_match.group(1).strip()
            if incident_symptom and extracted_data.get("ì¥ì• í˜„ìƒ") == "ì •ë³´ì—†ìŒ":
                extracted_data["ì¥ì• í˜„ìƒ"] = incident_symptom
                st.session_state.extract_logs.append(f"ğŸ¯ ì •ê·œì‹ìœ¼ë¡œ ì¥ì• í˜„ìƒ ì¶”ì¶œ: {incident_symptom}")

        return extracted_data
        
    except Exception as e:
        if 'extract_logs' not in st.session_state:
            st.session_state.extract_logs = []
        st.session_state.extract_logs.append(f"âŒ AI ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return {"error": "ì¶”ì¶œ ì‹¤íŒ¨"}
    
def extract_duration_patterns(body_text: str) -> str:
    """ë‹¤ì–‘í•œ ì´ì¥ì‹œê°„ íŒ¨í„´ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜"""
    try:
        # ğŸ¯ ê°œì„ ëœ ì´ì¥ì‹œê°„ ì¶”ì¶œ íŒ¨í„´ë“¤
        patterns = [
            # 1. ê´„í˜¸ ì•ˆì— ìˆ«ìì™€ ë¶„ì´ ìˆëŠ” íŒ¨í„´ (ê°€ì¥ ì¼ë°˜ì )
            r'\((\d+ë¶„)\)',                           # (6ë¶„)
            r'\(ì´ì¥ì‹œê°„\s*:?\s*(\d+ë¶„)\)',           # (ì´ì¥ì‹œê°„ 6ë¶„), (ì´ì¥ì‹œê°„: 6ë¶„)
            r'\(.*?(\d+ë¶„).*?\)',                     # (ê¸°íƒ€ í…ìŠ¤íŠ¸ 6ë¶„ ê¸°íƒ€)
            
            # 2. ì‹œê°„ ë²”ìœ„ì—ì„œ ë¶„ ê³„ì‚° (HH:MM ~ HH:MM í˜•íƒœ)
            r'(\d{2}:\d{2})\s*~\s*(\d{2}:\d{2})',    # 09:51 ~ 09:57
            
            # 3. ì¥ì• ì‹œê°„ í‚¤ì›Œë“œ ë’¤ì˜ ê´„í˜¸ íŒ¨í„´
            r'ì¥ì• ì‹œê°„.*?\(.*?(\d+ë¶„).*?\)',          # ì¥ì• ì‹œê°„ : ... (102ë¶„)
            r'ì´ì¥ì‹œê°„.*?\(.*?(\d+ë¶„).*?\)',          # ì´ì¥ì‹œê°„ : ... (6ë¶„)
            
            # 4. ê¸°íƒ€ ì‹œê°„ í‘œí˜„
            r'(\d+)ë¶„\s*ê°„',                         # 6ë¶„ê°„
            r'ì´\s*(\d+)ë¶„',                         # ì´ 6ë¶„
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, body_text, re.IGNORECASE)
            if matches:
                if len(matches[0]) == 2 and ':' in matches[0][0]:
                    # ì‹œê°„ ë²”ìœ„ íŒ¨í„´ì¸ ê²½ìš° (HH:MM ~ HH:MM)
                    start_time, end_time = matches[0]
                    try:
                        start_h, start_m = map(int, start_time.split(':'))
                        end_h, end_m = map(int, end_time.split(':'))
                        
                        start_total_minutes = start_h * 60 + start_m
                        end_total_minutes = end_h * 60 + end_m
                        
                        # ì‹œê°„ì´ ë‹¤ìŒë‚ ë¡œ ë„˜ì–´ê°„ ê²½ìš° ì²˜ë¦¬
                        if end_total_minutes < start_total_minutes:
                            end_total_minutes += 24 * 60
                        
                        duration_minutes = end_total_minutes - start_total_minutes
                        return f"({duration_minutes}ë¶„)"
                    except:
                        continue
                else:
                    # ë‹¤ë¥¸ íŒ¨í„´ë“¤ì˜ ê²½ìš°
                    duration = matches[0] if isinstance(matches[0], str) else matches[0][0]
                    if 'ë¶„' in duration:
                        return f"({duration})"
                    else:
                        return f"({duration}ë¶„)"
        
        return ""  # íŒ¨í„´ì„ ì°¾ì§€ ëª»í•œ ê²½ìš°
        
    except Exception as e:
        print(f"ì´ì¥ì‹œê°„ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return ""

def find_action_progress_table(doc):
    """ì¥ì•  ì¡°ì¹˜ ê²½ê³¼ í‘œ ì°¾ê¸°"""
    try:
        # ë¡œê·¸ ì €ì¥ì„ ìœ„í•œ session_state ì´ˆê¸°í™”
        if 'template_logs' not in st.session_state:
            st.session_state.template_logs = []
        
        for table_idx, table in enumerate(doc.tables):
            # ì²« ë²ˆì§¸ í–‰ì—ì„œ "ì¼ì‹œ", "ì‘ì—… ë‚´ìš©", "ë¹„ê³ " ê°™ì€ í—¤ë” ì°¾ê¸°
            if len(table.rows) > 0:
                header_row = table.rows[0]
                header_text = " ".join([cell.text.strip() for cell in header_row.cells])
                
                # ì¡°ì¹˜ ê²½ê³¼ ê´€ë ¨ í—¤ë” í‚¤ì›Œë“œë“¤
                progress_keywords = ["ì¼ì‹œ", "ì‹œê°„", "ì‘ì—…", "ë‚´ìš©", "í˜„ìƒ", "ë¹„ê³ ", "ê²½ê³¼"]
                matched_count = sum(1 for keyword in progress_keywords if keyword in header_text)
                
                if matched_count >= 2:  # ìµœì†Œ 2ê°œ í‚¤ì›Œë“œ ë§¤ì¹­ë˜ë©´ ì¡°ì¹˜ ê²½ê³¼ í‘œë¡œ íŒë‹¨
                    st.session_state.template_logs.append(f"ğŸ¯ ì¡°ì¹˜ ê²½ê³¼ í‘œ ë°œê²¬: í…Œì´ë¸” {table_idx} (í—¤ë”: {header_text})")
                    return table_idx, table
                    
        # í‚¤ì›Œë“œë¡œ ì°¾ì§€ ëª»í–ˆë‹¤ë©´ "ì¡°ì¹˜" í‚¤ì›Œë“œê°€ í¬í•¨ëœ í‘œ ì°¾ê¸°
        for table_idx, table in enumerate(doc.tables):
            for row in table.rows:
                for cell in row.cells:
                    if "ì¡°ì¹˜" in cell.text and ("ê²½ê³¼" in cell.text or "ê²°ê³¼" in cell.text):
                        st.session_state.template_logs.append(f"ğŸ¯ ì¡°ì¹˜ ê²½ê³¼ í‘œ ë°œê²¬ (í‚¤ì›Œë“œ ë§¤ì¹­): í…Œì´ë¸” {table_idx}")
                        return table_idx, table
                        
        return None, None
        
    except Exception as e:
        if 'template_logs' not in st.session_state:
            st.session_state.template_logs = []
        st.session_state.template_logs.append(f"âš ï¸ ì¡°ì¹˜ ê²½ê³¼ í‘œ ì°¾ê¸° ì˜¤ë¥˜: {e}")
        return None, None

def fill_action_progress_table(table, action_list):
    """ì¡°ì¹˜ ê²½ê³¼ í‘œì— ë°ì´í„° ì…ë ¥"""
    if not action_list or not table:
        return 0
    
    # ë¡œê·¸ ì €ì¥ì„ ìœ„í•œ session_state ì´ˆê¸°í™”
    if 'template_logs' not in st.session_state:
        st.session_state.template_logs = []
    
    filled_count = 0
    
    try:
        # í—¤ë” í–‰ì€ ê±´ë“œë¦¬ì§€ ì•Šê³ , ë‘ ë²ˆì§¸ í–‰ë¶€í„° ë°ì´í„° ì…ë ¥
        start_row = 1
        
        # í•„ìš”í•œ í–‰ ìˆ˜ ê³„ì‚°
        needed_rows = len(action_list)
        current_rows = len(table.rows)
        
        # í–‰ì´ ë¶€ì¡±í•˜ë©´ ì¶”ê°€
        if current_rows < needed_rows + start_row:
            rows_to_add = needed_rows + start_row - current_rows
            st.session_state.template_logs.append(f"ğŸ” ì¡°ì¹˜ ê²½ê³¼ í‘œì— {rows_to_add}ê°œ í–‰ ì¶”ê°€")
            
            for _ in range(rows_to_add):
                # ìƒˆ í–‰ ì¶”ê°€ (ì²« ë²ˆì§¸ í–‰ì˜ ì…€ ìˆ˜ë§Œí¼)
                new_row = table.add_row()
                filled_count += 1
        
        # ë°ì´í„° ì…ë ¥
        for idx, action_item in enumerate(action_list):
            row_idx = start_row + idx
            if row_idx < len(table.rows):
                row = table.rows[row_idx]
                
                # ê° ì…€ì— ë°ì´í„° ì…ë ¥ (ì‹œê°„, ë‚´ìš©, ë¹„ê³  ìˆœì„œ)
                if len(row.cells) >= 1:
                    row.cells[0].text = action_item.get("ì‹œê°„", "")
                if len(row.cells) >= 2:
                    row.cells[1].text = action_item.get("ë‚´ìš©", "")
                if len(row.cells) >= 3:
                    row.cells[2].text = action_item.get("ë¹„ê³ ", "")
                
                filled_count += 1
                st.session_state.template_logs.append(f"âœ… {action_item.get('ì‹œê°„')} - {action_item.get('ë‚´ìš©')}")
        
        return filled_count
        
    except Exception as e:
        st.session_state.template_logs.append(f"âŒ ì¡°ì¹˜ ê²½ê³¼ í‘œ ì…ë ¥ ì˜¤ë¥˜: {e}")
        return 0

def replace_placeholder_text(doc, placeholder, replacement):
    """ë¬¸ì„œ ì „ì²´ì—ì„œ í”Œë ˆì´ìŠ¤í™€ë”ë¥¼ ì°¾ì•„ì„œ êµì²´"""
    replaced_count = 0
    
    # ë¬¸ë‹¨ì—ì„œ êµì²´
    for paragraph in doc.paragraphs:
        if placeholder in paragraph.text:
            paragraph.text = paragraph.text.replace(placeholder, replacement)
            replaced_count += 1
    
    # í‘œì—ì„œ êµì²´
    for table in doc.tables:
        for row in table.rows:
            for cell in row.cells:
                if placeholder in cell.text:
                    cell.text = cell.text.replace(placeholder, replacement)
                    replaced_count += 1
    
    return replaced_count

def fill_template_safely(template_path: str, data: dict, record_id: int) -> str:
    """ì•ˆì „í•œ í…œí”Œë¦¿ ì±„ìš°ê¸° (ê°œì„ ëœ í‚¤ì›Œë“œ ê¸°ë°˜ ë°©ì‹)"""
    try:
        # ë¡œê·¸ ì €ì¥ì„ ìœ„í•œ session_state ì´ˆê¸°í™”
        if 'template_logs' not in st.session_state:
            st.session_state.template_logs = []
        
        st.session_state.template_logs = []  # ë¡œê·¸ ì´ˆê¸°í™”
        
        doc = Document(template_path)
        filled_count = 0
        
        # 1. ì‹œìŠ¤í…œëª… í”Œë ˆì´ìŠ¤í™€ë” êµì²´ (#ì„œë¹„ìŠ¤ëª… â†’ KOS-ì˜¤ë”(KOS-Internet))
        system_name = data.get("ì‹œìŠ¤í…œëª…", "")
        if system_name and system_name != "ì •ë³´ì—†ìŒ":
            replaced = replace_placeholder_text(doc, "(#ì„œë¹„ìŠ¤ëª…)", system_name)
            if replaced > 0:
                filled_count += replaced
                st.session_state.template_logs.append(f"ğŸ¯ ì‹œìŠ¤í…œëª… êµì²´ ì™„ë£Œ: (#ì„œë¹„ìŠ¤ëª…) â†’ {system_name} ({replaced}ê³³)")
            else:
                st.session_state.template_logs.append("âš ï¸ (#ì„œë¹„ìŠ¤ëª…) í”Œë ˆì´ìŠ¤í™€ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # 2. ê¸°íƒ€ í”Œë ˆì´ìŠ¤í™€ë”ë“¤ êµì²´ (ìƒí™©ë°˜ì¥ í¬í•¨)
        placeholder_mappings = {
            "(#ì¥ì• ë“±ê¸‰)": data.get("ì¥ì• _ë“±ê¸‰", ""),
            "(#ë°œìƒì‹œê°„)": data.get("ë°œìƒ_ì‹œê°„", ""),
            "(#ì¸ì§€ì‹œê°„)": data.get("ì¸ì§€_ì‹œê°„", ""),
            "(#ë³µêµ¬ì‹œê°„)": data.get("ë³µêµ¬_ì‹œê°„", ""),
            "(#ì´ì¥ì‹œê°„)": data.get("ì´ì¥_ì‹œê°„", ""),
            "(#ì†Œì†ë³¸ë¶€)": data.get("ì†Œì†_ë³¸ë¶€", ""),
            "(#ì†Œì†íŒ€)": data.get("ì†Œì†_íŒ€", ""),
            "(#ìƒí™©ë°˜ì¥)": data.get("ìƒí™©ë°˜ì¥", ""),
            "(#ë³µêµ¬ë°˜ì¥ ì†Œì†)": data.get("ë³µêµ¬ë°˜ì¥_ì†Œì†", ""),
            "(#ë³´ê³ ì ì†Œì†)": data.get("ë³¸ë¶€ì´í•˜_ì†Œì†", ""),
            "(#ë³µêµ¬ë°˜ì¥)": data.get("ë³µêµ¬ë°˜ì¥", ""),
            "(#ì¥ì• í˜„ìƒ)": data.get("ì¥ì• _í˜„ìƒ", ""),
            "(#ì¥ì• íŒŒê¸‰ì˜í–¥)": data.get("íŒŒê¸‰_ì˜í–¥", ""),
            "(#ì¥ì• ê·¼ë³¸ì›ì¸)": data.get("ê·¼ë³¸_ì›ì¸", ""),
        }
        
        for placeholder, value in placeholder_mappings.items():
            if value and value != "ì •ë³´ì—†ìŒ":
                replaced = replace_placeholder_text(doc, placeholder, value)
                if replaced > 0:
                    filled_count += replaced
                    st.session_state.template_logs.append(f"âœ… {placeholder} â†’ {value} ({replaced}ê³³)")
        
        # ìƒí™©ë°˜ì¥ ë³„ë„ ì²˜ë¦¬ (í”Œë ˆì´ìŠ¤í™€ë”ì™€ í‚¤ì›Œë“œ ë§¤ì¹­ ëª¨ë‘ ì‹œë„)
        situation_leader = data.get("ìƒí™©ë°˜ì¥", "")
        if situation_leader and situation_leader != "ì •ë³´ì—†ìŒ":
            # 1. í”Œë ˆì´ìŠ¤í™€ë” êµì²´ ì‹œë„
            replaced = replace_placeholder_text(doc, "(#ìƒí™©ë°˜ì¥)", situation_leader)
            if replaced > 0:
                filled_count += replaced
                st.session_state.template_logs.append(f"ğŸ¯ ìƒí™©ë°˜ì¥ í”Œë ˆì´ìŠ¤í™€ë” êµì²´: {situation_leader} ({replaced}ê³³)")
                    
        # 3. ìš´ì˜ë¶€ì„œì—ë„ ë³µêµ¬ë°˜ì¥ ì†Œì† ì •ë³´ ì…ë ¥ (ì¶”ê°€ ë³´ì¥)
        recovery_dept = data.get("ë³µêµ¬ë°˜ì¥_ì†Œì†", "")
        if recovery_dept and recovery_dept != "ì •ë³´ì—†ìŒ":
            # ìš´ì˜ë¶€ì„œ í”Œë ˆì´ìŠ¤í™€ë”ë„ ê°™ì€ ê°’ìœ¼ë¡œ êµì²´
            replaced = replace_placeholder_text(doc, "(#ìš´ì˜ë¶€ì„œ)", recovery_dept)
            if replaced > 0:
                filled_count += replaced
                st.session_state.template_logs.append(f"âœ… (#ìš´ì˜ë¶€ì„œ) â†’ {recovery_dept} ({replaced}ê³³)")

        # 4. ì œëª© ì…ë ¥ (ì²« ë²ˆì§¸ ë¬¸ë‹¨ì— ê°•ì œ ì…ë ¥)
        title = data.get("ì¥ì• _ì œëª©", "")
        if title and title != "ì •ë³´ì—†ìŒ":
            # ì²« ë²ˆì§¸ ë¬¸ë‹¨ì— ì œëª© ì…ë ¥ (ê¸°ì¡´ ë‚´ìš© ë®ì–´ì“°ê¸°)
            if len(doc.paragraphs) > 0:
                doc.paragraphs[0].text = title
                filled_count += 1
                st.session_state.template_logs.append(f"ğŸ¯ ì œëª© ì…ë ¥: {title}")
            else:
                # ë¬¸ë‹¨ì´ ì—†ìœ¼ë©´ ìƒˆë¡œ ì¶”ê°€
                new_para = doc.add_paragraph(title)
                doc._body._element.insert(0, new_para._element)
                filled_count += 1
                st.session_state.template_logs.append(f"ğŸ¯ ì œëª© ì¶”ê°€: {title}")
        
        # 5. ì†Œì† ì •ë³´ ì…ë ¥ (ë‘ ë²ˆì§¸ ë¬¸ë‹¨) - ìˆ˜ì •ëœ ë¶€ë¶„
        dept_text = ""
        if data.get("ë³¸ë¶€ì´í•˜_ì†Œì†") and data.get("ë³¸ë¶€ì´í•˜_ì†Œì†") != "ì •ë³´ì—†ìŒ":
            dept_text = data.get("ë³¸ë¶€ì´í•˜_ì†Œì†")  # ê³µë°± ì œê±°
        dept_text += f" ({current_time.strftime('%Y.%m.%d')})"
        
        # ë‘ ë²ˆì§¸ ë‚´ìš©ì´ ìˆëŠ” ë¬¸ë‹¨ì— ì…ë ¥ (ì„œì‹ ìœ ì§€)
        content_paras = [p for p in doc.paragraphs if p.text.strip()]
        if len(content_paras) >= 2:
            # ê¸°ì¡´ ì„œì‹ì„ ìœ ì§€í•˜ë©´ì„œ í…ìŠ¤íŠ¸ë§Œ êµì²´
            paragraph = content_paras[1]
            
            # ê¸°ì¡´ runë“¤ì„ ëª¨ë‘ ì œê±°í•˜ê³  ìƒˆë¡œìš´ run ì¶”ê°€
            for run in paragraph.runs:
                run._element.getparent().remove(run._element)
            
            # ìƒˆë¡œìš´ run ì¶”ê°€ (ê¸°ë³¸ ì„œì‹ ì ìš©)
            new_run = paragraph.add_run(dept_text)
            
            # í°íŠ¸ í¬ê¸°ì™€ êµµê¸° ì„¤ì • (í…œí”Œë¦¿ê³¼ ë™ì¼í•˜ê²Œ)
            new_run.font.size = Pt(10)  # í°íŠ¸ í¬ê¸° 10pt
            new_run.font.bold = False   # êµµê¸° ì œê±°
            
            filled_count += 1
            st.session_state.template_logs.append(f"ğŸ¯ ì†Œì† ì •ë³´ ì…ë ¥: {dept_text} (ì„œì‹ ì ìš©)")
        
        # 6. ì¥ì•  ì¡°ì¹˜ ê²½ê³¼ í‘œì— ë°ì´í„° ì…ë ¥
        action_list = data.get("ì¥ì• _ì¡°ì¹˜_ê²½ê³¼_ë¦¬ìŠ¤íŠ¸", [])
        if action_list and action_list != "ì •ë³´ì—†ìŒ":
            table_idx, action_table = find_action_progress_table(doc)
            if action_table:
                action_filled = fill_action_progress_table(action_table, action_list)
                filled_count += action_filled
                st.session_state.template_logs.append(f"ğŸ¯ ì¡°ì¹˜ ê²½ê³¼ í‘œ ì…ë ¥ ì™„ë£Œ: {len(action_list)}ê°œ í•­ëª©, {action_filled}ê°œ í–‰ ì²˜ë¦¬")
            else:
                st.session_state.template_logs.append("âš ï¸ ì¡°ì¹˜ ê²½ê³¼ í‘œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
        # 7. ìƒì„± ì •ë³´ ì¶”ê°€
        # doc.add_paragraph(f"\n[AI ìƒì„±: {current_time.strftime('%Y-%m-%d %H:%M:%S')} | ë ˆì½”ë“œ: {record_id} | ì…ë ¥: {filled_count}ê°œ]")
        
        # 8. ì €ì¥
        temp_path = tempfile.NamedTemporaryFile(delete=False, suffix=".docx").name
        doc.save(temp_path)
        
        st.session_state.template_logs.append(f"âœ… ì´ {filled_count}ê°œ í•„ë“œ ì…ë ¥ ì™„ë£Œ")
        return temp_path
        
    except Exception as e:
        if 'template_logs' not in st.session_state:
            st.session_state.template_logs = []
        st.session_state.template_logs.append(f"âŒ í…œí”Œë¦¿ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        raise Exception(f"í…œí”Œë¦¿ ì±„ìš°ê¸° ì‹¤íŒ¨: {e}")

def upload_to_azure_word(file_path: str, filename: str):
    """24ì‹œê°„ ìœ íš¨ Azure ì—…ë¡œë“œ"""
    try:
        blob_service_client = BlobServiceClient.from_connection_string(STORAGE_CONN_STR)
        timestamp = datetime.datetime.now(korea_tz).strftime("%Y%m%d_%H%M%S")
        blob_name = f"{timestamp}_{filename}"
        
        # ì—…ë¡œë“œ
        blob_client = blob_service_client.get_blob_client(container=WORD_CONTAINER_NAME, blob=blob_name)
        with open(file_path, "rb") as data:
            blob_client.upload_blob(data, overwrite=True)
        
        # 24ì‹œê°„ SAS í† í°
        account_key = STORAGE_CONN_STR.split('AccountKey=')[1].split(';')[0]
        sas_token = generate_blob_sas(
            account_name=STORAGE_ACCOUNT_NAME,
            container_name=WORD_CONTAINER_NAME,
            blob_name=blob_name,
            account_key=account_key,
            permission=BlobSasPermissions(read=True),
            expiry=datetime.datetime.now(korea_tz) + datetime.timedelta(hours=24)
        )
        
        url = f"https://{STORAGE_ACCOUNT_NAME}.blob.core.windows.net/{WORD_CONTAINER_NAME}/{blob_name}?{sas_token}"
        return True, url, None
        
    except Exception as e:
        return False, None, str(e)
    
##ë³´ê³ ì„œ(ì´ˆì•ˆ) í™œìš© ê°€ì´ë“œ
def show_completion_guide_simple():
    """ê°„ë‹¨í•œ ì™„ë£Œ ê°€ì´ë“œ í‘œì‹œ"""
    
    # ì£¼ì˜ì‚¬í•­
    st.warning("âš ï¸ **ì¤‘ìš” ì•ˆë‚´**\n\në³´ê³ ì„œëŠ” ì²¨ë¶€ ë³µêµ¬ë³´ê³ (eml) ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ AIê°€ ìë™ ìƒì„±í•œ ì´ˆì•ˆì…ë‹ˆë‹¤. ì´ˆì•ˆì— ì˜¤ë¥˜ê°€ ìˆì„ ìˆ˜ ìˆìœ¼ë‹ˆ ëª¨ë“  í•­ëª©ì„ ì‚¬ìš©ìê»˜ì„œ ì§ì ‘ í™•ì¸í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.")
        
    # ê°€ì´ë“œ ë‹¤ìš´ë¡œë“œ
    st.subheader("ğŸ“‹ ë³´ê³ ì„œ í™œìš© ê°€ì´ë“œ")
    st.info("Best Practiceë¥¼ ì œê³µí•˜ë‹ˆ ì²¨ë¶€ íŒŒì¼ì„ ì°¸ê³ í•˜ì„¸ìš”.")
    
    # ë¡œì»¬ íŒŒì¼ ê²½ë¡œ
    guide_path = "data/docx/20250320_ì¥ì• ë³´ê³ ì„œ_KT AICC ê³µê³µì§€ìì²´_ê³ ê°í¬í„¸ì ‘ì†ì§€ì—°ì¥ì• _v1.0.docx"
    guide_exists = os.path.exists(guide_path)
    
    col1, col2 = st.columns(2)
    with col1:
        if guide_exists:
            with open(guide_path, "rb") as file:
                st.download_button(
                    label="ğŸ“¥ ì¥ì• ì›ì¸ë¶„ì„ë³´ê³ ì„œ(BÂ·P) ë‹¤ìš´ë¡œë“œ",
                    data=file.read(),
                    file_name="20250320_ì¥ì• ë³´ê³ ì„œ_KT AICC ê³µê³µì§€ìì²´_ê³ ê°í¬í„¸ì ‘ì†ì§€ì—°ì¥ì• _v1.0.docx",
                    mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                )
        else:
            st.error("âš ï¸ ê°€ì´ë“œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    with col2:
        if st.button("ğŸ” ë¯¸ë¦¬ë³´ê¸°"):
            # ë¯¸ë¦¬ë³´ê¸° ì´ë¯¸ì§€ (ë¡œì»¬ íŒŒì¼ì´ ìˆë‹¤ê³  ê°€ì •)
            preview_image_path = "data/docx/guide-preview.png"
            if os.path.exists(preview_image_path):
                st.image(preview_image_path)
    st.divider()


# === Streamlit ì•± ===
st.title("ğŸ’¡ ì¥ì• ë³´ê³ ì„œ ì´ˆì•ˆ ìƒì„±ê¸°")
st.caption("ë³µêµ¬ë³´ê³ (eml)ì„ ì—…ë¡œë“œí•˜ë©´ ì¥ì• ë³´ê³ ì„œ ì´ˆì•ˆì„ ìƒì„± í•©ë‹ˆë‹¤")

# ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
db_success, db_message = init_database()

# Azure ì—°ê²° ìƒíƒœ í™•ì¸
connection_test_result, connection_message = test_azure_connection()

# ì „ì—­ ìƒíƒœ ì´ˆê¸°í™”
if 'stage' not in st.session_state:
    st.session_state.stage = 'upload'  # 'upload', 'processing', 'completed'

if 'current_record_id' not in st.session_state:
    st.session_state.current_record_id = None

if 'extracted' not in st.session_state:
    st.session_state.extracted = None

# í…œí”Œë¦¿ íŒŒì¼ í™•ì¸
template_path = "data/docx/iap-report-sample1(#).docx"
template_exists = os.path.exists(template_path)

# 1ë‹¨ê³„: EML íŒŒì¼ ì—…ë¡œë“œ
if st.session_state.stage == 'upload':
    st.subheader("ğŸ“ EML íŒŒì¼ ì—…ë¡œë“œ")
    
    uploaded_file = st.file_uploader(
        "ë³µêµ¬ë³´ê³ ì„œ EML íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”",
        type=['eml'],
        help="ë³µêµ¬ ë³´ê³ ì„œê°€ í¬í•¨ëœ EML íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”"
    )
    
    if uploaded_file is not None:
        # íŒŒì¼ ë‚´ìš© ì½ê¸°
        file_content = uploaded_file.read()
        file_content_str = file_content.decode('utf-8', errors='ignore')
        
        # EML íŒŒì¼ íŒŒì‹±
        with st.spinner('EML íŒŒì¼ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...'):
            parsed_data, parse_error = parse_eml_file(file_content_str)
        
        if parse_error:
            st.error(f"âŒ EML íŒŒì¼ íŒŒì‹± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {parse_error}")
        else:
            # íŒŒì‹±ëœ ë‚´ìš© í‘œì‹œ
            display_eml_content(parsed_data)
            
            st.divider()
            
            # ì—…ë¡œë“œ í™•ì¸
            if not connection_test_result:
                st.error("âŒ Azure Storage ì—°ê²°ì´ ì„¤ì •ë˜ì§€ ì•Šì•„ ì—…ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            elif not db_success:
                st.error("âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì´ ì„¤ì •ë˜ì§€ ì•Šì•„ ì—…ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                if st.button("âœ… ì—…ë¡œë“œ ë° ë‹¤ìŒ ë‹¨ê³„", type="primary"):
                    with st.spinner('Azure Storageì— ì—…ë¡œë“œ ì¤‘ì…ë‹ˆë‹¤...'):
                        success, blob_name, upload_error = upload_to_azure_eml_blob(
                            file_content, 
                            uploaded_file.name
                        )
                    
                    if success:
                        st.success(f"âœ… íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
                        
                        # ë°ì´í„°ë² ì´ìŠ¤ì— ì •ë³´ ì €ì¥
                        with st.spinner('ë°ì´í„°ë² ì´ìŠ¤ì— ì •ë³´ë¥¼ ì €ì¥ ì¤‘ì…ë‹ˆë‹¤...'):
                            db_success_insert, record_id, db_error = insert_eml_data(
                                parsed_data, 
                                uploaded_file.name, 
                                blob_name, 
                                len(file_content)
                            )
                        
                        if db_success_insert:
                            st.success(f"âœ… ë°ì´í„°ë² ì´ìŠ¤ì— ì„±ê³µì ìœ¼ë¡œ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤! (ID: {record_id})")
                            
                            # ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
                            st.session_state.current_record_id = record_id
                            st.session_state.current_filename = uploaded_file.name
                            st.session_state.current_body_text = parsed_data['body_text']
                            st.session_state.stage = 'processing'
                            st.rerun()
                        else:
                            st.error(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ë“±ë¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {db_error}")
                    else:
                        st.error(f"âŒ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {upload_error}")

# 2ë‹¨ê³„: AI ë¶„ì„ ë° ë³´ê³ ì„œ ìƒì„±
elif st.session_state.stage == 'processing':
    st.subheader("ğŸ” AI ë¶„ì„ ë° ë³´ê³ ì„œ ìƒì„±")
    
    # í˜„ì¬ íŒŒì¼ ì •ë³´ í‘œì‹œ
    st.info(f"ğŸ“„ ë¶„ì„ ëŒ€ìƒ: {st.session_state.current_filename} (ID: {st.session_state.current_record_id})")
    
    # OpenAI ì„¤ì • í™•ì¸
    if not openai_endpoint or not openai_api_key:
        st.error("âŒ OpenAI ì„¤ì •ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        st.stop()
    
    # í…œí”Œë¦¿ íŒŒì¼ í™•ì¸
    if not template_exists:
        st.error("âŒ í…œí”Œë¦¿ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()
    
    # AI ë¶„ì„ ì‹¤í–‰
    if st.session_state.extracted is None:
        with st.spinner("AIê°€ ì¥ì• ë³´ê³ ì„œ ì •ë³´ë¥¼ ì¶”ì¶œ ì¤‘ì…ë‹ˆë‹¤..."):
            extracted = extract_precise_data(st.session_state.current_body_text)
            if "error" not in extracted:
                st.session_state.extracted = extracted
                st.success("âœ… ì •ë³´ ì¶”ì¶œ ì™„ë£Œ!")
                
                # AI ë¶„ì„ ë¡œê·¸ í‘œì‹œ
                if hasattr(st.session_state, 'extract_logs') and st.session_state.extract_logs:
                    with st.expander("ğŸ” AI ë¶„ì„ ë¡œê·¸ ë³´ê¸°"):
                        for log in st.session_state.extract_logs:
                            st.write(log)
            else:
                st.error("âŒ ì •ë³´ ì¶”ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                if st.button("ğŸ”„ ë‹¤ì‹œ ì‹œë„"):
                    st.rerun()
                st.stop()
    
    # ì¶”ì¶œëœ ì •ë³´ í‘œì‹œ
    if st.session_state.extracted:
        data = st.session_state.extracted
        valid_data = {k: v for k, v in data.items() if v and v != "ì •ë³´ì—†ìŒ"}
        
        st.subheader("ğŸ“‹ ì¶”ì¶œëœ ì •ë³´")
        with st.expander("ì¶”ì¶œëœ ë°ì´í„° ë³´ê¸°"):
            st.json(valid_data)
        
        st.divider()
        
        # ë³´ê³ ì„œ ìƒì„±
        st.subheader("ğŸ“„ ì¥ì• ë¶„ì„ë³´ê³ ì„œ ìƒì„±")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("ğŸ“„ ë³´ê³ ì„œ ìƒì„±", type="primary"):
                with st.spinner("ë³´ê³ ì„œë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                    try:
                        # ë³´ê³ ì„œ ìƒì„±
                        report_path = fill_template_safely(template_path, data, st.session_state.current_record_id)
                        
                        # í…œí”Œë¦¿ ì²˜ë¦¬ ë¡œê·¸ í‘œì‹œ
                        if hasattr(st.session_state, 'template_logs') and st.session_state.template_logs:
                            with st.expander("ğŸ” í…œí”Œë¦¿ ì²˜ë¦¬ ë¡œê·¸ ë³´ê¸°"):
                                for log in st.session_state.template_logs:
                                    st.write(log)
                        
                        # Azure ì—…ë¡œë“œ
                        success, url, error = upload_to_azure_word(report_path, f"ë³´ê³ ì„œ_{st.session_state.current_record_id}.docx")
                        os.unlink(report_path)
                        
                        if success:
                            st.success("âœ… ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ!")
                            st.session_state.report_url = url
                            st.session_state.stage = 'completed'
                            st.rerun()
                        else:
                            st.error(f"âŒ ë³´ê³ ì„œ ì—…ë¡œë“œ ì‹¤íŒ¨: {error}")
                            
                    except Exception as e:
                        st.error(f"âŒ ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {e}")
        
        with col2:
            if st.button("ğŸ”„ ìƒˆ íŒŒì¼ ì—…ë¡œë“œ"):
                # ìƒíƒœ ì´ˆê¸°í™”
                st.session_state.stage = 'upload'
                st.session_state.current_record_id = None
                st.session_state.extracted = None
                st.rerun()

# 3ë‹¨ê³„: ì™„ë£Œ
elif st.session_state.stage == 'completed':
    st.subheader("âœ… ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ")
    
    st.success(f"ì¥ì• ë¶„ì„ë³´ê³ ì„œê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    # ë‹¤ìš´ë¡œë“œ ë§í¬
    if hasattr(st.session_state, 'report_url'):
        st.markdown(f"### [ğŸ“¥ ë‹¤ìš´ë¡œë“œ - AI ìƒì„± ë³´ê³ ì„œ]({st.session_state.report_url})")
        st.info("ğŸ’¡ ë‹¤ìš´ë¡œë“œ ë§í¬ëŠ” 24ì‹œê°„ ë™ì•ˆ ìœ íš¨í•©ë‹ˆë‹¤.")
    
    st.divider()
    
    # ğŸ¯ ê°€ì´ë“œ í‘œì‹œ
    show_completion_guide_simple()

    # ì¶”ê°€ ì‘ì—… ì˜µì…˜
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("ğŸ”„ ìƒˆ ë³´ê³ ì„œ ìƒì„±"):
            # ìƒíƒœ ì´ˆê¸°í™”
            st.session_state.stage = 'upload'
            st.session_state.current_record_id = None
            st.session_state.extracted = None
            if hasattr(st.session_state, 'report_url'):
                delattr(st.session_state, 'report_url')
            st.rerun()
    
    with col2:
        if st.button("ğŸ“‹ ê¸°ì¡´ íŒŒì¼ë¡œ ë‹¤ì‹œ ìƒì„±"):
            # ê°™ì€ íŒŒì¼ë¡œ ë‹¤ì‹œ ìƒì„±
            st.session_state.stage = 'processing'
            st.session_state.extracted = None  # ì¬ë¶„ì„
            st.rerun()