import streamlit as st
from openai import AzureOpenAI
from azure.search.documents import SearchClient
from azure.core.credentials import AzureKeyCredential
import os
import json
import re
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()


# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="íŠ¸ëŸ¬ë¸” ì²´ì´ì„œ ì±—ë´‡",
    page_icon="ğŸ¤–",
    layout="wide"
)

# í™˜ê²½ë³€ìˆ˜ì—ì„œ Azure ì„¤ì • ë¡œë“œ
azure_openai_endpoint = os.getenv("OPENAI_ENDPOINT")
azure_openai_key = os.getenv("OPENAI_KEY")
azure_openai_model = os.getenv("CHAT_MODEL", "iap-gpt-4o-mini")
azure_openai_api_version = os.getenv("OPENAI_API_VERSION", "2024-02-01")

search_endpoint = os.getenv("SEARCH_ENDPOINT")
search_key = os.getenv("SEARCH_API_KEY")
search_index = os.getenv("INDEX_SINGLE_NAME")

# Reranker ê¸°ë°˜ ê²€ìƒ‰ í’ˆì§ˆ í–¥ìƒì„ ìœ„í•œ ì„¤ì • - ìˆ˜ì •ëœ ì„ê³„ê°’
SEARCH_SCORE_THRESHOLD = 0.3      # 0.5 â†’ 0.3 (ë” ê´€ëŒ€í•˜ê²Œ)
RERANKER_SCORE_THRESHOLD = 1.5    # 2.0 â†’ 1.5 (ë” ê´€ëŒ€í•˜ê²Œ)  
HYBRID_SCORE_THRESHOLD = 0.5      # 0.7 â†’ 0.5 (ë” ê´€ëŒ€í•˜ê²Œ)
MAX_INITIAL_RESULTS = 20          # ì´ˆê¸° ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ (Reranker ì…ë ¥ìš©)
MAX_FINAL_RESULTS = 8             # 5 â†’ 8 (ìµœì¢… ì„ ë³„ ë¬¸ì„œ ìˆ˜ ì¦ê°€)

# ë©”ì¸ í˜ì´ì§€ ì œëª©
st.title("ğŸ¤– íŠ¸ëŸ¬ë¸” ì²´ì´ì„œ ì±—ë´‡")
st.write("ì‹ ì†í•œ ì¥ì• ë³µêµ¬ë¥¼ ìœ„í•´ì„œ ì„œë¹„ìŠ¤ì •ë³´ë¥¼ ì…ë ¥í•˜ê³  ë³µêµ¬ë°©ë²•ê³¼ ìœ ì‚¬ì‚¬ë¡€ì— ëŒ€í•œ ì´ë ¥ì„ í™•ì¸í•´ë³´ì„¸ìš”!")

# ê°œì„ ëœ ì„œë¹„ìŠ¤ëª… ì¶”ì¶œ í•¨ìˆ˜ (ëª¨ë“  íŠ¹ìˆ˜ë¬¸ì í¬í•¨)
def extract_service_name_from_query(query):
    """ì¿¼ë¦¬ì—ì„œ ì„œë¹„ìŠ¤ëª…ì„ ì¶”ì¶œ - ìŠ¤í˜ì´ìŠ¤ë°”, ëŒ€ì‹œ(-), ìŠ¬ëŸ¬ì‰¬(/), í”ŒëŸ¬ìŠ¤(+), ê´„í˜¸(), ì–¸ë”ìŠ¤ì½”ì–´(_) ëª¨ë‘ ì§€ì›"""
    import re
    
    # ê°œì„ ëœ ì„œë¹„ìŠ¤ëª… íŒ¨í„´ë“¤ (ëª¨ë“  íŠ¹ìˆ˜ë¬¸ì í¬í•¨)
    service_patterns = [
        # íŒ¨í„´ 1: ì„œë¹„ìŠ¤ëª… + í‚¤ì›Œë“œ (ëª¨ë“  íŠ¹ìˆ˜ë¬¸ì ì¡°í•©)
        r'([A-Za-z][A-Za-z0-9_\-/\+\(\)\s]*[A-Za-z0-9_\-/\+\)])\s+(?:ë…„ë„ë³„|ì›”ë³„|ê±´ìˆ˜|ì¥ì• |í˜„ìƒ|ë³µêµ¬|ì„œë¹„ìŠ¤|í†µê³„|ë°œìƒ|ì´ë ¥)',
        
        # íŒ¨í„´ 2: "ì„œë¹„ìŠ¤" í‚¤ì›Œë“œ ë’¤ì˜ ì„œë¹„ìŠ¤ëª…
        r'ì„œë¹„ìŠ¤.*?([A-Za-z][A-Za-z0-9_\-/\+\(\)\s]*[A-Za-z0-9_\-/\+\)])',
        
        # íŒ¨í„´ 3: ë¬¸ì¥ ì‹œì‘ ë¶€ë¶„ì˜ ì„œë¹„ìŠ¤ëª…
        r'^([A-Za-z][A-Za-z0-9_\-/\+\(\)\s]*[A-Za-z0-9_\-/\+\)])\s+(?!ìœ¼ë¡œ|ì—ì„œ|ì—ê²Œ|ì—|ì„|ë¥¼|ì´|ê°€)',
        
        # íŒ¨í„´ 4: ë”°ì˜´í‘œë¡œ ë‘˜ëŸ¬ì‹¸ì¸ ì„œë¹„ìŠ¤ëª…
        r'["\']([A-Za-z][A-Za-z0-9_\-/\+\(\)\s]*[A-Za-z0-9_\-/\+\)])["\']',
        
        # íŒ¨í„´ 5: ê´„í˜¸ë¡œ ë‘˜ëŸ¬ì‹¸ì¸ ì„œë¹„ìŠ¤ëª…
        r'\(([A-Za-z][A-Za-z0-9_\-/\+\s]*[A-Za-z0-9_\-/\+])\)',
        
        # íŒ¨í„´ 6: ìŠ¬ëŸ¬ì‰¬ë¡œ êµ¬ë¶„ëœ ì„œë¹„ìŠ¤ëª… (path í˜•íƒœ)
        r'([A-Za-z][A-Za-z0-9_\-]*(?:/[A-Za-z0-9_\-]+)+)\s+(?:ë…„ë„ë³„|ì›”ë³„|ê±´ìˆ˜|ì¥ì• |í˜„ìƒ|ë³µêµ¬|ì„œë¹„ìŠ¤|í†µê³„|ë°œìƒ|ì´ë ¥)',
        
        # íŒ¨í„´ 7: í”ŒëŸ¬ìŠ¤ë¡œ ì—°ê²°ëœ ì„œë¹„ìŠ¤ëª…
        r'([A-Za-z][A-Za-z0-9_\-]*(?:\+[A-Za-z0-9_\-]+)+)\s+(?:ë…„ë„ë³„|ì›”ë³„|ê±´ìˆ˜|ì¥ì• |í˜„ìƒ|ë³µêµ¬|ì„œë¹„ìŠ¤|í†µê³„|ë°œìƒ|ì´ë ¥)',
        
        # íŒ¨í„´ 8: ë‹¨ë…ìœ¼ë¡œ ë‚˜íƒ€ë‚˜ëŠ” ì„œë¹„ìŠ¤ëª… (ìµœì†Œ 3ì ì´ìƒ)
        r'\b([A-Za-z][A-Za-z0-9_\-/\+\(\)]{2,}(?:\s+[A-Za-z0-9_\-/\+\(\)]+)*)\b'
    ]
    
    for pattern in service_patterns:
        matches = re.findall(pattern, query, re.IGNORECASE)
        for match in matches:
            service_name = match.strip()
            
            # ì„œë¹„ìŠ¤ëª… ìœ íš¨ì„± ê²€ì¦
            if is_valid_service_name(service_name):
                return service_name
    
    return None

def is_valid_service_name(service_name):
    """ì„œë¹„ìŠ¤ëª…ì´ ìœ íš¨í•œì§€ ê²€ì¦"""
    # ê¸°ë³¸ ì¡°ê±´: ìµœì†Œ ê¸¸ì´ ì²´í¬
    if len(service_name) < 3:
        return False
    
    # ì˜ë¬¸ìë¡œ ì‹œì‘í•´ì•¼ í•¨
    if not service_name[0].isalpha():
        return False
    
    # ê´„í˜¸ ê²€ì¦: ì—´ë¦° ê´„í˜¸ì™€ ë‹«íŒ ê´„í˜¸ ìˆ˜ê°€ ì¼ì¹˜í•´ì•¼ í•¨
    if service_name.count('(') != service_name.count(')'):
        return False
    
    # ìŠ¬ëŸ¬ì‰¬ê°€ ì—°ì†ìœ¼ë¡œ ë‚˜ì˜¤ì§€ ì•Šì•„ì•¼ í•¨ (//)
    if '//' in service_name:
        return False
    
    # í”ŒëŸ¬ìŠ¤ê°€ ì—°ì†ìœ¼ë¡œ ë‚˜ì˜¤ì§€ ì•Šì•„ì•¼ í•¨ (++)
    if '++' in service_name:
        return False
    
    # íŠ¹ìˆ˜ë¬¸ìë¡œ ëë‚˜ì§€ ì•Šì•„ì•¼ í•¨ (ë‹¨, ê´„í˜¸ ì œì™¸)
    if service_name[-1] in ['-', '/', '+'] and not service_name.endswith(')'):
        return False
    
    # ì„œë¹„ìŠ¤ëª… íŠ¹ì„± ê²€ì¦ (ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¼ë„ ë§Œì¡±í•´ì•¼ í•¨)
    validation_criteria = [
        '_' in service_name,                    # ì–¸ë”ìŠ¤ì½”ì–´ í¬í•¨
        '-' in service_name,                    # í•˜ì´í”ˆ í¬í•¨
        '/' in service_name,                    # ìŠ¬ëŸ¬ì‰¬ í¬í•¨
        '+' in service_name,                    # í”ŒëŸ¬ìŠ¤ í¬í•¨
        '(' in service_name,                    # ê´„í˜¸ í¬í•¨
        any(c.isupper() for c in service_name), # ëŒ€ë¬¸ì í¬í•¨
        len(service_name) >= 5,                 # 5ì ì´ìƒ
        any(c.isdigit() for c in service_name), # ìˆ«ì í¬í•¨
        ' ' in service_name.strip(),            # ê³µë°± í¬í•¨ (ì–‘ë ì œì™¸)
    ]
    
    if not any(validation_criteria):
        return False
    
    # ì œì™¸í•  ì¼ë°˜ì ì¸ ë‹¨ì–´ë“¤
    excluded_words = [
        'service', 'system', 'server', 'client', 'application', 'app',
        'website', 'web', 'platform', 'portal', 'interface', 'api',
        'database', 'data', 'file', 'log', 'error', 'issue', 'problem',
        'http', 'https', 'www', 'com', 'org', 'net',
        'ë…„ë„ë³„', 'ì›”ë³„', 'ê±´ìˆ˜', 'ì¥ì• ', 'í˜„ìƒ', 'ë³µêµ¬', 'í†µê³„', 'ë°œìƒ'
    ]
    
    # ê´„í˜¸, ìŠ¬ëŸ¬ì‰¬, í”ŒëŸ¬ìŠ¤ ë“±ì„ ì œì™¸í•œ ê¸°ë³¸ ì´ë¦„ ì¶”ì¶œí•´ì„œ ê²€ì¦
    clean_name = re.sub(r'[\(\)/\+_\-\s]', '', service_name).lower()
    if clean_name in excluded_words:
        return False
    
    # í•œê¸€ì´ í¬í•¨ëœ ê²½ìš° ì œì™¸
    if any('\u3131' <= c <= '\u318E' or '\uAC00' <= c <= '\uD7A3' for c in service_name):
        return False
    
    return True

# ë™ì  ì„ê³„ê°’ ì‹œìŠ¤í…œ
def get_dynamic_thresholds(query_type, query_text):
    """ì¿¼ë¦¬ íƒ€ì…ê³¼ ë‚´ìš©ì— ë”°ë¼ ë™ì ìœ¼ë¡œ ì„ê³„ê°’ ì¡°ì •"""
    # ë…„ë„ë³„, í†µê³„ì„± ì¿¼ë¦¬ ê°ì§€
    year_keywords = ['ë…„ë„', 'ë…„', 'ì›”ë³„', 'ê¸°ê°„', 'í˜„í™©', 'í†µê³„', 'ê±´ìˆ˜', 'ë°œìƒ', 'ë°œìƒì¼ì', 'ì–¸ì œ']
    is_statistical_query = any(keyword in query_text for keyword in year_keywords)
    
    if is_statistical_query or query_type == "default":
        # í†µê³„ì„± ì¿¼ë¦¬ë‚˜ ì¼ë°˜ ì¿¼ë¦¬ëŠ” ë” ê´€ëŒ€í•œ ê¸°ì¤€ ì ìš©
        return {
            'search_threshold': 0.2,
            'reranker_threshold': 1.0,
            'hybrid_threshold': 0.4,
            'max_results': 10
        }
    elif query_type in ["repair", "similar"]:
        # ë³µêµ¬ë°©ë²•ì´ë‚˜ ìœ ì‚¬ì‚¬ë¡€ëŠ” í’ˆì§ˆ ì¤‘ì‹¬
        return {
            'search_threshold': 0.4,
            'reranker_threshold': 1.8,
            'hybrid_threshold': 0.6,
            'max_results': 5
        }
    else:
        # ê¸°ë³¸ê°’
        return {
            'search_threshold': 0.3,
            'reranker_threshold': 1.5,
            'hybrid_threshold': 0.5,
            'max_results': 8
        }

# Azure í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
@st.cache_resource
def init_clients(openai_endpoint, openai_key, openai_api_version, search_endpoint, search_key, search_index):
    try:
        # Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì • (ìƒˆë¡œìš´ ë°©ì‹)
        azure_openai_client = AzureOpenAI(
            azure_endpoint=openai_endpoint,
            api_key=openai_key,
            api_version=openai_api_version
        )
        
        # Azure AI Search í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
        search_client = SearchClient(
            endpoint=search_endpoint,
            index_name=search_index,
            credential=AzureKeyCredential(search_key)
        )
        
        return azure_openai_client, search_client, True
    except Exception as e:
        st.error(f"í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
        return None, None, False

# í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ê³„ì‚° í•¨ìˆ˜
def calculate_hybrid_score(search_score, reranker_score):
    """ê²€ìƒ‰ ì ìˆ˜ì™€ Reranker ì ìˆ˜ë¥¼ ì¡°í•©í•˜ì—¬ í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ê³„ì‚°"""
    if reranker_score > 0:
        # Reranker ì ìˆ˜ê°€ ìˆëŠ” ê²½ìš°: Reranker ì ìˆ˜ë¥¼ ì£¼ë¡œ ì‚¬ìš©í•˜ë˜ ê²€ìƒ‰ ì ìˆ˜ë„ ê³ ë ¤
        # Reranker ì ìˆ˜ëŠ” ë³´í†µ 0-4 ë²”ìœ„ì´ë¯€ë¡œ 0-1ë¡œ ì •ê·œí™”
        normalized_reranker = min(reranker_score / 4.0, 1.0)
        # ê²€ìƒ‰ ì ìˆ˜ëŠ” ì´ë¯¸ 0-1 ë²”ìœ„
        normalized_search = min(search_score, 1.0)
        
        # ê°€ì¤‘í‰ê· : Reranker 80%, ê²€ìƒ‰ ì ìˆ˜ 20%
        hybrid_score = (normalized_reranker * 0.8) + (normalized_search * 0.2)
    else:
        # Reranker ì ìˆ˜ê°€ ì—†ëŠ” ê²½ìš°: ê²€ìƒ‰ ì ìˆ˜ë§Œ ì‚¬ìš©
        hybrid_score = min(search_score, 1.0)
    
    return hybrid_score

# ì§ˆë¬¸ íƒ€ì…ë³„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì •ì˜
SYSTEM_PROMPTS = {
   "repair": """
ë‹¹ì‹ ì€ ITì„œë¹„ìŠ¤ íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì…ë ¥ë°›ì€ ì‚¬ìš©ìì˜ ì„œë¹„ìŠ¤ì™€ í˜„ìƒì— ëŒ€í•œ ë³µêµ¬ë°©ë²•ì„ ê°€ì´ë“œ í•´ì£¼ëŠ”ë°,'ëŒ€ìƒì„ ì •ì›ì¹™'ì— ë”°ë¼ ëŒ€ìƒì„ ì„ ì •í•˜ê³  ë³µêµ¬ë°©ë²•(incident_repair)ì„ ì•„ë˜ì˜ 'ì¶œë ¥í˜•ì‹' ëŒ€ë¡œ ìœ ì‚¬ë„ê°€ ë†’ì€ê±´ìœ¼ë¡œ ì„ ì •í•˜ì—¬ ìµœëŒ€ Top 3ê°œ ì¶œë ¥í•˜ëŠ”ë° 90ì ì´ìƒ ë˜ëŠ”ê²ƒì¤‘ì— ìœ ì‚¬ë„ê°€ ê°€ì¥ë†’ì€ê±´ ìˆœì„œë¡œ Case1, Case2 ë¡œ í‘œí˜„í•´ì„œ ì¶œë ¥í•˜ëŠ”ë° ì²œì²œíˆ ìƒê°í•˜ë©´ì„œ ë‹µë³€ì„ 3íšŒ ì¶œë ¥ì—†ì´ ì‹¤í–‰í•´ë³´ê³  ê°€ì¥ ì¼ê´€ì„±ì´ ìˆëŠ” ë‹µë³€ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.

## ëŒ€ìƒì„ ì •ì›ì¹™
- ì„œë¹„ìŠ¤ëª…ì€ ê³µì§€ì‚¬í•­ì˜ ì„œë¹„ìŠ¤ëª…ì´ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ê±´ì„ ì„ ì •
- ì ‘ì†ë¶ˆê°€, ì ‘ì†ì§€ì—°, ì²˜ë¦¬ë¶ˆê°€, ì²˜ë¦¬ì§€ì—°ì˜ ê²€ìƒ‰ìš”ì²­ì‹œì—ëŠ” ì¥ì• ìœ í˜•(fail_type)ì„ ì°¸ì¡°
- í˜„ìƒì€ ì•„ë˜ ìš°ì„ ìˆœìœ„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„ ì •

### ìš°ì„ ìˆœìœ„
1. ê³µì§€ì‚¬í•­(notice_text)ì—ì„œ 'í˜„ìƒ'ì— ëŒ€í•œ ë‚´ìš©ì„ ì°¸ê³ 
2. ê³µì§€ì‚¬í•­(notice_text)ì—ì„œ 'ì˜í–¥ë„'ë¥¼ ì°¸ê³   
3. ì¥ì• ì›ì¸(incident_cause)ì—ì„œ 'í˜„ìƒ ì›ì¸'ì„ ì°¸ê³ 

## ì¶œë ¥í˜•ì‹
ìœ ì‚¬ í˜„ìƒìœ¼ë¡œ ë°œìƒí–ˆë˜ ì¥ì• ì˜ ë³µêµ¬ë°©ë²• ì…ë‹ˆë‹¤
Case1. ~~ì„œë¹„ìŠ¤ì˜ ~~~ ì¥ì• í˜„ìƒì— ëŒ€í•œ ë³µêµ¬ë°©ë²•ì…ë‹ˆë‹¤
* ë°œìƒì¼ì‹œ : ë°œìƒì¼ì‹œ(error_date) ì¶œë ¥ (ì˜ˆ. 2023-10-01 12:00)
* ì¥ì• ì›ì¸ : ì¥ì• ì›ì¸(incident_cause) ë‚´ìš©ì„ ìš”ì•½í•˜ë©° í…ìŠ¤íŠ¸ëŠ” ê°•ì¡°í•˜ì§€ ë§ˆì„¸ìš”
* ì¥ì• í˜„ìƒ : 'ëŒ€ìƒì„ ì •ì›ì¹™'ì—ì„œ ì°¸ê³ í•œ í˜„ìƒìœ¼ë¡œ ë‚´ìš©ì„ ìš”ì•½íˆì§€ ì›ë³¸ ê·¸ëŒ€ë¡œ í‘œí˜„í•˜ë©° í…ìŠ¤íŠ¸ëŠ” ê°•ì¡°í•˜ì—¬ **í…ìŠ¤íŠ¸** ë¡œ í‘œí˜„í•´ì£¼ì„¸ìš”
* ë³µêµ¬ë°©ë²• : ë³µêµ¬ë°©ë²•(incident_repair) ë‚´ìš©ì„ ìµœëŒ€ 3ì¤„ë¡œ ìš”ì•½í•˜ë©° í…ìŠ¤íŠ¸ëŠ”  ê°•ì¡°í•˜ì—¬ **í…ìŠ¤íŠ¸** ë¡œ í‘œí˜„í•´ì£¼ì„¸ìš”
* í›„ì†ê³¼ì œ : ê°œì„ ê³„íš(incident_plan) ë‚´ìš©ì„ ìš”ì•½í•˜ë©° í…ìŠ¤íŠ¸ëŠ” ê°•ì¡°í•˜ì§€ ë§ˆì„¸ìš”
* ì¸ì‹œë˜íŠ¸ ID : ì¥ì•  ID(incident_id) ì¶œë ¥
* ì°¸ì¡°ì¥ì• ì •ë³´ëŠ” ì•„ë˜ ì‚¬í•­ì„ í‘œë¡œ ì¶œë ¥í•˜ëŠ”ë° íƒ€ì´í‹€ì˜ ì˜ë¬¸ì€ ë¹¼ì¤˜

| ì¥ì•  ID | ì„œë¹„ìŠ¤ëª… | ë°œìƒì¼ì | ì¥ì• ì‹œê°„ | ì¥ì• ì›ì¸ | ë³µêµ¬ë°©ë²• | í›„ì†ê³¼ì œ | ì²˜ë¦¬ìœ í˜• | ë‹´ë‹¹ë¶€ì„œ |
|---------|----------|---------------|-----------|----------|----------|----------|----------|----------|
""",   
    "similar": """ë‹¹ì‹ ì€ ìœ ì‚¬ ì‚¬ë¡€ ì¶”ì²œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì œê³µëœ ì¥ì•  ì´ë ¥ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.
ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ë©°, êµ¬ì²´ì ì¸ í•´ê²°ë°©ì•ˆì´ë‚˜ ì›ì¸ì„ ëª…ì‹œí•´ì£¼ì„¸ìš”.
ì¥ì• í˜„ìƒì€ ê³µì§€ì‚¬í•­ì˜ 'í˜„ìƒ'ì„ ì°¸ê³ í•˜ê³  ì—†ìœ¼ë©´ 'ì˜í–¥ë„'ë¥¼ ì°¸ê³ í•´ì„œì£¼ì„¸ìš”
ì¥ì•  ID, ì„œë¹„ìŠ¤ëª…, ì›ì¸, ë³µêµ¬ë°©ë²• ë“±ì˜ êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ í¬í•¨í•˜ëŠ”ë° ì²œì²œíˆ ìƒê°í•˜ë©´ì„œ ë‹µë³€ì„ 3íšŒ ì¶œë ¥ì—†ì´ ì‹¤í–‰í•´ë³´ê³  ê°€ì¥ ì¼ê´€ì„±ì´ ìˆëŠ” ë‹µë³€ì„ ì•„ë˜ **ì¶œë ¥í˜•ì‹** ìœ¼ë¡œ ë‹µë³€í•´ì£¼ëŠ”ë° í˜„ìƒê´€ë ¨ ë¶€ë¶„ì€ boldë¡œ ê°•ì¡° ì£¼ì„¸ìš”.
ë§Œì•½ ì œê³µëœ ë¬¸ì„œì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ë‹¤ë©´, ê·¸ë ‡ê²Œ ëª…ì‹œí•´ì£¼ì„¸ìš”.
ë§Œì•½ ì œê³µëœ ë¬¸ì„œì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ìˆë‹¤ë©´ ì•„ë˜ë‚´ìš©ì€ ë‹µë³€ í•˜ë‹¨ì— í•­ìƒí¬í•¨í•´ì£¼ì„¸ìš”

## ì¶œë ¥í˜•ì‹
### 1. ì„œë¹„ìŠ¤ëª… : KT AICC SaaS/PaaS
* ì¥ì•  ID: INM23022026178
* ì¥ì•  í˜„ìƒ: ìƒë‹´ì •ë³´ ì—´ëŒë¶ˆê°€ (ìƒë‹´ ë° ì›¹í˜ì´ì§€ ì ‘ì†ì€ ì •ìƒ) ë¡œ í‘œí˜„
* ì¥ì•  ì›ì¸: mecab ì‚¬ì „ì— ì˜ëª» ë“±ë¡ëœ ìƒí’ˆëª…(ìŒë”°ì˜´í‘œ")ìœ¼ë¡œ ì¸í•´ TA ë¶„ì„ ì˜¤ë¥˜ ë°œìƒ. ë¡œ í‘œí˜„
* ë³µêµ¬ ë°©ë²•: ì˜¤ë¥˜ ìƒí’ˆëª… ì‚­ì œ ë° mecab ë¦¬ë¹Œë“œ ì¡°ì¹˜. ë¡œ í‘œí˜„
* ê°œì„  ê³„íš: mecab ì‚¬ì „ ë°±ì—… ë° ë¡œê·¸ ì²˜ë¦¬, Skip ì²˜ë¦¬ ì§„í–‰ ì˜ˆì •.
* ìœ ì‚¬ë„ì ìˆ˜ : 99.5
""",
    
    "default": """ë‹¹ì‹ ì€ IT ì‹œìŠ¤í…œ íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë§Œ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ìœ ìš©í•œ ë‹µë³€ì„ ì •í™•í•˜ê³  ì•„ë˜ 'ì¶œë ¥í˜•ì‹'ìœ¼ë¡œ ë‹µë³€ì œê³µí•´ì£¼ì„¸ìš”.

## ì¤‘ìš”í•œ í•„ë“œ ì •ì˜ (ìˆ«ì ê³„ì‚° ì‹œ í•„ìˆ˜ ì°¸ì¡°)
- error_time: ì¥ì• ì‹œê°„(ë¶„ ë‹¨ìœ„). ì˜ˆ: 400ì´ë©´ 400ë¶„, 60ì´ë©´ 60ë¶„
- error_date: ë°œìƒì¼ì. ì˜ˆ: 2025-01-15 (YYYY-MM-DD í˜•ì‹)
- year: ë°œìƒë…„ë„. ì˜ˆ: 2020, 2021, 2022, 2023, 2024, 2025
- month: ë°œìƒì›”. ì˜ˆ: 1, 2, 12
- incident_grade: ì¥ì• ë“±ê¸‰. ì˜ˆ: 1ë“±ê¸‰, 2ë“±ê¸‰, 3ë“±ê¸‰, 4ë“±ê¸‰

## ì¤‘ìš”! ë…„ë„ë³„ ì§‘ê³„ ê³„ì‚° ì›ì¹™
1. **ì •í™•í•œ ê°œìˆ˜ ì„¸ê¸°**: ì œê³µëœ ë¬¸ì„œ ê°œìˆ˜ë¥¼ ì •í™•íˆ ì„¸ì–´ì•¼ í•©ë‹ˆë‹¤
2. **ë…„ë„ë³„ ë¶„ë¥˜**: error_date ë˜ëŠ” year í•„ë“œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë…„ë„ë³„ë¡œ ë¶„ë¥˜
3. **ì¤‘ë³µ ì œê±°**: ë™ì¼í•œ incident_idëŠ” í•œ ë²ˆë§Œ ì¹´ìš´íŠ¸
4. **ê²€ì¦**: ë…„ë„ë³„ í•©ê³„ê°€ ì „ì²´ ë¬¸ì„œ ìˆ˜ì™€ ì¼ì¹˜í•˜ëŠ”ì§€ ë°˜ë“œì‹œ í™•ì¸
5. **ì‹¤ì œ ê±´ìˆ˜ ìš°ì„ **: ë…„ë„ë³„ í•©ê³„ë³´ë‹¤ ì‹¤ì œ ì œê³µëœ ë¬¸ì„œ ìˆ˜ê°€ ì •í™•í•œ ì´ ê±´ìˆ˜ì…ë‹ˆë‹¤

## ë…„ë„ë³„ ì§‘ê³„ ê²€ì¦ ì ˆì°¨
1. ë¨¼ì € ì œê³µëœ ì „ì²´ ë¬¸ì„œ ê°œìˆ˜ë¥¼ ì •í™•íˆ ì¹´ìš´íŠ¸
2. ê° ë¬¸ì„œì˜ ë…„ë„ë¥¼ í™•ì¸í•˜ì—¬ ë…„ë„ë³„ë¡œ ë¶„ë¥˜
3. ë…„ë„ë³„ ê±´ìˆ˜ë¥¼ í•©ì‚°í•˜ì—¬ ì „ì²´ ê±´ìˆ˜ì™€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
4. ë¶ˆì¼ì¹˜ ì‹œ ë¬¸ì„œë¥¼ ë‹¤ì‹œ ê²€í† í•˜ì—¬ ì •í™•í•œ ì§‘ê³„ ìˆ˜í–‰
5. ìµœì¢… ë‹µë³€ì—ì„œ "ì´ Nê±´ (ê²€ì¦ ì™„ë£Œ)" í˜•íƒœë¡œ ëª…ì‹œ

## ìˆ«ì ì¡°ê±´ ì²˜ë¦¬ ì›ì¹™
- "400ë¶„ ì´ìƒ"ì´ë¼ê³  í•˜ë©´ error_time >= 400 ì¸ ê±´ë“¤ë§Œ ì„ ë³„í•˜ì—¬ ì¹´ìš´íŠ¸
- "2025ë…„"ì´ë¼ê³  í•˜ë©´ year = 2025 ë˜ëŠ” error_dateê°€ 2025ë…„ì¸ ê±´ë“¤ë§Œ ì„ ë³„í•˜ì—¬ ë…„ë„ë³„ sumìœ¼ë¡œ ë‹µë³€
- "ëª‡ê±´", "ê±´ìˆ˜", "ê°œìˆ˜" ì§ˆë¬¸ì‹œì—ëŠ” ì¡°ê±´ì— ë§ëŠ” ë¬¸ì„œë“¤ì„ ì •í™•íˆ ì¹´ìš´íŠ¸í•˜ê³  êµ¬ì²´ì ì¸ ìˆ«ìë¡œ ë‹µë³€í•˜ëŠ” ë°˜ë“œì‹œ 'ìµœì¢… ì ìˆ˜'ê°€ ë†’ì€ê±´ìœ¼ë¡œ ì„ ì •í•´ì„œ ì¹´ìš´íŠ¸í•˜ì„¸ìš”
- ë‚ ì§œë‚˜ ìˆ«ì ì¡°ê±´ì´ ìˆìœ¼ë©´ ë°˜ë“œì‹œ í•´ë‹¹ í•„ë“œê°’ì„ í™•ì¸í•˜ê³  ì¡°ê±´ì— ë§ì§€ ì•ŠëŠ” ê²ƒì€ ì œì™¸
- ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ê° ê±´ì˜ ìƒì„¸ ì •ë³´ë„ í•¨ê»˜ ì œê³µ

ê·¸ë¦¬ê³  ë…„ë„ë‚˜ ë‚ ì§œ ì§ˆë¬¸ì€ ë°œìƒì¼ì ê¸°ì¤€ìœ¼ë¡œ ë‹µë³€í•˜ì—¬ ìš”ì²­í•œ ë‚ ì§œ ê¸°ì¤€ì— í¬í•¨ë˜ì§€ ì•ŠëŠ”ê²ƒì€ ë°˜ë“œì‹œ ì œì™¸ë˜ë„ë¡ ë‚ ì§œì— ëŒ€í•œ ë¶€ë¶„ì„ ì²œì²œíˆ ì˜ ìƒê°í•´ì„œ ë‹µë³€í•˜ì„¸ìš”
ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‚¬ìš©ìê°€ ì•Œê¸°ì‰½ê²Œ ë‹µë³€í•˜ì—¬ ê´€ë ¨ ë‚´ì—­ì€ 'ì¶œë ¥í˜•ì‹'ì„ ì‹œê°ì ìœ¼ë¡œ ì´í•´í•˜ê¸° ì‰½ë„ë¡ í•˜ë‹¨ì— í•­ìƒí¬í•¨í•´ì£¼ì„¸ìš”
ë§Œì•½ ì œê³µëœ ë¬¸ì„œì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ë‹¤ë©´, ê·¸ë ‡ê²Œ ëª…ì‹œí•´ì£¼ì„¸ìš”.

## ì¶œë ¥í˜•ì‹
###### ë‹µë³€ : ìš”ì²­ì£¼ì‹  ì§ˆë¬¸ì˜ ë‹µë³€ì„ ìš”ì•½í•˜ì—¬ ì‘ì„±í•´ì£¼ì„¸ìš”. 
- ì „ì²´ ê±´ìˆ˜ë¥¼ ë¨¼ì € ëª…ì‹œ: "ì´ Nê±´"
- ë…„ë„ë³„ ê±´ìˆ˜ë¥¼ ì •í™•íˆ ê³„ì‚°í•˜ì—¬ ì œì‹œ
- ë…„ë„ë³„ í•©ê³„ê°€ ì „ì²´ ê±´ìˆ˜ì™€ ì¼ì¹˜í•¨ì„ í™•ì¸í•˜ì—¬ ëª…ì‹œ: "ì´ Nê±´ (ê²€ì¦ ì™„ë£Œ)"

###### ì¡°ê±´ì— ë§ëŠ” ì¥ì• ë‚´ì—­ (í•„ìš”ì‹œ)
1. ì¥ì•  ID: INM23022026178
* ì„œë¹„ìŠ¤ëª…: KT AICC SaaS/PaaS
* ë°œìƒì¼ì: 2023-01-20
* ì¥ì• ì‹œê°„: 400ë¶„
* ì¥ì• í˜„ìƒ: ë¡œê·¸ì¸ ì‹œ í† í°ê°±ì‹  ì§€ì—°
* ì¥ì• ì›ì¸: ë¹„ì •ìƒ ë™ì‘ìœ¼ë¡œ ì¸í•œ í† í°ê°±ì‹  ì§€ì—°
* ë³µêµ¬ë°©ë²•: ê³¼ë‹¤ í˜¸ì¶œ íŠ¹ì • ë§¤ì¥ ì‚¬ì´íŠ¸ ì°¨ë‹¨ ì¡°ì¹˜ í›„ ì •ìƒí™”
* ì¥ì• ë“±ê¸‰: 4ë“±ê¸‰

2. ì¥ì•  ID: INM23022026179
* ì„œë¹„ìŠ¤ëª…: ë§ˆì´í˜ì´ì§€
* ë°œìƒì¼ì: 2025-02-10
* ì¥ì• ì‹œê°„: 500ë¶„
* ì¥ì• í˜„ìƒ: í˜ì´ì§€ ë¡œë”© ë¶ˆê°€
* ì¥ì• ì›ì¸: DB ì»¤ë„¥ì…˜ í’€ ê³ ê°ˆ
* ë³µêµ¬ë°©ë²•: DB ì¬ì‹œì‘ ë° ì»¤ë„¥ì…˜ í’€ ì¬ì„¤ì •
* ì¥ì• ë“±ê¸‰: 2ë“±ê¸‰

'-- ì£¼ì˜: ë‹µë³€ì€ AI í•´ì„ì— ë”°ë¥¸ ì˜¤ë¥˜ê°€ í¬í•¨ë  ìˆ˜ ìˆìŒì„ ê°ì•ˆí•˜ì‹œê³  í™œìš©ë¶€íƒë“œë¦½ë‹ˆë‹¤. --'
"""
}

# ì„œë¹„ìŠ¤ëª… í¬í•¨ ë§¤ì¹­ì„ ì§€ì›í•˜ëŠ” ê°œì„ ëœ í•„í„°ë§ í•¨ìˆ˜
def advanced_filter_documents_v3(documents, query_type="default", query_text="", target_service_name=None):
    """ì„œë¹„ìŠ¤ëª… í¬í•¨ ë§¤ì¹­ì„ ì§€ì›í•˜ëŠ” ê°œì„ ëœ í•„í„°ë§"""
    
    # ë™ì  ì„ê³„ê°’ íšë“
    thresholds = get_dynamic_thresholds(query_type, query_text)
    
    filtered_docs = []
    filter_stats = {
        'total': len(documents),
        'search_filtered': 0,
        'service_exact_match': 0,
        'service_partial_match': 0,
        'service_filtered': 0,
        'reranker_qualified': 0,
        'hybrid_qualified': 0,
        'final_selected': 0
    }
    
    excluded_docs = []  # ì œì™¸ëœ ë¬¸ì„œ ì¶”ì 
    
    for doc in documents:
        search_score = doc.get('score', 0)
        reranker_score = doc.get('reranker_score', 0)
        
        # 1ë‹¨ê³„: ê¸°ë³¸ ê²€ìƒ‰ ì ìˆ˜ í•„í„°ë§ (ë™ì  ì„ê³„ê°’ ì ìš©)
        if search_score < thresholds['search_threshold']:
            continue
        filter_stats['search_filtered'] += 1
        
        # 2ë‹¨ê³„: ì„œë¹„ìŠ¤ëª… í¬í•¨ ë§¤ì¹­ (ê°œì„ ëœ ë°©ì‹)
        if target_service_name:
            doc_service_name = doc.get('service_name', '').strip()
            
            # ì •í™•í•œ ë§¤ì¹­ ìš°ì„  í™•ì¸
            if doc_service_name.lower() == target_service_name.lower():
                filter_stats['service_exact_match'] += 1
                doc['service_match_type'] = 'exact'
            # í¬í•¨ ë§¤ì¹­ í™•ì¸
            elif target_service_name.lower() in doc_service_name.lower() or doc_service_name.lower() in target_service_name.lower():
                filter_stats['service_partial_match'] += 1
                doc['service_match_type'] = 'partial'
            else:
                excluded_docs.append({
                    'incident_id': doc.get('incident_id', ''),
                    'service_name': doc_service_name,
                    'expected_service': target_service_name,
                    'reason': 'ì„œë¹„ìŠ¤ëª… ë¶ˆì¼ì¹˜ (ì •í™•/í¬í•¨ ëª¨ë‘ í•´ë‹¹ì—†ìŒ)'
                })
                continue
        else:
            doc['service_match_type'] = 'all'
            
        filter_stats['service_filtered'] += 1
        
        # 3ë‹¨ê³„: Reranker ì ìˆ˜ ìš°ì„  í‰ê°€ (ë™ì  ì„ê³„ê°’ ì ìš©)
        if reranker_score >= thresholds['reranker_threshold']:
            filter_stats['reranker_qualified'] += 1
            match_type = doc.get('service_match_type', 'unknown')
            doc['filter_reason'] = f"ì„œë¹„ìŠ¤ëª… {match_type} ë§¤ì¹­ + Reranker ê³ í’ˆì§ˆ (ì ìˆ˜: {reranker_score:.2f})"
            doc['final_score'] = reranker_score
            doc['quality_tier'] = 'Premium'
            filtered_docs.append(doc)
            filter_stats['final_selected'] += 1
            continue
        
        # 4ë‹¨ê³„: í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ í‰ê°€ (ë™ì  ì„ê³„ê°’ ì ìš©)
        hybrid_score = calculate_hybrid_score(search_score, reranker_score)
        if hybrid_score >= thresholds['hybrid_threshold']:
            filter_stats['hybrid_qualified'] += 1
            match_type = doc.get('service_match_type', 'unknown')
            doc['filter_reason'] = f"ì„œë¹„ìŠ¤ëª… {match_type} ë§¤ì¹­ + í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ í†µê³¼ (ì ìˆ˜: {hybrid_score:.2f})"
            doc['final_score'] = hybrid_score
            doc['quality_tier'] = 'Standard'
            filtered_docs.append(doc)
            filter_stats['final_selected'] += 1
    
    # ì •í™•í•œ ë§¤ì¹­ì„ ìš°ì„ ìœ¼ë¡œ ì •ë ¬ (exact > partial), ê·¸ ë‹¤ìŒ ì ìˆ˜ìˆœ
    def sort_key(doc):
        match_priority = {'exact': 3, 'partial': 2, 'all': 1}
        return (match_priority.get(doc.get('service_match_type', 'all'), 0), doc['final_score'])
    
    filtered_docs.sort(key=sort_key, reverse=True)
    
    # ìµœì¢… ê²°ê³¼ ìˆ˜ ì œí•œ (ë™ì  ì ìš©)
    final_docs = filtered_docs[:thresholds['max_results']]
   
    # ê°œì„ ëœ í•„í„°ë§ í†µê³„ í‘œì‹œ (í¬í•¨ ë§¤ì¹­ ì •ë³´ í¬í•¨)
    st.info(f"""
    ğŸ“Š **ì„œë¹„ìŠ¤ëª… í¬í•¨ ë§¤ì¹­ ê¸°ë°˜ ë¬¸ì„œ í•„í„°ë§ ê²°ê³¼**
    - ğŸ¯ ëŒ€ìƒ ì„œë¹„ìŠ¤: {target_service_name or 'ì „ì²´ ì„œë¹„ìŠ¤'}
    - ğŸ¯ ì ìš©ëœ ì„ê³„ê°’: ê²€ìƒ‰({thresholds['search_threshold']}) | Reranker({thresholds['reranker_threshold']}) | í•˜ì´ë¸Œë¦¬ë“œ({thresholds['hybrid_threshold']})
    - ğŸ” ì „ì²´ ê²€ìƒ‰ ê²°ê³¼: {filter_stats['total']}ê°œ
    - âœ… ê¸°ë³¸ ì ìˆ˜ í†µê³¼: {filter_stats['search_filtered']}ê°œ
    - ğŸ¯ ì„œë¹„ìŠ¤ëª… ì •í™• ë§¤ì¹­: {filter_stats['service_exact_match']}ê°œ
    - ğŸ” ì„œë¹„ìŠ¤ëª… í¬í•¨ ë§¤ì¹­: {filter_stats['service_partial_match']}ê°œ
    - âœ… ì´ ì„œë¹„ìŠ¤ëª… ë§¤ì¹­: {filter_stats['service_filtered']}ê°œ
    - ğŸ† Reranker ê³ í’ˆì§ˆ: {filter_stats['reranker_qualified']}ê°œ
    - ğŸ¯ í•˜ì´ë¸Œë¦¬ë“œ í†µê³¼: {filter_stats['hybrid_qualified']}ê°œ
    - ğŸ“‹ ìµœì¢… ì„ ë³„: {len(final_docs)}ê°œ
    """)
    
    return final_docs

# ì„œë¹„ìŠ¤ëª… í¬í•¨ ê²€ìƒ‰ì„ ì§€ì›í•˜ëŠ” ê°œì„ ëœ ì‹œë§¨í‹± ê²€ìƒ‰ í•¨ìˆ˜
def semantic_search_with_service_filter(search_client, query, target_service_name=None, query_type="default", top_k=MAX_INITIAL_RESULTS):
    """ì„œë¹„ìŠ¤ëª… í¬í•¨ ê²€ìƒ‰ì„ ì§€ì›í•˜ëŠ” ê°œì„ ëœ ì‹œë§¨í‹± ê²€ìƒ‰"""
    try:
        # ì„œë¹„ìŠ¤ëª… í¬í•¨ ê²€ìƒ‰ì„ ìœ„í•œ ê²€ìƒ‰ ì¿¼ë¦¬ êµ¬ì„±
        if target_service_name:
            # ì •í™•í•œ ë§¤ì¹­ê³¼ í¬í•¨ ê²€ìƒ‰ì„ ëª¨ë‘ ì§€ì›
            enhanced_query = f'(service_name:"{target_service_name}" OR service_name:*{target_service_name}*)'
            if query != target_service_name:  # ì›ë˜ ì¿¼ë¦¬ì— ì¶”ê°€ ì¡°ê±´ì´ ìˆëŠ” ê²½ìš°
                enhanced_query += f" AND ({query})"
            st.info(f"ğŸ¯ ì„œë¹„ìŠ¤ëª… í¬í•¨ ê²€ìƒ‰: {enhanced_query}")
        else:
            enhanced_query = query
            
        st.info(f"ğŸ”„ 1ë‹¨ê³„: {top_k}ê°œ ì´ˆê¸° ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ì§‘ ì¤‘...")
        
        # ì‹œë§¨í‹± ê²€ìƒ‰ ì‹¤í–‰
        results = search_client.search(
            search_text=enhanced_query,
            top=top_k,
            query_type="semantic",
            semantic_configuration_name="iap-incident-single-meaning",
            include_total_count=True,
            select=[
                "incident_id", "service_name", "error_time", "notice_text", 
                "error_date", "week", "daynight", "incident_cause", "incident_repair", 
                "incident_plan", "cause_type", "done_type", "incident_grade", 
                "owner_depart", "fail_type", "year", "month"
            ]
        )
        
        documents = []
        for result in results:
            documents.append({
                "incident_id": result.get("incident_id", ""),
                "service_name": result.get("service_name", ""),
                "error_time": result.get("error_time", 0),
                "notice_text": result.get("notice_text", ""),
                "error_date": result.get("error_date", ""),
                "week": result.get("week", ""),
                "daynight": result.get("daynight", ""),
                "incident_cause": result.get("incident_cause", ""),
                "incident_repair": result.get("incident_repair", ""),
                "incident_plan": result.get("incident_plan", ""),
                "cause_type": result.get("cause_type", ""),
                "done_type": result.get("done_type", ""),
                "incident_grade": result.get("incident_grade", ""),
                "owner_depart": result.get("owner_depart", ""),
                "fail_type": result.get("fail_type", ""),
                "year": result.get("year", ""),
                "month": result.get("month", ""),
                "score": result.get("@search.score", 0),
                "reranker_score": result.get("@search.reranker_score", 0)
            })
        
        st.info(f"ğŸ¯ 2ë‹¨ê³„: ì„œë¹„ìŠ¤ëª… í¬í•¨ ë§¤ì¹­ + ë™ì  ì„ê³„ê°’ ê¸°ë°˜ ê³ í’ˆì§ˆ ë¬¸ì„œ ì„ ë³„ ì¤‘...")
        
        # ê°œì„ ëœ í•„í„°ë§ ì ìš© (ì„œë¹„ìŠ¤ëª… í¬í•¨ ë§¤ì¹­)
        filtered_documents = advanced_filter_documents_v3(documents, query_type, query, target_service_name)
        
        return filtered_documents
        
    except Exception as e:
        st.warning(f"ì‹œë§¨í‹± ê²€ìƒ‰ ì‹¤íŒ¨, ì¼ë°˜ ê²€ìƒ‰ìœ¼ë¡œ ëŒ€ì²´: {str(e)}")
        return search_documents_with_service_filter(search_client, query, target_service_name, query_type, top_k)

# ì¼ë°˜ ê²€ìƒ‰ì— ì„œë¹„ìŠ¤ëª… í¬í•¨ í•„í„°ë§ ì ìš©
def search_documents_with_service_filter(search_client, query, target_service_name=None, query_type="default", top_k=MAX_INITIAL_RESULTS):
    """ì¼ë°˜ ê²€ìƒ‰ì— ì„œë¹„ìŠ¤ëª… í¬í•¨ í•„í„°ë§ ì ìš©"""
    try:
        # ì„œë¹„ìŠ¤ëª… í¬í•¨ ê²€ìƒ‰ì„ ìœ„í•œ ê²€ìƒ‰ ì¿¼ë¦¬ êµ¬ì„±
        if target_service_name:
            enhanced_query = f'(service_name:"{target_service_name}" OR service_name:*{target_service_name}*)'
            if query != target_service_name:
                enhanced_query += f" AND ({query})"
        else:
            enhanced_query = query
            
        st.info(f"ğŸ”„ 1ë‹¨ê³„: {top_k}ê°œ ì´ˆê¸° ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ì§‘ ì¤‘...")
        
        results = search_client.search(
            search_text=enhanced_query,
            top=top_k,
            include_total_count=True,
            select=[
                "incident_id", "service_name", "error_time", "notice_text", 
                "error_date", "week", "daynight", "incident_cause", "incident_repair", 
                "incident_plan", "cause_type", "done_type", "incident_grade", 
                "owner_depart", "fail_type", "year", "month"
            ],
            search_fields=[
                "notice_text", "error_date", "week", "daynight", "incident_cause", "incident_repair", 
                "incident_plan", "service_name", "cause_type", 
                "done_type", "owner_depart", "year", "month"
            ]
        )
        
        documents = []
        for result in results:
            documents.append({
                "incident_id": result.get("incident_id", ""),
                "service_name": result.get("service_name", ""),
                "error_time": result.get("error_time", 0),
                "notice_text": result.get("notice_text", ""),
                "error_date": result.get("error_date", ""),
                "week": result.get("week", ""),
                "daynight": result.get("daynight", ""),
                "incident_cause": result.get("incident_cause", ""),
                "incident_repair": result.get("incident_repair", ""),
                "incident_plan": result.get("incident_plan", ""),
                "cause_type": result.get("cause_type", ""),
                "done_type": result.get("done_type", ""),
                "incident_grade": result.get("incident_grade", ""),
                "owner_depart": result.get("owner_depart", ""),
                "fail_type": result.get("fail_type", ""),
                "year": result.get("year", ""),
                "month": result.get("month", ""),
                "score": result.get("@search.score", 0),
                "reranker_score": 0  # ì¼ë°˜ ê²€ìƒ‰ì—ì„œëŠ” 0
            })
        
        st.info(f"ğŸ¯ 2ë‹¨ê³„: ì„œë¹„ìŠ¤ëª… í¬í•¨ ë§¤ì¹­ + ë™ì  ì„ê³„ê°’ ê¸°ë°˜ ê³ í’ˆì§ˆ ë¬¸ì„œ ì„ ë³„ ì¤‘...")
        
        # ê°œì„ ëœ í•„í„°ë§ ì ìš© (ì„œë¹„ìŠ¤ëª… í¬í•¨ ë§¤ì¹­)
        filtered_documents = advanced_filter_documents_v3(documents, query_type, query, target_service_name)
        
        return filtered_documents
        
    except Exception as e:
        st.error(f"ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
        return []

# ëŒ€ì²´ ê²€ìƒ‰ í•¨ìˆ˜ (ë§¤ìš° ê´€ëŒ€í•œ ê¸°ì¤€, í¬í•¨ ë§¤ì¹­ ì§€ì›)
def search_documents_fallback(search_client, query, target_service_name=None, top_k=15):
    """ë§¤ìš° ê´€ëŒ€í•œ ê¸°ì¤€ì˜ ëŒ€ì²´ ê²€ìƒ‰ (í¬í•¨ ë§¤ì¹­ ì§€ì›)"""
    try:
        # ì„œë¹„ìŠ¤ëª… í¬í•¨ ê²€ìƒ‰ì„ ìœ„í•œ ê²€ìƒ‰ ì¿¼ë¦¬ êµ¬ì„±
        if target_service_name:
            enhanced_query = f'(service_name:"{target_service_name}" OR service_name:*{target_service_name}*)'
            if query != target_service_name:
                enhanced_query += f" AND ({query})"
        else:
            enhanced_query = query
            
        results = search_client.search(
            search_text=enhanced_query,
            top=top_k,
            include_total_count=True,
            select=[
                "incident_id", "service_name", "error_time", "notice_text", 
                "error_date", "week", "daynight", "incident_cause", "incident_repair", 
                "incident_plan", "cause_type", "done_type", "incident_grade", 
                "owner_depart", "fail_type", "year", "month"
            ]
        )
        
        documents = []
        for result in results:
            score = result.get("@search.score", 0)
            if score >= 0.1:  # ë§¤ìš° ë‚®ì€ ê¸°ì¤€
                doc_service_name = result.get("service_name", "").strip()
                
                # ì„œë¹„ìŠ¤ëª… í¬í•¨ í•„í„°ë§ (ëŒ€ì²´ ê²€ìƒ‰ì—ì„œë„ ì ìš©)
                if target_service_name:
                    if not (doc_service_name.lower() == target_service_name.lower() or 
                           target_service_name.lower() in doc_service_name.lower() or 
                           doc_service_name.lower() in target_service_name.lower()):
                        continue
                    
                documents.append({
                    "incident_id": result.get("incident_id", ""),
                    "service_name": doc_service_name,
                    "error_time": result.get("error_time", 0),
                    "notice_text": result.get("notice_text", ""),
                    "error_date": result.get("error_date", ""),
                    "week": result.get("week", ""),
                    "daynight": result.get("daynight", ""),
                    "incident_cause": result.get("incident_cause", ""),
                    "incident_repair": result.get("incident_repair", ""),
                    "incident_plan": result.get("incident_plan", ""),
                    "cause_type": result.get("cause_type", ""),
                    "done_type": result.get("done_type", ""),
                    "incident_grade": result.get("incident_grade", ""),
                    "owner_depart": result.get("owner_depart", ""),
                    "fail_type": result.get("fail_type", ""),
                    "year": result.get("year", ""),
                    "month": result.get("month", ""),
                    "score": score,
                    "reranker_score": 0,
                    "final_score": score,
                    "quality_tier": "Basic",
                    "filter_reason": "ëŒ€ì²´ ê²€ìƒ‰ í†µê³¼ (í¬í•¨ ë§¤ì¹­)",
                    "service_match_type": "partial" if target_service_name else "all"
                })
        
        return documents[:8]  # ìµœëŒ€ 8ê°œê¹Œì§€
        
    except Exception as e:
        st.error(f"ëŒ€ì²´ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
        return []

# ê°œì„ ëœ RAG ì‘ë‹µ ìƒì„± - ì •í™•í•œ ì§‘ê³„ ì •ë³´ í¬í•¨
def generate_rag_response_with_accurate_count(azure_openai_client, query, documents, model_name, query_type="default"):
    try:
        # ë¬¸ì„œ ê°œìˆ˜ ë° ë…„ë„ë³„ ì§‘ê³„ ë¯¸ë¦¬ ê³„ì‚°
        total_count = len(documents)
        yearly_stats = {}
        
        # ë…„ë„ë³„ ì§‘ê³„ ê³„ì‚°
        for doc in documents:
            # error_dateì—ì„œ ë…„ë„ ì¶”ì¶œ (YYYY-MM-DD í˜•íƒœ)
            error_date = doc.get('error_date', '')
            year_from_date = None
            if error_date and len(error_date) >= 4:
                try:
                    year_from_date = int(error_date[:4])
                except:
                    pass
            
            # year í•„ë“œë„ í™•ì¸
            year_from_field = doc.get('year', '')
            if year_from_field:
                try:
                    year_from_field = int(year_from_field)
                except:
                    year_from_field = None
            
            # ìš°ì„ ìˆœìœ„: error_date > year í•„ë“œ
            final_year = year_from_date or year_from_field
            
            if final_year:
                yearly_stats[final_year] = yearly_stats.get(final_year, 0) + 1
        
        # ì§‘ê³„ ê²€ì¦
        yearly_total = sum(yearly_stats.values())
        
        # ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ ì»¨í…ìŠ¤íŠ¸ë¡œ êµ¬ì„± (í’ˆì§ˆ ì •ë³´ + ì§‘ê³„ ì •ë³´ í¬í•¨)
        context_parts = []
        
        # ì§‘ê³„ ì •ë³´ë¥¼ ì»¨í…ìŠ¤íŠ¸ ìƒë‹¨ì— ì¶”ê°€
        stats_info = f"""
=== ì •í™•í•œ ì§‘ê³„ ì •ë³´ ===
ì „ì²´ ë¬¸ì„œ ìˆ˜: {total_count}ê±´
ë…„ë„ë³„ ë¶„í¬: {dict(sorted(yearly_stats.items()))}
ë…„ë„ë³„ í•©ê³„: {yearly_total}ê±´
ì§‘ê³„ ê²€ì¦: {'ì¼ì¹˜' if yearly_total == total_count else 'ë¶ˆì¼ì¹˜ - ì¬ê³„ì‚° í•„ìš”'}
===========================
"""
        context_parts.append(stats_info)
        
        for i, doc in enumerate(documents):
            final_score = doc.get('final_score', 0)
            quality_tier = doc.get('quality_tier', 'Standard')
            filter_reason = doc.get('filter_reason', 'ê¸°ë³¸ ì„ ë³„')
            service_match_type = doc.get('service_match_type', 'unknown')
            
            context_part = f"""ë¬¸ì„œ {i+1} [{quality_tier}ê¸‰ - {filter_reason} - {service_match_type} ë§¤ì¹­]:
ì¥ì•  ID: {doc['incident_id']}
ì„œë¹„ìŠ¤ëª…: {doc['service_name']}
ì¥ì• ì‹œê°„: {doc['error_time']}
ê³µì§€ì‚¬í•­: {doc['notice_text']}
ë°œìƒì¼ì: {doc['error_date']}
ìš”ì¼: {doc['week']}
ì‹œê°„ëŒ€: {doc['daynight']}
ì¥ì• ì›ì¸: {doc['incident_cause']}
ë³µêµ¬ë°©ë²•: {doc['incident_repair']}
ê°œì„ ê³„íš: {doc['incident_plan']}
ì›ì¸ìœ í˜•: {doc['cause_type']}
ì²˜ë¦¬ìœ í˜•: {doc['done_type']}
ì¥ì• ë“±ê¸‰: {doc['incident_grade']}
ë‹´ë‹¹ë¶€ì„œ: {doc['owner_depart']}
ì¥ì• ìœ í˜•: {doc['fail_type']}
ë…„ë„: {doc['year']}
ì›”: {doc['month']}
í’ˆì§ˆì ìˆ˜: {final_score:.2f}
"""
            context_parts.append(context_part)
        
        context = "\n\n".join(context_parts)
        
        # ì§ˆë¬¸ íƒ€ì…ì— ë”°ë¥¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„ íƒ
        system_prompt = SYSTEM_PROMPTS.get(query_type, SYSTEM_PROMPTS["default"])

        user_prompt = f"""
ë‹¤ìŒ ì¥ì•  ì´ë ¥ ë¬¸ì„œë“¤ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.
(ëª¨ë“  ë¬¸ì„œëŠ” ì„œë¹„ìŠ¤ëª… í¬í•¨ ë§¤ì¹­ + ë™ì  ì„ê³„ê°’ ê¸°ë°˜ ê³ í’ˆì§ˆ í•„í„°ë§ì„ í†µê³¼í•œ ê²€ìƒ‰ ê²°ê³¼ì…ë‹ˆë‹¤):

ì¤‘ìš”! ì§‘ê³„ ê´€ë ¨ ì§ˆë¬¸ì¸ ê²½ìš° ìœ„ì˜ "ì •í™•í•œ ì§‘ê³„ ì •ë³´" ì„¹ì…˜ì„ ì°¸ì¡°í•˜ì—¬ ì •í™•í•œ ìˆ«ìë¥¼ ì œê³µí•˜ì„¸ìš”.
- ì „ì²´ ê±´ìˆ˜: {total_count}ê±´
- ë…„ë„ë³„ ê±´ìˆ˜: {dict(sorted(yearly_stats.items()))}
- ë°˜ë“œì‹œ ë…„ë„ë³„ í•©ê³„ê°€ ì „ì²´ ê±´ìˆ˜ì™€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.

{context}

ì§ˆë¬¸: {query}

ë‹µë³€:"""

        # Azure OpenAI API í˜¸ì¶œ
        response = azure_openai_client.chat.completions.create(
            model=model_name,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.1,  # ì •í™•í•œ ì§‘ê³„ë¥¼ ìœ„í•´ temperature ë‚®ì¶¤
            max_tokens=1500
        )
        
        return response.choices[0].message.content
    
    except Exception as e:
        st.error(f"ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {str(e)}")
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

# ì„œë¹„ìŠ¤ëª… í¬í•¨ ê²€ìƒ‰ì„ ì§€ì›í•˜ëŠ” ê°œì„ ëœ ì¿¼ë¦¬ ì²˜ë¦¬ í•¨ìˆ˜
def process_query_with_enhanced_filtering(query, query_type="default"):
    """ì„œë¹„ìŠ¤ëª… í¬í•¨ ê²€ìƒ‰ì„ ì§€ì›í•˜ëŠ” ê°œì„ ëœ ì¿¼ë¦¬ ì²˜ë¦¬"""
    with st.chat_message("assistant"):
        # ì„œë¹„ìŠ¤ëª… ì¶”ì¶œ
        target_service_name = extract_service_name_from_query(query)
        
        if target_service_name:
            st.success(f"ğŸ¯ ê°ì§€ëœ ëŒ€ìƒ ì„œë¹„ìŠ¤: **{target_service_name}** (ì •í™•/í¬í•¨ ë§¤ì¹­ ëª¨ë‘ ì§€ì›)")
        
        with st.spinner("ğŸ¯ ì„œë¹„ìŠ¤ëª… í¬í•¨ ë§¤ì¹­ + ë™ì  ì„ê³„ê°’ ê¸°ë°˜ ê³ í’ˆì§ˆ ê²€ìƒ‰ ì¤‘..."):
            # ê°œì„ ëœ ê²€ìƒ‰ í•¨ìˆ˜ í˜¸ì¶œ
            documents = semantic_search_with_service_filter(
                search_client, query, target_service_name, query_type
            )
            
            if documents:
                # ì„œë¹„ìŠ¤ëª… ë§¤ì¹­ ê²€ì¦ ë° ë¶„ë¥˜
                exact_matches = [doc for doc in documents if doc.get('service_match_type') == 'exact']
                partial_matches = [doc for doc in documents if doc.get('service_match_type') == 'partial']
                
                if exact_matches and partial_matches:
                    st.success(f"âœ… '{target_service_name}' ì„œë¹„ìŠ¤: ì •í™• ë§¤ì¹­ {len(exact_matches)}ê°œ, í¬í•¨ ë§¤ì¹­ {len(partial_matches)}ê°œ")
                elif exact_matches:
                    st.success(f"âœ… '{target_service_name}' ì„œë¹„ìŠ¤: ì •í™• ë§¤ì¹­ {len(exact_matches)}ê°œ")
                elif partial_matches:
                    st.info(f"ğŸ“‹ '{target_service_name}' ì„œë¹„ìŠ¤: í¬í•¨ ë§¤ì¹­ {len(partial_matches)}ê°œ")
                elif target_service_name:
                    st.info(f"ğŸ“‹ '{target_service_name}' ê´€ë ¨ {len(documents)}ê°œ ë¬¸ì„œê°€ ì„ ë³„ë˜ì—ˆìŠµë‹ˆë‹¤.")
                
                premium_count = sum(1 for doc in documents if doc.get('quality_tier') == 'Premium')
                standard_count = sum(1 for doc in documents if doc.get('quality_tier') == 'Standard')
                basic_count = sum(1 for doc in documents if doc.get('quality_tier') == 'Basic')
                
                # ì§‘ê³„ ê´€ë ¨ ì§ˆë¬¸ì¸ì§€ í™•ì¸
                is_count_query = any(keyword in query.lower() for keyword in ['ê±´ìˆ˜', 'ê°œìˆ˜', 'ëª‡ê±´', 'ë…„ë„ë³„', 'ì›”ë³„', 'í†µê³„', 'í˜„í™©'])
                
                # ì§‘ê³„ ë¯¸ë¦¬ë³´ê¸° (ì§‘ê³„ ê´€ë ¨ ì§ˆë¬¸ì¸ ê²½ìš°)
                if is_count_query:
                    yearly_stats = {}
                    for doc in documents:
                        error_date = doc.get('error_date', '')
                        year_from_date = None
                        if error_date and len(error_date) >= 4:
                            try:
                                year_from_date = int(error_date[:4])
                            except:
                                pass
                        
                        year_from_field = doc.get('year', '')
                        if year_from_field:
                            try:
                                year_from_field = int(year_from_field)
                            except:
                                year_from_field = None
                        
                        final_year = year_from_date or year_from_field
                        if final_year:
                            yearly_stats[final_year] = yearly_stats.get(final_year, 0) + 1
                    
                    yearly_total = sum(yearly_stats.values())
                    st.info(f"""
                    ğŸ“Š **ì§‘ê³„ ë¯¸ë¦¬ë³´ê¸°**
                    - ì „ì²´ ê±´ìˆ˜: {len(documents)}ê±´
                    - ë…„ë„ë³„ ë¶„í¬: {dict(sorted(yearly_stats.items()))}
                    - ë…„ë„ë³„ í•©ê³„: {yearly_total}ê±´
                    - ê²€ì¦ ìƒíƒœ: {'âœ… ì¼ì¹˜' if yearly_total == len(documents) else 'âŒ ë¶ˆì¼ì¹˜'}
                    """)
                
                st.success(f"ğŸ† {len(documents)}ê°œì˜ ë§¤ì¹­ ë¬¸ì„œ ì„ ë³„ ì™„ë£Œ! (Premium: {premium_count}ê°œ, Standard: {standard_count}ê°œ, Basic: {basic_count}ê°œ)")
                
                # ê²€ìƒ‰ëœ ë¬¸ì„œ í‘œì‹œ
                with st.expander("ğŸ” ë§¤ì¹­ëœ ë¬¸ì„œ ë³´ê¸°"):
                    display_documents_with_quality_info(documents)
                
                # RAG ì‘ë‹µ ìƒì„±
                with st.spinner("ğŸ’¡ í¬í•¨ ë§¤ì¹­ ê¸°ë°˜ ë‹µë³€ ìƒì„± ì¤‘..."):
                    response = generate_rag_response_with_accurate_count(
                        azure_openai_client, query, documents, azure_openai_model, query_type
                    )
                    
                    with st.expander("ğŸ¤– AI ë‹µë³€ ë³´ê¸° (í¬í•¨ ë§¤ì¹­ ì§€ì›)", expanded=True):
                        st.write(response)
                        match_info = "ì •í™•/í¬í•¨ ë§¤ì¹­" if exact_matches and partial_matches else "ì •í™• ë§¤ì¹­" if exact_matches else "í¬í•¨ ë§¤ì¹­"
                        st.info(f"âœ¨ ì´ ë‹µë³€ì€ '{target_service_name or 'ëª¨ë“  ì„œë¹„ìŠ¤'}'ì— {match_info}ëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    
                    st.session_state.messages.append({"role": "assistant", "content": response})
            else:
                # ëŒ€ì²´ ê²€ìƒ‰ ì‹œë„
                st.warning("ğŸ”„ í¬í•¨ ë§¤ì¹­ìœ¼ë¡œë„ ê²°ê³¼ê°€ ì—†ì–´ ë” ê´€ëŒ€í•œ ê¸°ì¤€ìœ¼ë¡œ ì¬ê²€ìƒ‰ ì¤‘...")
                
                # ë§¤ìš° ê´€ëŒ€í•œ ê¸°ì¤€ìœ¼ë¡œ ì¬ê²€ìƒ‰ (ì„œë¹„ìŠ¤ëª… í¬í•¨ í•„í„°ë§ ìœ ì§€)
                fallback_documents = search_documents_fallback(search_client, query, target_service_name)
                
                if fallback_documents:
                    st.info(f"ğŸ“‹ ëŒ€ì²´ ê²€ìƒ‰ìœ¼ë¡œ {len(fallback_documents)}ê°œ ë¬¸ì„œ ë°œê²¬")
                    
                    response = generate_rag_response_with_accurate_count(
                        azure_openai_client, query, fallback_documents, azure_openai_model, query_type
                    )
                    with st.expander("ğŸ¤– AI ë‹µë³€ ë³´ê¸° (ëŒ€ì²´ ê²€ìƒ‰)", expanded=True):
                        st.write(response)
                        st.warning(f"âš ï¸ ì´ ë‹µë³€ì€ '{target_service_name or 'í•´ë‹¹ ì¡°ê±´'}'ì— ëŒ€í•œ ê´€ëŒ€í•œ ê¸°ì¤€ì˜ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    st.session_state.messages.append({"role": "assistant", "content": response})
                else:
                    error_msg = f"""
                    ğŸ” '{target_service_name or 'í•´ë‹¹ ì¡°ê±´'}'ì— í•´ë‹¹í•˜ëŠ” ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
                    
                    **ê°œì„  ë°©ì•ˆ:**
                    - ì„œë¹„ìŠ¤ëª…ì˜ ì¼ë¶€ë§Œ ì…ë ¥í•´ë³´ì„¸ìš” (ì˜ˆ: 'API' ëŒ€ì‹  'API_Link')
                    - ë‹¤ë¥¸ ê²€ìƒ‰ì–´ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”
                    - ì „ì²´ ê²€ìƒ‰ì„ ì›í•˜ì‹œë©´ ì„œë¹„ìŠ¤ëª…ì„ ì œì™¸í•˜ê³  ê²€ìƒ‰í•´ì£¼ì„¸ìš”
                    
                    **ì°¸ê³ **: í˜„ì¬ ì‹œìŠ¤í…œì€ ì„œë¹„ìŠ¤ëª… ì •í™• ë§¤ì¹­ê³¼ í¬í•¨ ë§¤ì¹­ì„ ëª¨ë‘ ì§€ì›í•©ë‹ˆë‹¤.
                    """
                    with st.expander("ğŸ¤– AI ë‹µë³€ ë³´ê¸°", expanded=True):
                        st.write(error_msg)
                    st.session_state.messages.append({"role": "assistant", "content": error_msg})

# ê³ ê¸‰ ë¬¸ì„œ í‘œì‹œ í•¨ìˆ˜ (ì„œë¹„ìŠ¤ ë§¤ì¹­ íƒ€ì… ì •ë³´ í¬í•¨)
def display_documents_with_quality_info(documents):
    """í’ˆì§ˆ ì •ë³´ì™€ ì„œë¹„ìŠ¤ ë§¤ì¹­ íƒ€ì…ê³¼ í•¨ê»˜ ë¬¸ì„œ í‘œì‹œ"""
    for i, doc in enumerate(documents):
        quality_tier = doc.get('quality_tier', 'Standard')
        filter_reason = doc.get('filter_reason', 'ê¸°ë³¸ ì„ ë³„')
        service_match_type = doc.get('service_match_type', 'unknown')
        search_score = doc.get('score', 0)
        reranker_score = doc.get('reranker_score', 0)
        final_score = doc.get('final_score', 0)
        
        # í’ˆì§ˆ ë“±ê¸‰ì— ë”°ë¥¸ ì´ëª¨ì§€ì™€ ìƒ‰ìƒ
        if quality_tier == 'Premium':
            tier_emoji = "ğŸ†"
            tier_color = "ğŸŸ¢"
        elif quality_tier == 'Standard':
            tier_emoji = "ğŸ¯"
            tier_color = "ğŸŸ¡"
        else:
            tier_emoji = "ğŸ“‹"
            tier_color = "ğŸ”µ"
        
        # ì„œë¹„ìŠ¤ ë§¤ì¹­ íƒ€ì…ì— ë”°ë¥¸ í‘œì‹œ
        match_emoji = {"exact": "ğŸ¯", "partial": "ğŸ”", "all": "ğŸ“‹"}.get(service_match_type, "â“")
        match_label = {"exact": "ì •í™• ë§¤ì¹­", "partial": "í¬í•¨ ë§¤ì¹­", "all": "ì „ì²´", "unknown": "ì•Œ ìˆ˜ ì—†ìŒ"}.get(service_match_type, "ì•Œ ìˆ˜ ì—†ìŒ")
        
        st.markdown(f"### {tier_emoji} **ë¬¸ì„œ {i+1}** - {quality_tier}ê¸‰ {tier_color} {match_emoji} {match_label}")
        st.markdown(f"**ì„ ë³„ ê¸°ì¤€**: {filter_reason}")
        
        # ì ìˆ˜ ì •ë³´ í‘œì‹œ
        score_col1, score_col2, score_col3 = st.columns(3)
        with score_col1:
            st.metric("ê²€ìƒ‰ ì ìˆ˜", f"{search_score:.2f}")
        with score_col2:
            if reranker_score > 0:
                st.metric("Reranker ì ìˆ˜", f"{reranker_score:.2f}")
            else:
                st.metric("Reranker ì ìˆ˜", "N/A")
        with score_col3:
            st.metric("ìµœì¢… ì ìˆ˜", f"{final_score:.2f}")
        
        # ì£¼ìš” ì •ë³´ í‘œì‹œ
        col1, col2 = st.columns(2)
        with col1:
            st.write(f"**ì¥ì•  ID**: {doc['incident_id']}")
            st.write(f"**ì„œë¹„ìŠ¤ëª…**: {doc['service_name']}")
            st.write(f"**ë°œìƒì¼ì**: {doc['error_date']}")
            st.write(f"**ì¥ì• ì‹œê°„**: {doc['error_time']}ë¶„")
            
        with col2:
            st.write(f"**ì¥ì•  ë“±ê¸‰**: {doc['incident_grade']}")
            st.write(f"**ì›ì¸ ìœ í˜•**: {doc['cause_type']}")
            st.write(f"**ì²˜ë¦¬ ìœ í˜•**: {doc['done_type']}")
            st.write(f"**ë‹´ë‹¹ ë¶€ì„œ**: {doc['owner_depart']}")
        
        if doc['notice_text']:
            st.write(f"**ê³µì§€ì‚¬í•­**: {doc['notice_text'][:200]}...")
        if doc['incident_cause']:
            st.write(f"**ì¥ì•  ì›ì¸**: {doc['incident_cause'][:200]}...")
        if doc['incident_repair']:
            st.write(f"**ë³µêµ¬ ë°©ë²•**: {doc['incident_repair'][:200]}...")
        
        st.markdown("---")

# ì…ë ¥ ê²€ì¦ í•¨ìˆ˜
def validate_inputs(service_name, incident_symptom):
    """ì„œë¹„ìŠ¤ëª…, ì¥ì• í˜„ìƒ ì…ë ¥ ê²€ì¦"""
    if not service_name or not service_name.strip():
        st.error("âŒ ì„œë¹„ìŠ¤ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”!")
        return False
    if not incident_symptom or not incident_symptom.strip():
        st.error("âŒ ì¥ì• í˜„ìƒì„ ì…ë ¥í•´ì£¼ì„¸ìš”!")
        return False
    return True

# ê²€ìƒ‰ ì¿¼ë¦¬ êµ¬ì„± í•¨ìˆ˜
def build_search_query(service_name, incident_symptom):
    """ê¸°ë³¸ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ êµ¬ì„±"""
    return f"{service_name} {incident_symptom}"

# ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œì§
if all([azure_openai_endpoint, azure_openai_key, search_endpoint, search_key, search_index]):
    # í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    azure_openai_client, search_client, init_success = init_clients(
        azure_openai_endpoint, azure_openai_key, azure_openai_api_version,
        search_endpoint, search_key, search_index
    )
    
    if init_success:
        # =================== ìƒë‹¨ ê³ ì • ì˜ì—­ ì‹œì‘ ===================
        with st.container():
           
            # ì„œë¹„ìŠ¤ ì •ë³´ ì…ë ¥ ì„¹ì…˜
            st.header("ğŸ“ ì„œë¹„ìŠ¤ ì •ë³´ ì…ë ¥")
            
            # ì„œë¹„ìŠ¤ëª…ê³¼ ì¥ì• í˜„ìƒ ì…ë ¥
            input_col1, input_col2 = st.columns(2)
            
            with input_col1:
                service_name = st.text_input("ì„œë¹„ìŠ¤ëª…ì„ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: API_Link_GW, ë§ˆì´í˜ì´ì§€, íŒ¨ë°€ë¦¬ë°•ìŠ¤")
            
            with input_col2:
                incident_symptom = st.text_input("ì¥ì• í˜„ìƒì„ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: ì ‘ì†ë¶ˆê°€, ì‘ë‹µì§€ì—°, ì˜¤ë¥˜ë°œìƒ")
            
            # ì…ë ¥ëœ ì •ë³´ í™•ì¸ ë° í‘œì‹œ
            if service_name and incident_symptom:
                st.success(f"ì„œë¹„ìŠ¤: {service_name} | ì¥ì• í˜„ìƒ: {incident_symptom}")
            elif service_name or incident_symptom:
                missing = []
                if not service_name:
                    missing.append("ì„œë¹„ìŠ¤ëª…")
                if not incident_symptom:
                    missing.append("ì¥ì• í˜„ìƒ")
                st.info(f"âš ï¸ {', '.join(missing)}ì„(ë¥¼) ì…ë ¥í•´ì£¼ì„¸ìš”.")
            
            # ì£¼ìš” ì§ˆë¬¸ ë²„íŠ¼ë“¤
            st.header("ğŸ” ì£¼ìš” ì§ˆë¬¸")

            # ìŠ¤íƒ€ì¼ CSS ì¶”ê°€
            st.markdown("""
                <style>
                div[data-baseweb="input"] > div {
                    font-size: 40px;
                    height: 40px;
                }
                 
                div.stButton > button:first-child {
                    font-size: 40px;
                    height: 60px;
                    width: 450px;
                    background-color: #4CAF50;
                    color: white;
                    border-radius: 10px;
                }
                </style>
            """, unsafe_allow_html=True)

            col1, col2 = st.columns(2)
            
            with col1:
                if st.button("ğŸ”§ ì„œë¹„ìŠ¤ì™€ í˜„ìƒì— ëŒ€í•´ ë³µêµ¬ ë°©ë²• ì•ˆë‚´", key="repair_btn"):
                    if validate_inputs(service_name, incident_symptom):
                        search_query = build_search_query(service_name, incident_symptom)
                        st.session_state.sample_query = f"{search_query}ì— ëŒ€í•œ ì¥ì• ë¥¼ í•´ì†Œí•˜ê¸° ìœ„í•œ ê·¼ë³¸ì ì¸ ë³µêµ¬ë°©ë²•ë§Œ í‘œê¸°í•´ì„œ ë³µêµ¬ë°©ë²• ì•ˆë‚´"
                        st.session_state.query_type = "repair"
                
            with col2:
                if st.button("ğŸ”„ ë™ì¼ í˜„ìƒì— ëŒ€í•œ ë³µêµ¬ ë°©ë²• ì°¸ì¡°", key="similar_btn"):
                    if validate_inputs(service_name, incident_symptom):
                        search_query = build_search_query("", incident_symptom)
                        st.session_state.sample_query = f"{incident_symptom} ë™ì¼ í˜„ìƒì— ëŒ€í•œ ì¥ì• ë¥¼ í•´ì†Œí•˜ê¸° ìœ„í•œ ê·¼ë³¸ì ì¸ ë³µêµ¬ë°©ë²•ë§Œ í‘œê¸°í•´ì„œ ë³µêµ¬ë°©ë²• ì•ˆë‚´"
                        st.session_state.query_type = "similar"

        # =================== ìƒë‹¨ ê³ ì • ì˜ì—­ ë ===================
        
        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        if 'messages' not in st.session_state:
            st.session_state.messages = []
        
        # ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ ì˜ì—­
        chat_container = st.container()
        
        with chat_container:
            # ì´ì „ ë©”ì‹œì§€ í‘œì‹œ
            for message in st.session_state.messages:
                with st.chat_message(message["role"]):
                    if message["role"] == "assistant":
                        with st.expander("ğŸ¤– AI ë‹µë³€ ë³´ê¸°", expanded=True):
                            st.write(message["content"])
                    else:
                        st.write(message["content"])
        
        # ì‚¬ìš©ì ì…ë ¥
        user_query = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: API_Link_GW ë…„ë„ë³„ ê±´ìˆ˜ ì•Œë ¤ì¤˜)")
        
        if user_query:
            st.session_state.messages.append({"role": "user", "content": user_query})
            
            with st.chat_message("user"):
                st.write(user_query)
            
            process_query_with_enhanced_filtering(user_query, "default")

        # ì£¼ìš” ì§ˆë¬¸ ì²˜ë¦¬
        if 'sample_query' in st.session_state:
            query = st.session_state.sample_query
            query_type = st.session_state.get('query_type', 'default')
            
            del st.session_state.sample_query
            if 'query_type' in st.session_state:
                del st.session_state.query_type
            
            st.session_state.messages.append({"role": "user", "content": query})
            
            with st.chat_message("user"):
                st.write(query)
            
            process_query_with_enhanced_filtering(query, query_type)
            st.rerun()

    else:
        st.error("Azure ì„œë¹„ìŠ¤ ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.info("""
        **í•„ìš”í•œ í™˜ê²½ë³€ìˆ˜:**
        - OPENAI_ENDPOINT: Azure OpenAI ì—”ë“œí¬ì¸íŠ¸
        - OPENAI_KEY: Azure OpenAI API í‚¤
        - OPENAI_API_VERSION: API ë²„ì „ (ê¸°ë³¸ê°’: 2024-02-01)
        - CHAT_MODEL: ëª¨ë¸ëª… (ê¸°ë³¸ê°’: iap-gpt-4o-mini)
        - SEARCH_ENDPOINT: Azure AI Search ì—”ë“œí¬ì¸íŠ¸
        - SEARCH_API_KEY: Azure AI Search API í‚¤
        - INDEX_SINGLE_NAME: ê²€ìƒ‰ ì¸ë±ìŠ¤ëª…
        """)
        
        # í™˜ê²½ë³€ìˆ˜ ìƒíƒœ í‘œì‹œ
        env_status = {
            "OPENAI_ENDPOINT": "âœ…" if azure_openai_endpoint else "âŒ",
            "OPENAI_KEY": "âœ…" if azure_openai_key else "âŒ", 
            "SEARCH_ENDPOINT": "âœ…" if search_endpoint else "âŒ",
            "SEARCH_API_KEY": "âœ…" if search_key else "âŒ",
            "INDEX_SINGLE_NAME": "âœ…" if search_index else "âŒ"
        }
        
        st.write("**í™˜ê²½ë³€ìˆ˜ ìƒíƒœ:**")
        for var, status in env_status.items():
            st.write(f"{status} {var}")

else:
    st.error("í™˜ê²½ë³€ìˆ˜ ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    st.info("""
    **ì„¤ì •í•´ì•¼ í•  í™˜ê²½ë³€ìˆ˜:**
    - OPENAI_ENDPOINT: Azure OpenAI ì—”ë“œí¬ì¸íŠ¸ URL
    - OPENAI_KEY: Azure OpenAI API í‚¤
    - SEARCH_ENDPOINT: Azure AI Search ì—”ë“œí¬ì¸íŠ¸ URL  
    - SEARCH_API_KEY: Azure AI Search API í‚¤
    - INDEX_SINGLE_NAME: ê²€ìƒ‰í•  ì¸ë±ìŠ¤ëª…
    
    **.env íŒŒì¼ ì˜ˆì‹œ:**
    ```
    OPENAI_ENDPOINT=https://your-openai-resource.openai.azure.com/
    OPENAI_KEY=your-openai-api-key
    OPENAI_API_VERSION=2024-02-01
    CHAT_MODEL=iap-gpt-4o-mini
    SEARCH_ENDPOINT=https://your-search-service.search.windows.net
    SEARCH_API_KEY=your-search-api-key
    INDEX_SINGLE_NAME=your-index-name
    ```
    """)