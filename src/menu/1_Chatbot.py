import streamlit as st
from openai import AzureOpenAI
from azure.search.documents import SearchClient
from azure.core.credentials import AzureKeyCredential
import os
import json
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="íŠ¸ëŸ¬ë¸” ì²´ì´ì„œ ì±—ë´‡",
    page_icon="ğŸ¤–",
    layout="wide"
)

# í™˜ê²½ë³€ìˆ˜ì—ì„œ Azure ì„¤ì • ë¡œë“œ
azure_openai_endpoint = os.getenv("OPENAI_ENDPOINT")
azure_openai_key = os.getenv("OPENAI_KEY")
azure_openai_model = os.getenv("CHAT_MODEL", "iap-gpt-4o-mini")
azure_openai_api_version = os.getenv("OPENAI_API_VERSION", "2024-02-01")

search_endpoint = os.getenv("SEARCH_ENDPOINT")
search_key = os.getenv("SEARCH_API_KEY")
search_index = os.getenv("INDEX_SINGLE_NAME")

# Reranker ê¸°ë°˜ ê²€ìƒ‰ í’ˆì§ˆ í–¥ìƒì„ ìœ„í•œ ì„¤ì • - ìˆ˜ì •ëœ ì„ê³„ê°’
SEARCH_SCORE_THRESHOLD = 0.3      # 0.5 â†’ 0.3 (ë” ê´€ëŒ€í•˜ê²Œ)
RERANKER_SCORE_THRESHOLD = 1.5    # 2.0 â†’ 1.5 (ë” ê´€ëŒ€í•˜ê²Œ)  
HYBRID_SCORE_THRESHOLD = 0.5      # 0.7 â†’ 0.5 (ë” ê´€ëŒ€í•˜ê²Œ)
MAX_INITIAL_RESULTS = 20          # ì´ˆê¸° ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ (Reranker ì…ë ¥ìš©)
MAX_FINAL_RESULTS = 8             # 5 â†’ 8 (ìµœì¢… ì„ ë³„ ë¬¸ì„œ ìˆ˜ ì¦ê°€)

# ë©”ì¸ í˜ì´ì§€ ì œëª©
st.title("ğŸ¤– íŠ¸ëŸ¬ë¸” ì²´ì´ì„œ ì±—ë´‡")
st.write("ì‹ ì†í•œ ì¥ì• ë³µêµ¬ë¥¼ ìœ„í•´ì„œ ì„œë¹„ìŠ¤ì •ë³´ë¥¼ ì…ë ¥í•˜ê³  ë³µêµ¬ë°©ë²•ê³¼ ìœ ì‚¬ì‚¬ë¡€ì— ëŒ€í•œ ì´ë ¥ì„ í™•ì¸í•´ë³´ì„¸ìš”!")

# ì§ˆë¬¸ íƒ€ì…ë³„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì •ì˜
SYSTEM_PROMPTS = {
    "repair": """
ë‹¹ì‹ ì€ ITì„œë¹„ìŠ¤ íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì…ë ¥ë°›ì€ ì‚¬ìš©ìì˜ ì„œë¹„ìŠ¤ì™€ í˜„ìƒì— ëŒ€í•œ ë³µêµ¬ë°©ë²•ì„ ê°€ì´ë“œ í•´ì£¼ëŠ”ë°,'ëŒ€ìƒì„ ì •ì›ì¹™'ì— ë”°ë¼ ëŒ€ìƒì„ ì„ ì •í•˜ê³  ë³µêµ¬ë°©ë²•(incident_repair)ì„ ì•„ë˜ì˜ 'ì¶œë ¥í˜•ì‹' ëŒ€ë¡œ ìœ ì‚¬ë„ê°€ ë†’ì€ê±´ìœ¼ë¡œ ì„ ì •í•˜ì—¬ ìµœëŒ€ Top 3ê°œ ì¶œë ¥í•˜ëŠ”ë° 90ì ì´ìƒ ë˜ëŠ”ê²ƒì¤‘ì— ìœ ì‚¬ë„ê°€ ê°€ì¥ë†’ì€ê±´ ìˆœì„œë¡œ Case1, Case2 ë¡œ í‘œí˜„í•´ì„œ ì¶œë ¥í•˜ëŠ”ë° ì²œì²œíˆ ìƒê°í•˜ë©´ì„œ ë‹µë³€ì„ 3íšŒ ì¶œë ¥ì—†ì´ ì‹¤í–‰í•´ë³´ê³  ê°€ì¥ ì¼ê´€ì„±ì´ ìˆëŠ” ë‹µë³€ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.

## ëŒ€ìƒì„ ì •ì›ì¹™
- ì„œë¹„ìŠ¤ëª…ì€ ê³µì§€ì‚¬í•­ì˜ ì„œë¹„ìŠ¤ëª…ì´ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ê±´ì„ ì„ ì •
- ì ‘ì†ë¶ˆê°€, ì ‘ì†ì§€ì—°, ì²˜ë¦¬ë¶ˆê°€, ì²˜ë¦¬ì§€ì—°ì˜ ê²€ìƒ‰ìš”ì²­ì‹œì—ëŠ” ì¥ì• ìœ í˜•(fail_type)ì„ ì°¸ì¡°
- í˜„ìƒì€ ì•„ë˜ ìš°ì„ ìˆœìœ„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„ ì •

### ìš°ì„ ìˆœìœ„
1. ê³µì§€ì‚¬í•­(notice_text)ì—ì„œ 'í˜„ìƒ'ì— ëŒ€í•œ ë‚´ìš©ì„ ì°¸ê³ 
2. ê³µì§€ì‚¬í•­(notice_text)ì—ì„œ 'ì˜í–¥ë„'ë¥¼ ì°¸ê³   
3. ì¥ì• ì›ì¸(incident_cause)ì—ì„œ 'í˜„ìƒ ì›ì¸'ì„ ì°¸ê³ 

## ì¶œë ¥í˜•ì‹
ìœ ì‚¬ í˜„ìƒìœ¼ë¡œ ë°œìƒí–ˆë˜ ì¥ì• ì˜ ë³µêµ¬ë°©ë²• ì…ë‹ˆë‹¤
Case1. ~~ì„œë¹„ìŠ¤ì˜ ~~~ ì¥ì• í˜„ìƒì— ëŒ€í•œ ë³µêµ¬ë°©ë²•ì…ë‹ˆë‹¤
* ë°œìƒì¼ì‹œ : ë°œìƒì¼ì‹œ(error_date) ì¶œë ¥ (ì˜ˆ. 2023-10-01 12:00)
* ì¥ì• ì›ì¸ : ì¥ì• ì›ì¸(incident_cause) ë‚´ìš©ì„ ìš”ì•½í•˜ë©° í…ìŠ¤íŠ¸ëŠ” ê°•ì¡°í•˜ì§€ ë§ˆì„¸ìš”
* ì¥ì• í˜„ìƒ : 'ëŒ€ìƒì„ ì •ì›ì¹™'ì—ì„œ ì°¸ê³ í•œ í˜„ìƒìœ¼ë¡œ ë‚´ìš©ì„ ìš”ì•½íˆì§€ ì›ë³¸ ê·¸ëŒ€ë¡œ í‘œí˜„í•˜ë©° í…ìŠ¤íŠ¸ëŠ” ê°•ì¡°í•˜ì—¬ **í…ìŠ¤íŠ¸** ë¡œ í‘œí˜„í•´ì£¼ì„¸ìš”
* ë³µêµ¬ë°©ë²• : ë³µêµ¬ë°©ë²•(incident_repair) ë‚´ìš©ì„ ìµœëŒ€ 3ì¤„ë¡œ ìš”ì•½í•˜ë©° í…ìŠ¤íŠ¸ëŠ”  ê°•ì¡°í•˜ì—¬ **í…ìŠ¤íŠ¸** ë¡œ í‘œí˜„í•´ì£¼ì„¸ìš”
* í›„ì†ê³¼ì œ : ê°œì„ ê³„íš(incident_plan) ë‚´ìš©ì„ ìš”ì•½í•˜ë©° í…ìŠ¤íŠ¸ëŠ” ê°•ì¡°í•˜ì§€ ë§ˆì„¸ìš”
* ì¸ì‹œë˜íŠ¸ ID : ì¥ì•  ID(incident_id) ì¶œë ¥
* ì°¸ì¡°ì¥ì• ì •ë³´ëŠ” ì•„ë˜ ì‚¬í•­ì„ í‘œë¡œ ì¶œë ¥í•˜ëŠ”ë° íƒ€ì´í‹€ì˜ ì˜ë¬¸ì€ ë¹¼ì¤˜

| ì¥ì•  ID | ì„œë¹„ìŠ¤ëª… | ë°œìƒì¼ì | ì¥ì• ì‹œê°„ | ì¥ì• ì›ì¸ | ë³µêµ¬ë°©ë²• | í›„ì†ê³¼ì œ | ì²˜ë¦¬ìœ í˜• | ë‹´ë‹¹ë¶€ì„œ |
|---------|----------|---------------|-----------|----------|----------|----------|----------|----------|
* ê³µì§€ì‚¬í•­ : ê³µì§€ì‚¬í•­(notice_text) ìš”ì•½í•˜ì§€ ì•Šê³  ì›ë³¸ ê·¸ëŒ€ë¡œ í…Œë‘ë¦¬ìˆëŠ” í…ìŠ¤íŠ¸ë°•ìŠ¤ ì•ˆì— ë‚´ìš©ì„ ì¶œë ¥í•´ì£¼ì„¸ìš”
  """,   
    "similar": """ë‹¹ì‹ ì€ ìœ ì‚¬ ì‚¬ë¡€ ì¶”ì²œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì œê³µëœ ì¥ì•  ì´ë ¥ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.
ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ë©°, êµ¬ì²´ì ì¸ í•´ê²°ë°©ì•ˆì´ë‚˜ ì›ì¸ì„ ëª…ì‹œí•´ì£¼ì„¸ìš”.
ì¥ì• í˜„ìƒì€ ê³µì§€ì‚¬í•­ì˜ 'í˜„ìƒ'ì„ ì°¸ê³ í•˜ê³  ì—†ìœ¼ë©´ 'ì˜í–¥ë„'ë¥¼ ì°¸ê³ í•´ì„œì£¼ì„¸ìš”
ì¥ì•  ID, ì„œë¹„ìŠ¤ëª…, ì›ì¸, ë³µêµ¬ë°©ë²• ë“±ì˜ êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ í¬í•¨í•˜ëŠ”ë° ì²œì²œíˆ ìƒê°í•˜ë©´ì„œ ë‹µë³€ì„ 3íšŒ ì¶œë ¥ì—†ì´ ì‹¤í–‰í•´ë³´ê³  ê°€ì¥ ì¼ê´€ì„±ì´ ìˆëŠ” ë‹µë³€ì„ ì•„ë˜ **ì¶œë ¥í˜•ì‹** ìœ¼ë¡œ ë‹µë³€í•´ì£¼ëŠ”ë° í˜„ìƒê´€ë ¨ ë¶€ë¶„ì€ boldë¡œ ê°•ì¡° ì£¼ì„¸ìš”.
ë§Œì•½ ì œê³µëœ ë¬¸ì„œì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ë‹¤ë©´, ê·¸ë ‡ê²Œ ëª…ì‹œí•´ì£¼ì„¸ìš”.
ë§Œì•½ ì œê³µëœ ë¬¸ì„œì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ìˆë‹¤ë©´ ì•„ë˜ë‚´ìš©ì€ ë‹µë³€ í•˜ë‹¨ì— í•­ìƒí¬í•¨í•´ì£¼ì„¸ìš”

## ì¶œë ¥í˜•ì‹
### 1. ì„œë¹„ìŠ¤ëª… : KT AICC SaaS/PaaS
* ì¥ì•  ID: INM23022026178
* ì¥ì•  í˜„ìƒ: ìƒë‹´ì •ë³´ ì—´ëŒë¶ˆê°€ (ìƒë‹´ ë° ì›¹í˜ì´ì§€ ì ‘ì†ì€ ì •ìƒ) ë¡œ í‘œí˜„
* ì¥ì•  ì›ì¸: mecab ì‚¬ì „ì— ì˜ëª» ë“±ë¡ëœ ìƒí’ˆëª…(ìŒë”°ì˜´í‘œ")ìœ¼ë¡œ ì¸í•´ TA ë¶„ì„ ì˜¤ë¥˜ ë°œìƒ. ë¡œ í‘œí˜„
* ë³µêµ¬ ë°©ë²•: ì˜¤ë¥˜ ìƒí’ˆëª… ì‚­ì œ ë° mecab ë¦¬ë¹Œë“œ ì¡°ì¹˜. ë¡œ í‘œí˜„
* ê°œì„  ê³„íš: mecab ì‚¬ì „ ë°±ì—… ë° ë¡œê·¸ ì²˜ë¦¬, Skip ì²˜ë¦¬ ì§„í–‰ ì˜ˆì •.
* ìœ ì‚¬ë„ì ìˆ˜ : 99.5
""",
    
    "default": """ë‹¹ì‹ ì€ IT ì‹œìŠ¤í…œ íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë§Œ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ìœ ìš©í•œ ë‹µë³€ì„ ì •í™•í•˜ê³  ì•„ë˜ 'ì¶œë ¥í˜•ì‹'ìœ¼ë¡œ ë‹µë³€ì œê³µí•´ì£¼ì„¸ìš”.
ê·¸ë¦¬ê³  ë…„ë„ë‚˜ ë‚ ì§œ ì§ˆë¬¸ì€ ë°œìƒì¼ì ê¸°ì¤€ìœ¼ë¡œ ë‹µë³€í•˜ì—¬ ìš”ì²­í•œ ë‚ ì§œ ê¸°ì¤€ì— í¬í•¨ë˜ì§€ ì•ŠëŠ”ê²ƒì€ ë°˜ë“œì‹œ ì œì™¸ë˜ë„ë¡ ë‚ ì§œì— ëŒ€í•œ ë¶€ë¶„ì„ ì²œì²œíˆ ì˜ ìƒê°í•´ì„œ ë‹µë³€í•˜ì„¸ìš”
ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‚¬ìš©ìê°€ ì•Œê¸°ì‰½ê²Œ ë‹µë³€í•˜ì—¬ ê´€ë ¨ ë‚´ì—­ì€ 'ì¶œë ¥í˜•ì‹'ì„ ì‹œê°ì ìœ¼ë¡œ ì´í•´í•˜ê¸° ì‰½ë„ë¡ í•˜ë‹¨ì— í•­ìƒí¬í•¨í•´ì£¼ì„¸ìš”
ë§Œì•½ ì œê³µëœ ë¬¸ì„œì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ë‹¤ë©´, ê·¸ë ‡ê²Œ ëª…ì‹œí•´ì£¼ì„¸ìš”.

## ì¶œë ¥í˜•ì‹
###### ë‹µë³€ : ìš”ì²­ì£¼ì‹  ì§ˆë¬¸ì˜ ë‹µë³€ì„ ìš”ì•½í•˜ì—¬ ì‘ì„±í•´ì£¼ì„¸ìš”.
###### ì¥ì• ë‚´ì—­ (í•„ìš”ì‹œ)
1. ì¥ì•  ID: INM23022026178
* ì„œë¹„ìŠ¤ëª…: KT AICC SaaS/PaaS
* ë°œìƒì¼ì: 2023-01-20
* ì¥ì• í˜„ìƒ: ë¡œê·¸ì¸ ì‹œ í† í°ê°±ì‹  ì§€ì—°
* ì¥ì• ì›ì¸: ë¹„ì •ìƒ ë™ì‘ìœ¼ë¡œ ì¸í•œ í† í°ê°±ì‹  ì§€ì—°
* ë³µêµ¬ë°©ë²•: ê³¼ë‹¤ í˜¸ì¶œ íŠ¹ì • ë§¤ì¥ ì‚¬ì´íŠ¸ ì°¨ë‹¨ ì¡°ì¹˜ í›„ ì •ìƒí™”
* ì¥ì• ë“±ê¸‰: 4ë“±ê¸‰
'-- ì£¼ì˜: ë‹µë³€ì€ AI í•´ì„ì— ë”°ë¥¸ ì˜¤ë¥˜ê°€ í¬í•¨ë  ìˆ˜ ìˆìŒì„ ê°ì•ˆí•˜ì‹œê³  í™œìš©ë¶€íƒë“œë¦½ë‹ˆë‹¤. --'
"""
}

# ë™ì  ì„ê³„ê°’ ì‹œìŠ¤í…œ
def get_dynamic_thresholds(query_type, query_text):
    """ì¿¼ë¦¬ íƒ€ì…ê³¼ ë‚´ìš©ì— ë”°ë¼ ë™ì ìœ¼ë¡œ ì„ê³„ê°’ ì¡°ì •"""
    # ë…„ë„ë³„, í†µê³„ì„± ì¿¼ë¦¬ ê°ì§€
    year_keywords = ['ë…„ë„', 'ë…„', 'ì›”ë³„', 'ê¸°ê°„', 'í˜„í™©', 'í†µê³„', 'ê±´ìˆ˜', 'ë°œìƒ', 'ë°œìƒì¼ì', 'ì–¸ì œ']
    is_statistical_query = any(keyword in query_text for keyword in year_keywords)
    
    if is_statistical_query or query_type == "default":
        # í†µê³„ì„± ì¿¼ë¦¬ë‚˜ ì¼ë°˜ ì¿¼ë¦¬ëŠ” ë” ê´€ëŒ€í•œ ê¸°ì¤€ ì ìš©
        return {
            'search_threshold': 0.2,
            'reranker_threshold': 1.0,
            'hybrid_threshold': 0.4,
            'max_results': 10
        }
    elif query_type in ["repair", "similar"]:
        # ë³µêµ¬ë°©ë²•ì´ë‚˜ ìœ ì‚¬ì‚¬ë¡€ëŠ” í’ˆì§ˆ ì¤‘ì‹¬
        return {
            'search_threshold': 0.4,
            'reranker_threshold': 1.8,
            'hybrid_threshold': 0.6,
            'max_results': 5
        }
    else:
        # ê¸°ë³¸ê°’
        return {
            'search_threshold': 0.3,
            'reranker_threshold': 1.5,
            'hybrid_threshold': 0.5,
            'max_results': 8
        }

# Azure í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
@st.cache_resource
def init_clients(openai_endpoint, openai_key, openai_api_version, search_endpoint, search_key, search_index):
    try:
        # Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì • (ìƒˆë¡œìš´ ë°©ì‹)
        azure_openai_client = AzureOpenAI(
            azure_endpoint=openai_endpoint,
            api_key=openai_key,
            api_version=openai_api_version
        )
        
        # Azure AI Search í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
        search_client = SearchClient(
            endpoint=search_endpoint,
            index_name=search_index,
            credential=AzureKeyCredential(search_key)
        )
        
        return azure_openai_client, search_client, True
    except Exception as e:
        st.error(f"í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
        return None, None, False

# í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ê³„ì‚° í•¨ìˆ˜
def calculate_hybrid_score(search_score, reranker_score):
    """ê²€ìƒ‰ ì ìˆ˜ì™€ Reranker ì ìˆ˜ë¥¼ ì¡°í•©í•˜ì—¬ í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ê³„ì‚°"""
    if reranker_score > 0:
        # Reranker ì ìˆ˜ê°€ ìˆëŠ” ê²½ìš°: Reranker ì ìˆ˜ë¥¼ ì£¼ë¡œ ì‚¬ìš©í•˜ë˜ ê²€ìƒ‰ ì ìˆ˜ë„ ê³ ë ¤
        # Reranker ì ìˆ˜ëŠ” ë³´í†µ 0-4 ë²”ìœ„ì´ë¯€ë¡œ 0-1ë¡œ ì •ê·œí™”
        normalized_reranker = min(reranker_score / 4.0, 1.0)
        # ê²€ìƒ‰ ì ìˆ˜ëŠ” ì´ë¯¸ 0-1 ë²”ìœ„
        normalized_search = min(search_score, 1.0)
        
        # ê°€ì¤‘í‰ê· : Reranker 80%, ê²€ìƒ‰ ì ìˆ˜ 20%
        hybrid_score = (normalized_reranker * 0.8) + (normalized_search * 0.2)
    else:
        # Reranker ì ìˆ˜ê°€ ì—†ëŠ” ê²½ìš°: ê²€ìƒ‰ ì ìˆ˜ë§Œ ì‚¬ìš©
        hybrid_score = min(search_score, 1.0)
    
    return hybrid_score

# ë™ì  ì„ê³„ê°’ì„ ì ìš©í•œ ê³ ê¸‰ ë¬¸ì„œ í•„í„°ë§ í•¨ìˆ˜
def advanced_filter_documents(documents, query_type="default", query_text=""):
    """ë™ì  ì„ê³„ê°’ì„ ì ìš©í•œ ê³ ê¸‰ í•„í„°ë§"""
    # ë™ì  ì„ê³„ê°’ íšë“
    thresholds = get_dynamic_thresholds(query_type, query_text)
    
    filtered_docs = []
    filter_stats = {
        'total': len(documents),
        'search_filtered': 0,
        'reranker_qualified': 0,
        'hybrid_qualified': 0,
        'final_selected': 0
    }
    
    for doc in documents:
        search_score = doc.get('score', 0)
        reranker_score = doc.get('reranker_score', 0)
        
        # 1ë‹¨ê³„: ê¸°ë³¸ ê²€ìƒ‰ ì ìˆ˜ í•„í„°ë§ (ë™ì  ì„ê³„ê°’ ì ìš©)
        if search_score < thresholds['search_threshold']:
            continue
        filter_stats['search_filtered'] += 1
        
        # 2ë‹¨ê³„: Reranker ì ìˆ˜ ìš°ì„  í‰ê°€ (ë™ì  ì„ê³„ê°’ ì ìš©)
        if reranker_score >= thresholds['reranker_threshold']:
            filter_stats['reranker_qualified'] += 1
            doc['filter_reason'] = f"Reranker ê³ í’ˆì§ˆ (ì ìˆ˜: {reranker_score:.2f})"
            doc['final_score'] = reranker_score
            doc['quality_tier'] = 'Premium'
            filtered_docs.append(doc)
            filter_stats['final_selected'] += 1
            continue
        
        # 3ë‹¨ê³„: í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ í‰ê°€ (ë™ì  ì„ê³„ê°’ ì ìš©)
        hybrid_score = calculate_hybrid_score(search_score, reranker_score)
        if hybrid_score >= thresholds['hybrid_threshold']:
            filter_stats['hybrid_qualified'] += 1
            doc['filter_reason'] = f"í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ í†µê³¼ (ì ìˆ˜: {hybrid_score:.2f})"
            doc['final_score'] = hybrid_score
            doc['quality_tier'] = 'Standard'
            filtered_docs.append(doc)
            filter_stats['final_selected'] += 1
    
    # ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ë†’ì€ ì ìˆ˜ ìš°ì„ )
    filtered_docs.sort(key=lambda x: x['final_score'], reverse=True)
    
    # ìµœì¢… ê²°ê³¼ ìˆ˜ ì œí•œ (ë™ì  ì ìš©)
    final_docs = filtered_docs[:thresholds['max_results']]
    
    # í•„í„°ë§ í†µê³„ í‘œì‹œ (ì„ê³„ê°’ ì •ë³´ í¬í•¨)
    st.info(f"""
    ğŸ“Š **ë™ì  ì„ê³„ê°’ ê¸°ë°˜ ë¬¸ì„œ í•„í„°ë§ ê²°ê³¼**
    - ğŸ¯ ì ìš©ëœ ì„ê³„ê°’: ê²€ìƒ‰({thresholds['search_threshold']}) | Reranker({thresholds['reranker_threshold']}) | í•˜ì´ë¸Œë¦¬ë“œ({thresholds['hybrid_threshold']})
    - ğŸ” ì „ì²´ ê²€ìƒ‰ ê²°ê³¼: {filter_stats['total']}ê°œ
    - âœ… ê¸°ë³¸ ì ìˆ˜ í†µê³¼: {filter_stats['search_filtered']}ê°œ
    - ğŸ† Reranker ê³ í’ˆì§ˆ: {filter_stats['reranker_qualified']}ê°œ
    - ğŸ¯ í•˜ì´ë¸Œë¦¬ë“œ í†µê³¼: {filter_stats['hybrid_qualified']}ê°œ
    - ğŸ“‹ ìµœì¢… ì„ ë³„: {len(final_docs)}ê°œ
    """)
    
    return final_docs

# ë™ì  ì„ê³„ê°’ì„ ì ìš©í•œ ì‹œë§¨í‹± ê²€ìƒ‰ í•¨ìˆ˜
def semantic_search_with_reranker(search_client, query, query_type="default", top_k=MAX_INITIAL_RESULTS):
    """ë™ì  ì„ê³„ê°’ì„ ì ìš©í•œ ê³ í’ˆì§ˆ ì‹œë§¨í‹± ê²€ìƒ‰"""
    try:
        st.info(f"ğŸ”„ 1ë‹¨ê³„: {top_k}ê°œ ì´ˆê¸° ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ì§‘ ì¤‘...")
        
        # ì‹œë§¨í‹± ê²€ìƒ‰ ì‹¤í–‰ (ë” ë§ì€ í›„ë³´ í™•ë³´)
        results = search_client.search(
            search_text=query,
            top=top_k,
            query_type="semantic",
            semantic_configuration_name="iap-incident-single-meaning",
            include_total_count=True,
            select=[
                "incident_id", "service_name", "error_time", "notice_text", 
                "error_date", "week", "daynight", "incident_cause", "incident_repair", 
                "incident_plan", "cause_type", "done_type", "incident_grade", 
                "owner_depart", "fail_type", "year", "month"
            ]
        )
        
        documents = []
        for result in results:
            documents.append({
                "incident_id": result.get("incident_id", ""),
                "service_name": result.get("service_name", ""),
                "error_time": result.get("error_time", ""),
                "notice_text": result.get("notice_text", ""),
                "error_date": result.get("error_date", ""),
                "week": result.get("week", ""),
                "daynight": result.get("daynight", ""),
                "incident_cause": result.get("incident_cause", ""),
                "incident_repair": result.get("incident_repair", ""),
                "incident_plan": result.get("incident_plan", ""),
                "cause_type": result.get("cause_type", ""),
                "done_type": result.get("done_type", ""),
                "incident_grade": result.get("incident_grade", ""),
                "owner_depart": result.get("owner_depart", ""),
                "fail_type": result.get("fail_type", ""),
                "year": result.get("year", ""),
                "month": result.get("month", ""),
                "score": result.get("@search.score", 0),
                "reranker_score": result.get("@search.reranker_score", 0)
            })
        
        st.info(f"ğŸ¯ 2ë‹¨ê³„: ë™ì  ì„ê³„ê°’ ê¸°ë°˜ ê³ í’ˆì§ˆ ë¬¸ì„œ ì„ ë³„ ì¤‘...")
        
        # ë™ì  ì„ê³„ê°’ ê¸°ë°˜ í•„í„°ë§ ì ìš©
        filtered_documents = advanced_filter_documents(documents, query_type, query)
        
        return filtered_documents
        
    except Exception as e:
        st.warning(f"ì‹œë§¨í‹± ê²€ìƒ‰ ì‹¤íŒ¨, ì¼ë°˜ ê²€ìƒ‰ìœ¼ë¡œ ëŒ€ì²´: {str(e)}")
        return search_documents_with_reranker(search_client, query, query_type, top_k)

# ì¼ë°˜ ê²€ìƒ‰ë„ ë™ì  ì„ê³„ê°’ ì ìš©
def search_documents_with_reranker(search_client, query, query_type="default", top_k=MAX_INITIAL_RESULTS):
    """ì¼ë°˜ ê²€ìƒ‰ì— ë™ì  ì„ê³„ê°’ ì ìš©"""
    try:
        st.info(f"ğŸ”„ 1ë‹¨ê³„: {top_k}ê°œ ì´ˆê¸° ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ì§‘ ì¤‘...")
        
        results = search_client.search(
            search_text=query,
            top=top_k,
            include_total_count=True,
            select=[
                "incident_id", "service_name", "error_time", "notice_text", 
                "error_date", "week", "daynight", "incident_cause", "incident_repair", 
                "incident_plan", "cause_type", "done_type", "incident_grade", 
                "owner_depart", "fail_type", "year", "month"
            ],
            search_fields=[
                "notice_text", "error_date", "week", "daynight", "incident_cause", "incident_repair", 
                "incident_plan", "service_name", "cause_type", 
                "done_type", "owner_depart", "year", "month"
            ]
        )
        
        documents = []
        for result in results:
            documents.append({
                "incident_id": result.get("incident_id", ""),
                "service_name": result.get("service_name", ""),
                "error_time": result.get("error_time", ""),
                "notice_text": result.get("notice_text", ""),
                "error_date": result.get("error_date", ""),
                "week": result.get("week", ""),
                "daynight": result.get("daynight", ""),
                "incident_cause": result.get("incident_cause", ""),
                "incident_repair": result.get("incident_repair", ""),
                "incident_plan": result.get("incident_plan", ""),
                "cause_type": result.get("cause_type", ""),
                "done_type": result.get("done_type", ""),
                "incident_grade": result.get("incident_grade", ""),
                "owner_depart": result.get("owner_depart", ""),
                "fail_type": result.get("fail_type", ""),
                "year": result.get("year", ""),
                "month": result.get("month", ""),
                "score": result.get("@search.score", 0),
                "reranker_score": 0  # ì¼ë°˜ ê²€ìƒ‰ì—ì„œëŠ” 0
            })
        
        st.info(f"ğŸ¯ 2ë‹¨ê³„: ë™ì  ì„ê³„ê°’ ê¸°ë°˜ ê³ í’ˆì§ˆ ë¬¸ì„œ ì„ ë³„ ì¤‘...")
        
        # ë™ì  ì„ê³„ê°’ ê¸°ë°˜ í•„í„°ë§ ì ìš©
        filtered_documents = advanced_filter_documents(documents, query_type, query)
        
        return filtered_documents
        
    except Exception as e:
        st.error(f"ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
        return []

# ëŒ€ì²´ ê²€ìƒ‰ í•¨ìˆ˜ (ë§¤ìš° ê´€ëŒ€í•œ ê¸°ì¤€)
def search_documents_fallback(search_client, query, top_k=15):
    """ë§¤ìš° ê´€ëŒ€í•œ ê¸°ì¤€ì˜ ëŒ€ì²´ ê²€ìƒ‰"""
    try:
        results = search_client.search(
            search_text=query,
            top=top_k,
            include_total_count=True,
            select=[
                "incident_id", "service_name", "error_time", "notice_text", 
                "error_date", "week", "daynight", "incident_cause", "incident_repair", 
                "incident_plan", "cause_type", "done_type", "incident_grade", 
                "owner_depart", "fail_type", "year", "month"
            ]
        )
        
        documents = []
        for result in results:
            score = result.get("@search.score", 0)
            if score >= 0.1:  # ë§¤ìš° ë‚®ì€ ê¸°ì¤€
                documents.append({
                    "incident_id": result.get("incident_id", ""),
                    "service_name": result.get("service_name", ""),
                    "error_time": result.get("error_time", ""),
                    "notice_text": result.get("notice_text", ""),
                    "error_date": result.get("error_date", ""),
                    "week": result.get("week", ""),
                    "daynight": result.get("daynight", ""),
                    "incident_cause": result.get("incident_cause", ""),
                    "incident_repair": result.get("incident_repair", ""),
                    "incident_plan": result.get("incident_plan", ""),
                    "cause_type": result.get("cause_type", ""),
                    "done_type": result.get("done_type", ""),
                    "incident_grade": result.get("incident_grade", ""),
                    "owner_depart": result.get("owner_depart", ""),
                    "fail_type": result.get("fail_type", ""),
                    "year": result.get("year", ""),
                    "month": result.get("month", ""),
                    "score": score,
                    "reranker_score": 0,
                    "final_score": score,
                    "quality_tier": "Basic",
                    "filter_reason": "ëŒ€ì²´ ê²€ìƒ‰ í†µê³¼"
                })
        
        return documents[:8]  # ìµœëŒ€ 8ê°œê¹Œì§€
        
    except Exception as e:
        st.error(f"ëŒ€ì²´ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
        return []

# RAG ì‘ë‹µ ìƒì„± - Reranker ì •ë³´ í¬í•¨
def generate_rag_response_with_reranker(azure_openai_client, query, documents, model_name, query_type="default"):
    try:
        # ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ ì»¨í…ìŠ¤íŠ¸ë¡œ êµ¬ì„± (í’ˆì§ˆ ì •ë³´ í¬í•¨)
        context_parts = []
        for i, doc in enumerate(documents):
            final_score = doc.get('final_score', 0)
            quality_tier = doc.get('quality_tier', 'Standard')
            filter_reason = doc.get('filter_reason', 'ê¸°ë³¸ ì„ ë³„')
            
            context_part = f"""ë¬¸ì„œ {i+1} [{quality_tier}ê¸‰ - {filter_reason}]:
ì¥ì•  ID: {doc['incident_id']}
ì„œë¹„ìŠ¤ëª…: {doc['service_name']}
ì¥ì• ì‹œê°„: {doc['error_time']}
ê³µì§€ì‚¬í•­: {doc['notice_text']}
ë°œìƒì¼ì: {doc['error_date']}
ìš”ì¼: {doc['week']}
ì‹œê°„ëŒ€: {doc['daynight']}
ì¥ì• ì›ì¸: {doc['incident_cause']}
ë³µêµ¬ë°©ë²•: {doc['incident_repair']}
ê°œì„ ê³„íš: {doc['incident_plan']}
ì›ì¸ìœ í˜•: {doc['cause_type']}
ì²˜ë¦¬ìœ í˜•: {doc['done_type']}
ì¥ì• ë“±ê¸‰: {doc['incident_grade']}
ë‹´ë‹¹ë¶€ì„œ: {doc['owner_depart']}
ì¥ì• ìœ í˜•: {doc['fail_type']}
ë…„ë„: {doc['year']}
ì›”: {doc['month']}
í’ˆì§ˆì ìˆ˜: {final_score:.2f}
"""
            context_parts.append(context_part)
        
        context = "\n\n".join(context_parts)
        
        # ì§ˆë¬¸ íƒ€ì…ì— ë”°ë¥¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„ íƒ
        system_prompt = SYSTEM_PROMPTS.get(query_type, SYSTEM_PROMPTS["default"])

        user_prompt = f"""
ë‹¤ìŒ ì¥ì•  ì´ë ¥ ë¬¸ì„œë“¤ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.
(ëª¨ë“  ë¬¸ì„œëŠ” ë™ì  ì„ê³„ê°’ ê¸°ë°˜ ê³ í’ˆì§ˆ í•„í„°ë§ì„ í†µê³¼í•œ ìµœê³  í’ˆì§ˆì˜ ê²€ìƒ‰ ê²°ê³¼ì…ë‹ˆë‹¤):

{context}

ì§ˆë¬¸: {query}

ë‹µë³€:"""

        # Azure OpenAI API í˜¸ì¶œ
        response = azure_openai_client.chat.completions.create(
            model=model_name,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.3,
            max_tokens=1500
        )
        
        return response.choices[0].message.content
    
    except Exception as e:
        st.error(f"ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {str(e)}")
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

# ê³ ê¸‰ ë¬¸ì„œ í‘œì‹œ í•¨ìˆ˜
def display_documents_with_quality_info(documents):
    """í’ˆì§ˆ ì •ë³´ì™€ í•¨ê»˜ ë¬¸ì„œ í‘œì‹œ"""
    for i, doc in enumerate(documents):
        quality_tier = doc.get('quality_tier', 'Standard')
        filter_reason = doc.get('filter_reason', 'ê¸°ë³¸ ì„ ë³„')
        search_score = doc.get('score', 0)
        reranker_score = doc.get('reranker_score', 0)
        final_score = doc.get('final_score', 0)
        
        # í’ˆì§ˆ ë“±ê¸‰ì— ë”°ë¥¸ ì´ëª¨ì§€ì™€ ìƒ‰ìƒ
        if quality_tier == 'Premium':
            tier_emoji = "ğŸ†"
            tier_color = "ğŸŸ¢"
        else:
            tier_emoji = "ğŸ¯"
            tier_color = "ğŸŸ¡"
        
        st.markdown(f"### {tier_emoji} **ë¬¸ì„œ {i+1}** - {quality_tier}ê¸‰ {tier_color}")
        st.markdown(f"**ì„ ë³„ ê¸°ì¤€**: {filter_reason}")
        
        # ì ìˆ˜ ì •ë³´ í‘œì‹œ
        score_col1, score_col2, score_col3 = st.columns(3)
        with score_col1:
            st.metric("ê²€ìƒ‰ ì ìˆ˜", f"{search_score:.2f}")
        with score_col2:
            if reranker_score > 0:
                st.metric("Reranker ì ìˆ˜", f"{reranker_score:.2f}")
            else:
                st.metric("Reranker ì ìˆ˜", "N/A")
        with score_col3:
            st.metric("ìµœì¢… ì ìˆ˜", f"{final_score:.2f}")
        
        # ì£¼ìš” ì •ë³´ í‘œì‹œ
        col1, col2 = st.columns(2)
        with col1:
            st.write(f"**ì¥ì•  ID**: {doc['incident_id']}")
            st.write(f"**ì„œë¹„ìŠ¤ëª…**: {doc['service_name']}")
            st.write(f"**ì¥ì•  ë“±ê¸‰**: {doc['incident_grade']}")
            
        with col2:
            st.write(f"**ì›ì¸ ìœ í˜•**: {doc['cause_type']}")
            st.write(f"**ì²˜ë¦¬ ìœ í˜•**: {doc['done_type']}")
            st.write(f"**ë‹´ë‹¹ ë¶€ì„œ**: {doc['owner_depart']}")
        

        if doc['notice_text']:
            st.write(f"**ê³µì§€ì‚¬í•­**: {doc['notice_text'][:200]}...")
        if doc['incident_cause']:
            st.write(f"**ì¥ì•  ì›ì¸**: {doc['incident_cause'][:200]}...")
        if doc['incident_repair']:
            st.write(f"**ë³µêµ¬ ë°©ë²•**: {doc['incident_repair'][:200]}...")
        
        st.markdown("---")

# ì…ë ¥ ê²€ì¦ í•¨ìˆ˜
def validate_inputs(service_name, incident_symptom):
    """ì„œë¹„ìŠ¤ëª…, ì¥ì• í˜„ìƒ ì…ë ¥ ê²€ì¦"""
    if not service_name or not service_name.strip():
        st.error("âŒ ì„œë¹„ìŠ¤ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”!")
        return False
    if not incident_symptom or not incident_symptom.strip():
        st.error("âŒ ì¥ì• í˜„ìƒì„ ì…ë ¥í•´ì£¼ì„¸ìš”!")
        return False
    return True

# ê²€ìƒ‰ ì¿¼ë¦¬ êµ¬ì„± í•¨ìˆ˜
def build_search_query(service_name, incident_symptom):
    """ê¸°ë³¸ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ êµ¬ì„±"""
    return f"{service_name} {incident_symptom}"

# ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œì§
if all([azure_openai_endpoint, azure_openai_key, search_endpoint, search_key, search_index]):
    # í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    azure_openai_client, search_client, init_success = init_clients(
        azure_openai_endpoint, azure_openai_key, azure_openai_api_version,
        search_endpoint, search_key, search_index
    )
    
    if init_success:
        # st.success("Azure ì„œë¹„ìŠ¤ ì—°ê²° ì„±ê³µ!")
        
        # =================== ìƒë‹¨ ê³ ì • ì˜ì—­ ì‹œì‘ ===================
        with st.container():
           
            # ì„œë¹„ìŠ¤ ì •ë³´ ì…ë ¥ ì„¹ì…˜
            st.header("ğŸ“ ì„œë¹„ìŠ¤ ì •ë³´ ì…ë ¥")
            
            # ì„œë¹„ìŠ¤ëª…ê³¼ ì¥ì• í˜„ìƒ ì…ë ¥
            input_col1, input_col2 = st.columns(2)
            
            with input_col1:
                service_name = st.text_input("ì„œë¹„ìŠ¤ëª…ì„ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: ë§ˆì´í˜ì´ì§€, íŒ¨ë°€ë¦¬ë°•ìŠ¤, í†µí•©ì¿ í°í”Œë«í¼")
            
            with input_col2:
                incident_symptom = st.text_input("ì¥ì• í˜„ìƒì„ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: ì ‘ì†ë¶ˆê°€, ì‘ë‹µì§€ì—°, ì˜¤ë¥˜ë°œìƒ")
            
            # ì…ë ¥ëœ ì •ë³´ í™•ì¸ ë° í‘œì‹œ
            if service_name and incident_symptom:
                st.success(f"ì„œë¹„ìŠ¤: {service_name} | ì¥ì• í˜„ìƒ: {incident_symptom}")
            elif service_name or incident_symptom:
                missing = []
                if not service_name:
                    missing.append("ì„œë¹„ìŠ¤ëª…")
                if not incident_symptom:
                    missing.append("ì¥ì• í˜„ìƒ")
                st.info(f"âš ï¸ {', '.join(missing)}ì„(ë¥¼) ì…ë ¥í•´ì£¼ì„¸ìš”.")
            
            # ì£¼ìš” ì§ˆë¬¸ ë²„íŠ¼ë“¤
            st.header("ğŸ” ì£¼ìš” ì§ˆë¬¸")

            # ìŠ¤íƒ€ì¼ CSS ì¶”ê°€
            st.markdown("""
                <style>
                div[data-baseweb="input"] > div {
                    font-size: 40px;
                    height: 40px;
                }
                 
                div.stButton > button:first-child {
                    font-size: 40px;
                    height: 60px;
                    width: 450px;
                    background-color: #4CAF50;
                    color: white;
                    border-radius: 10px;
                }
                </style>
            """, unsafe_allow_html=True)

            col1, col2 = st.columns(2)
            
            with col1:
                if st.button("ğŸ”§ ì„œë¹„ìŠ¤ì™€ í˜„ìƒì— ëŒ€í•´ ë³µêµ¬ ë°©ë²• ì•ˆë‚´", key="repair_btn"):
                    if validate_inputs(service_name, incident_symptom):
                        search_query = build_search_query(service_name, incident_symptom)
                        st.session_state.sample_query = f"{search_query}ì— ëŒ€í•œ ì¥ì• ë¥¼ í•´ì†Œí•˜ê¸° ìœ„í•œ ê·¼ë³¸ì ì¸ ë³µêµ¬ë°©ë²•ë§Œ í‘œê¸°í•´ì„œ ë³µêµ¬ë°©ë²• ì•ˆë‚´"
                        st.session_state.query_type = "repair"
                
            with col2:
                if st.button("ğŸ”„ ë™ì¼ í˜„ìƒì— ëŒ€í•œ ë³µêµ¬ ë°©ë²• ì°¸ì¡°", key="similar_btn"):
                    if validate_inputs(service_name, incident_symptom):
                        search_query = build_search_query("", incident_symptom)
                        st.session_state.sample_query = f"{incident_symptom} ë™ì¼ í˜„ìƒì— ëŒ€í•œ ì¥ì• ë¥¼ í•´ì†Œí•˜ê¸° ìœ„í•œ ê·¼ë³¸ì ì¸ ë³µêµ¬ë°©ë²•ë§Œ í‘œê¸°í•´ì„œ ë³µêµ¬ë°©ë²• ì•ˆë‚´"
                        st.session_state.query_type = "similar"

        # =================== ìƒë‹¨ ê³ ì • ì˜ì—­ ë ===================
        
        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        if 'messages' not in st.session_state:
            st.session_state.messages = []
        
        # ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ ì˜ì—­
        chat_container = st.container()
        
        with chat_container:
            # ì´ì „ ë©”ì‹œì§€ í‘œì‹œ
            for message in st.session_state.messages:
                with st.chat_message(message["role"]):
                    if message["role"] == "assistant":
                        with st.expander("ğŸ¤– AI ë‹µë³€ ë³´ê¸°", expanded=True):
                            st.write(message["content"])
                    else:
                        st.write(message["content"])
        
        # ê²€ìƒ‰ ë° ì‘ë‹µ ì²˜ë¦¬ í•¨ìˆ˜ (ë™ì  ì„ê³„ê°’ ì ìš©)
        def process_query_with_reranker(query, query_type="default"):
            with st.chat_message("assistant"):
                with st.spinner("ğŸ¯ ë™ì  ì„ê³„ê°’ ê¸°ë°˜ ê³ í’ˆì§ˆ ê²€ìƒ‰ ì¤‘..."):
                    # query_typeì„ ê²€ìƒ‰ í•¨ìˆ˜ì— ì „ë‹¬
                    documents = semantic_search_with_reranker(search_client, query, query_type)
                    
                    if documents:
                        premium_count = sum(1 for doc in documents if doc.get('quality_tier') == 'Premium')
                        standard_count = len(documents) - premium_count
                        basic_count = sum(1 for doc in documents if doc.get('quality_tier') == 'Basic')
                        
                        st.success(f"ğŸ† {len(documents)}ê°œì˜ ìµœê³ í’ˆì§ˆ ë¬¸ì„œ ì„ ë³„ ì™„ë£Œ! (Premium: {premium_count}ê°œ, Standard: {standard_count}ê°œ, Basic: {basic_count}ê°œ)")
                        
                        # ê²€ìƒ‰ëœ ë¬¸ì„œ í‘œì‹œ
                        with st.expander("ğŸ” ì„ ë³„ëœ ê³ í’ˆì§ˆ ë¬¸ì„œ ë³´ê¸°"):
                            display_documents_with_quality_info(documents)
                        
                        # RAG ì‘ë‹µ ìƒì„±
                        with st.spinner("ğŸ’¡ ë™ì  í’ˆì§ˆ ê¸°ë°˜ ì •í™•í•œ ë‹µë³€ ìƒì„± ì¤‘..."):
                            response = generate_rag_response_with_reranker(
                                azure_openai_client, query, documents, azure_openai_model, query_type
                            )
                            
                            with st.expander("ğŸ¤– AI ë‹µë³€ ë³´ê¸° (ë™ì  í’ˆì§ˆ ê°•í™”)", expanded=True):
                                st.write(response)
                                st.info("âœ¨ ì´ ë‹µë³€ì€ ì¿¼ë¦¬ íŠ¹ì„±ì— ë§ëŠ” ë™ì  í’ˆì§ˆ ê¸°ì¤€ìœ¼ë¡œ ì„ ë³„ëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
                            
                            st.session_state.messages.append({"role": "assistant", "content": response})
                    else:
                        # ëŒ€ì²´ ê²€ìƒ‰ ì‹œë„
                        st.warning("ğŸ”„ ë™ì  ì„ê³„ê°’ìœ¼ë¡œë„ ê²°ê³¼ê°€ ì—†ì–´ ë” ê´€ëŒ€í•œ ê¸°ì¤€ìœ¼ë¡œ ì¬ê²€ìƒ‰ ì¤‘...")
                        
                        # ë§¤ìš° ê´€ëŒ€í•œ ê¸°ì¤€ìœ¼ë¡œ ì¬ê²€ìƒ‰
                        fallback_documents = search_documents_fallback(search_client, query)
                        
                        if fallback_documents:
                            st.info(f"ğŸ“‹ ëŒ€ì²´ ê²€ìƒ‰ìœ¼ë¡œ {len(fallback_documents)}ê°œ ë¬¸ì„œ ë°œê²¬")
                            response = generate_rag_response_with_reranker(
                                azure_openai_client, query, fallback_documents, azure_openai_model, query_type
                            )
                            with st.expander("ğŸ¤– AI ë‹µë³€ ë³´ê¸° (ëŒ€ì²´ ê²€ìƒ‰)", expanded=True):
                                st.write(response)
                                st.warning("âš ï¸ ì´ ë‹µë³€ì€ ê´€ëŒ€í•œ ê¸°ì¤€ìœ¼ë¡œ ì„ ë³„ëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
                            st.session_state.messages.append({"role": "assistant", "content": response})
                        else:
                            error_msg = """
                            ğŸ” ëª¨ë“  ê²€ìƒ‰ ê¸°ì¤€ìœ¼ë¡œë„ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
                            
                            **ê°œì„  ë°©ì•ˆ:**
                            - ë” êµ¬ì²´ì ì¸ í‚¤ì›Œë“œ ì‚¬ìš©
                            - ë‹¤ë¥¸ í‘œí˜„ìœ¼ë¡œ ì¬ê²€ìƒ‰
                            - ê²€ìƒ‰ ë²”ìœ„ í™•ëŒ€
                            """
                            with st.expander("ğŸ¤– AI ë‹µë³€ ë³´ê¸°", expanded=True):
                                st.write(error_msg)
                            st.session_state.messages.append({"role": "assistant", "content": error_msg})
        
        # ì‚¬ìš©ì ì…ë ¥
        user_query = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ë§ˆì´í˜ì´ì§€ ìµœê·¼ ì¥ì•  ë°œìƒì¼ìì™€ ì¥ì• ì›ì¸ ì•Œë ¤ì¤˜)")
        
        if user_query:
            st.session_state.messages.append({"role": "user", "content": user_query})
            
            with st.chat_message("user"):
                st.write(user_query)
            
            process_query_with_reranker(user_query, "default")

        # ì£¼ìš” ì§ˆë¬¸ ì²˜ë¦¬
        if 'sample_query' in st.session_state:
            query = st.session_state.sample_query
            query_type = st.session_state.get('query_type', 'default')
            
            del st.session_state.sample_query
            if 'query_type' in st.session_state:
                del st.session_state.query_type
            
            st.session_state.messages.append({"role": "user", "content": query})
            
            with st.chat_message("user"):
                st.write(query)
            
            process_query_with_reranker(query, query_type)
            st.rerun()

else:
    st.error("í™˜ê²½ë³€ìˆ˜ ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.")