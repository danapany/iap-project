import streamlit as st
from config.settings_local import AppConfigLocal
from utils.azure_clients import AzureClientManager
from utils.search_utils_local import SearchManagerLocal
from utils.ui_components_local import UIComponentsLocal
from utils.query_processor_local import QueryProcessorLocal
from utils.logging_middleware import apply_logging_to_query_processor, set_client_ip

# ê²€ìƒ‰ í’ˆì§ˆ ì„¤ì •
DEFAULT_QUALITY_LEVEL = "ê³ ê¸‰"
DEFAULT_SEARCH_THRESHOLD = 0.25
DEFAULT_RERANKER_THRESHOLD = 2.2
DEFAULT_MAX_RESULTS = 20
DEFAULT_SEMANTIC_THRESHOLD = 0.3
DEFAULT_HYBRID_THRESHOLD = 0.4
MAX_QUERY_LENGTH = 300
DEBUG_MODE = False

def validate_query_length(query):
    """ì§ˆë¬¸ ê¸¸ì´ ê²€ì¦"""
    return len(query) <= MAX_QUERY_LENGTH, len(query)

def show_query_length_error(current_length):
    """ì§ˆë¬¸ ê¸¸ì´ ì´ˆê³¼ ì•ˆë‚´"""
    error_msg = f"""
    âš ï¸ **ì§ˆë¬¸ì„ ì¡°ê¸ˆ ë” ê°„ë‹¨íˆ ì…ë ¥í•´ ì£¼ì„¸ìš”**
    
    ğŸ“ í˜„ì¬: {current_length}ì / ìµœëŒ€: {MAX_QUERY_LENGTH}ì
    ğŸ“ ì´ˆê³¼: {current_length - MAX_QUERY_LENGTH}ì
    
    ğŸ’¡ **íŒ**: í•µì‹¬ ë‚´ìš©ë§Œ ê°„ê²°í•˜ê²Œ, ì„œë¹„ìŠ¤ëª…ê³¼ ì¥ì• í˜„ìƒ ì¤‘ì‹¬ìœ¼ë¡œ ì‘ì„±
    """
    with st.chat_message("assistant"):
        st.warning(error_msg)
    st.session_state.messages.append({"role": "assistant", "content": error_msg})

def get_quality_config(level):
    """í’ˆì§ˆ ì„¤ì • íŒ©í† ë¦¬ í•¨ìˆ˜"""
    configs = {
        'high': {
            'search_threshold': DEFAULT_SEARCH_THRESHOLD,
            'reranker_threshold': DEFAULT_RERANKER_THRESHOLD,
            'semantic_threshold': DEFAULT_SEMANTIC_THRESHOLD,
            'hybrid_threshold': DEFAULT_HYBRID_THRESHOLD,
            'max_results': DEFAULT_MAX_RESULTS,
            'quality_level': 'high',
            'description': f'ìµœê³  ì •í™•ì„± (ê²€ìƒ‰ì ìˆ˜ {int(DEFAULT_SEARCH_THRESHOLD*100)}ì , Reranker {DEFAULT_RERANKER_THRESHOLD}ì  ì´ìƒ)'
        },
        'medium': {
            'search_threshold': 0.20,
            'reranker_threshold': 2.0,
            'semantic_threshold': 0.25,
            'hybrid_threshold': 0.35,
            'max_results': 15,
            'quality_level': 'medium',
            'description': 'ì •í™•ì„±ê³¼ í¬ê´„ì„± ê· í˜• (ê²€ìƒ‰ì ìˆ˜ 20ì , Reranker 2.0ì  ì´ìƒ)'
        },
        'low': {
            'search_threshold': 0.15,
            'reranker_threshold': 1.5,
            'semantic_threshold': 0.2,
            'hybrid_threshold': 0.25,
            'max_results': 20,
            'quality_level': 'low',
            'description': 'ìµœëŒ€ í¬ê´„ì„± (ê²€ìƒ‰ì ìˆ˜ 15ì , Reranker 1.5ì  ì´ìƒ)'
        }
    }
    return configs.get(level, configs['medium'])

def apply_quality_config_to_app_config(app_config, quality_config):
    """ì•± ì„¤ì •ì— í’ˆì§ˆ ì„¤ì • ì ìš©"""
    original_get_dynamic_thresholds = app_config.get_dynamic_thresholds
    
    def get_enhanced_dynamic_thresholds(query_type="default", query_text=""):
        base_thresholds = original_get_dynamic_thresholds(query_type, query_text)
        
        improvements = ['negative_keyword_filtering', 'confidence_scoring', 
                       'enhanced_prompting', 'reflection_prompting']
        
        if query_type in ['repair', 'cause']:
            enhanced_thresholds = {
                'search_threshold': max(quality_config['search_threshold'], 0.25),
                'reranker_threshold': max(quality_config['reranker_threshold'], 2.0),
                'semantic_threshold': max(quality_config['semantic_threshold'], 0.25),
                'hybrid_threshold': max(quality_config['hybrid_threshold'], 0.4),
                'max_results': min(quality_config['max_results'], 15),
                'processing_mode': 'accuracy_first',
                'description': 'ì •í™•ì„± ìš°ì„  ì²˜ë¦¬',
                'improvements_applied': improvements
            }
        elif query_type in ['similar', 'default']:
            enhanced_thresholds = {
                'search_threshold': min(quality_config['search_threshold'], 0.15),
                'reranker_threshold': min(quality_config['reranker_threshold'], 1.5),
                'semantic_threshold': min(quality_config['semantic_threshold'], 0.2),
                'hybrid_threshold': min(quality_config['hybrid_threshold'], 0.3),
                'max_results': max(quality_config['max_results'], 20),
                'processing_mode': 'coverage_first',
                'description': 'í¬ê´„ì„± ìš°ì„  ì²˜ë¦¬',
                'improvements_applied': improvements
            }
        else:
            enhanced_thresholds = quality_config.copy()
            enhanced_thresholds.update({
                'processing_mode': 'balanced',
                'description': 'ê· í˜•ì¡íŒ ì²˜ë¦¬',
                'improvements_applied': improvements
            })
        
        base_thresholds.update(enhanced_thresholds)
        return base_thresholds
    
    app_config.get_dynamic_thresholds = get_enhanced_dynamic_thresholds
    return app_config

def main():
    """ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜"""
    st.set_page_config(
        page_title="íŠ¸ëŸ¬ë¸” ì²´ì´ì„œ ì±—ë´‡",
        page_icon="ğŸš€",
        layout="wide"
    )
    
    st.markdown("""
    <style>
        .fixed-chart-container {
            width: 800px !important; height: 650px !important;
            margin: 0 auto !important; border: 1px solid #e0e0e0;
            border-radius: 8px; padding: 10px; background-color: #fafafa;
            overflow: hidden; display: flex; justify-content: center; align-items: center;
        }
        .fixed-chart-container > div { width: 800px !important; height: 600px !important; }
        .stPyplot > div { display: flex !important; justify-content: center !important; }
        .main .block-container {
            max-width: none !important; padding-left: 2rem !important; padding-right: 2rem !important;
        }
        .chart-section { display: flex; justify-content: center; align-items: center; width: 100%; }
        .stChatMessage, .stChatInput {
            max-width: 1200px; margin: 0 !important; margin-left: 0 !important; margin-right: auto !important;
        }
    </style>
    """, unsafe_allow_html=True)
    
    st.title("ğŸš€ íŠ¸ëŸ¬ë¸” ì²´ì´ì„œ ì±—ë´‡")
    
    processing_modes = {
        'repair': 'ì •í™•ì„± ìš°ì„  (LLM ê²€ì¦+ì˜ë¯¸ì  ìœ ì‚¬ì„±)',
        'cause': 'ì •í™•ì„± ìš°ì„  (LLM ê²€ì¦+ì˜ë¯¸ì  ìœ ì‚¬ì„±)',
        'similar': 'í¬ê´„ì„± ìš°ì„  (LLM ê²€ì¦+ì˜ë¯¸ì  ìœ ì‚¬ì„±)',
        'inquiry': 'ì¡°ê±´ë³„ ë‚´ì—­ ì¡°íšŒ (LLM ê²€ì¦+ì˜ë¯¸ì  ìœ ì‚¬ì„±+íŠ¹ì • ì¡°ê±´ ê¸°ë°˜ ì¥ì•  ê²€ìƒ‰)',
        'statistics': 'í†µê³„ ì „ìš© ì²˜ë¦¬ (ì •í™•í•œ ì§‘ê³„+ì›”ë³„ ë²”ìœ„ ì •ê·œí™”+ë°ì´í„° ë¬´ê²°ì„± ë³´ì¥)',
        'default': 'í¬ê´„ì„± ìš°ì„  (LLM ê²€ì¦+ì˜ë¯¸ì  ìœ ì‚¬ì„±+ê´‘ë²”ìœ„ ê²€ìƒ‰+ì°¨íŠ¸ ì§€ì›)'
    }
    
    # í’ˆì§ˆ ì„¤ì • ì„ íƒ
    level_map = {"ê³ ê¸‰": "high", "ì´ˆê¸‰": "low", "ì¤‘ê¸‰": "medium"}
    selected_level = level_map.get(next((k for k in level_map if k in DEFAULT_QUALITY_LEVEL), "ì¤‘ê¸‰"))
    selected_quality_config = get_quality_config(selected_level)
    
    if DEBUG_MODE:
        mode_msg = {"high": "ğŸ¯ ì •í™•ì„± ìš°ì„ ", "low": "ğŸ“‹ í¬ê´„ì„± ìš°ì„ ", "medium": "âš–ï¸ ê· í˜• ëª¨ë“œ"}
        st.success(mode_msg.get(selected_level, "âš–ï¸ ê· í˜• ëª¨ë“œ"))
    
    st.session_state['quality_config'] = selected_quality_config
    
    # UI ë° ì„¤ì • ì´ˆê¸°í™”
    ui_components = UIComponentsLocal()
    ui_components.render_main_ui()
    
    config = AppConfigLocal()
    if not config.validate_config():
        ui_components.show_config_error(config.get_env_status())
        return
    
    config = apply_quality_config_to_app_config(config, selected_quality_config)
    
    # Azure í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    client_manager = AzureClientManager(config)
    azure_openai_client, search_client, init_success = client_manager.init_clients()
    
    if not init_success:
        ui_components.show_connection_error()
        return
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    
    ui_components.display_chat_messages()
    
    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    user_query = st.chat_input(f"ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ìµœëŒ€ {MAX_QUERY_LENGTH}ì)")
    
    # ìƒˆ ì§ˆë¬¸ ì‹œ ì´ì „ ìƒíƒœ ì´ˆê¸°í™”
    if user_query and user_query != st.session_state.get('last_query', ''):
        keys_to_remove = [key for key in st.session_state.keys() 
                         if key.startswith(('search_performed_', 'show_search_modal_'))]
        for key in keys_to_remove:
            del st.session_state[key]
        st.session_state['last_query'] = user_query
    
    if user_query:
        is_valid_length, current_length = validate_query_length(user_query)
        
        if not is_valid_length:
            show_query_length_error(current_length)
            return
        
        st.session_state.messages.append({"role": "user", "content": user_query})
        
        with st.chat_message("user"):
            st.write(user_query)
        
        query_processor = QueryProcessorLocal(
            azure_openai_client, search_client, 
            config.azure_openai_model, config
        )
        
        try:
            query_processor = apply_logging_to_query_processor(query_processor)
        except Exception as e:
            print(f"DEBUG: Failed to apply logging middleware: {e}")
        
        query_processor.debug_mode = DEBUG_MODE
        query_processor.search_manager.debug_mode = DEBUG_MODE
        
        if DEBUG_MODE:
            st.info(f"""
            ğŸš€ 5ê°€ì§€ ê°œì„ ì‚¬í•­ í™œì„±í™”
            ğŸ” ìƒˆ ì¿¼ë¦¬ íƒ€ì…: INQUIRY, STATISTICS
            ğŸ“Š ì™„ì „ ê³ ì • í¬ê¸° ì°¨íŠ¸ (800x600px)
            ğŸ“ ì§ˆë¬¸ ê¸¸ì´: {current_length}ì / {MAX_QUERY_LENGTH}ì
            ğŸ” ë¡œê¹… ì‹œìŠ¤í…œ í™œì„±í™”
            """)
        
        try:
            query_processor.process_query(user_query)
        except Exception as e:
            st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            st.info("ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            if DEBUG_MODE:
                import traceback
                st.error("ìƒì„¸ ì˜¤ë¥˜ ì •ë³´:")
                st.code(traceback.format_exc())

if __name__ == "__main__":
    main()