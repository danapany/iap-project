import streamlit as st
import re
from config.prompts_web import SystemPrompts
from config.settings_web import AppConfig
from utils.ui_components_web import UIComponents
from utils.internet_search_web import InternetSearchManager

class QueryProcessor:
    """ì›¹ ê²€ìƒ‰ ê¸°ë°˜ ì¿¼ë¦¬ ì²˜ë¦¬ ê´€ë¦¬ í´ë˜ìŠ¤ (DEBUG ëª¨ë“œ ì§€ì›, IT ê´€ë ¨ ì§ˆë¬¸ë§Œ ì²˜ë¦¬, ì„¸ì…˜ ë¶„ë¦¬ ì§€ì›)"""
    
    def __init__(self, azure_openai_client, model_name, config=None, session_key="web_chatbot"):
        self.azure_openai_client = azure_openai_client
        self.model_name = model_name
        # configê°€ ì „ë‹¬ë˜ì§€ ì•Šìœ¼ë©´ ìƒˆë¡œ ìƒì„±
        self.config = config if config else AppConfig()
        self.ui_components = UIComponents()
        self.internet_search = InternetSearchManager(self.config)
        self.debug_mode = getattr(config, 'debug_mode', False)
        
        # ì›¹ ë²„ì „ ì „ìš© ì„¸ì…˜ í‚¤ ì„¤ì •
        self.session_key = session_key
        self.messages_key = f"{session_key}_messages"
    
    def is_it_related_query(self, query):
        """LLMì„ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì´ IT/ì „ì‚°/ì‹œìŠ¤í…œ ê´€ë ¨ì¸ì§€ íŒë‹¨"""
        try:
            validation_prompt = f"""
ë‹¤ìŒ ì‚¬ìš©ì ì§ˆë¬¸ì´ IT/ì „ì‚°/ì‹œìŠ¤í…œ/ê¸°ìˆ  ê´€ë ¨ ì§ˆë¬¸ì¸ì§€ íŒë‹¨í•´ì£¼ì„¸ìš”.

**IT ê´€ë ¨ ì§ˆë¬¸ ì¹´í…Œê³ ë¦¬:**
- ì»´í“¨í„°, ì„œë²„, ë„¤íŠ¸ì›Œí¬, ë°ì´í„°ë² ì´ìŠ¤ ê´€ë ¨
- ì†Œí”„íŠ¸ì›¨ì–´, ì• í”Œë¦¬ì¼€ì´ì…˜, ì›¹ì„œë¹„ìŠ¤ ê´€ë ¨  
- í”„ë¡œê·¸ë˜ë°, ê°œë°œ, ë°°í¬ ê´€ë ¨
- í´ë¼ìš°ë“œ, ì¸í”„ë¼, ë³´ì•ˆ ê´€ë ¨
- ì‹œìŠ¤í…œ ì¥ì• , ë¬¸ì œ í•´ê²°, ì„¤ì • ê´€ë ¨
- ê¸°ìˆ  ì§€ì›, íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ê´€ë ¨

**ITì™€ ë¬´ê´€í•œ ì§ˆë¬¸ ì˜ˆì‹œ:**
- ì—°ì˜ˆì¸, ì—°ì˜ˆê³„ ì†Œì‹
- ì£¼ì‹, íˆ¬ì, ê¸ˆìœµ ì •ë³´
- ìš”ë¦¬, ë ˆì‹œí”¼, ìŒì‹
- ì—¬í–‰, ê´€ê´‘ì§€ ì •ë³´
- ìŠ¤í¬ì¸ , ê²Œì„(ì „ìê²Œì„ ì œì™¸)
- ì˜ë£Œ, ê±´ê°• ìƒë‹´
- ë²•ë¥ , ì •ì¹˜ ê´€ë ¨
- ì¼ë°˜ ìƒì‹, êµìœ¡ ë‚´ìš©

**ì‚¬ìš©ì ì§ˆë¬¸:** {query}

**ì‘ë‹µ í˜•ì‹:** 
- IT ê´€ë ¨ ì§ˆë¬¸ì¸ ê²½ìš°: "YES"
- ITì™€ ë¬´ê´€í•œ ì§ˆë¬¸ì¸ ê²½ìš°: "NO"

ë°˜ë“œì‹œ "YES" ë˜ëŠ” "NO"ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
"""

            response = self.azure_openai_client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì§ˆë¬¸ì„ ë¶„ë¥˜í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì§ˆë¬¸ì´ IT/ì „ì‚°/ì‹œìŠ¤í…œ ê¸°ìˆ  ê´€ë ¨ì¸ì§€ ì •í™•íˆ íŒë‹¨í•´ì£¼ì„¸ìš”."},
                    {"role": "user", "content": validation_prompt}
                ],
                temperature=0.1,
                max_tokens=10
            )
            
            result = response.choices[0].message.content.strip().upper()
            
            # DEBUG ëª¨ë“œì—ì„œë§Œ íŒë‹¨ ê²°ê³¼ í‘œì‹œ
            if self.debug_mode:
                st.info(f"ğŸ” DEBUG: IT ê´€ë ¨ì„± íŒë‹¨ ê²°ê³¼ - {result}")
            
            return result == "YES"
            
        except Exception as e:
            if self.debug_mode:
                st.warning(f"IT ê´€ë ¨ì„± íŒë‹¨ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: {str(e)}")
            # íŒë‹¨ ì‹¤íŒ¨ ì‹œ ì•ˆì „í•˜ê²Œ IT ê´€ë ¨ìœ¼ë¡œ ê°„ì£¼
            return True

    def show_non_it_response(self, query):
        """IT ê´€ë ¨ì´ ì•„ë‹Œ ì§ˆë¬¸ì— ëŒ€í•œ ì•ˆë‚´ ë©”ì‹œì§€ í‘œì‹œ"""
        non_it_response = f"""
ğŸš« **IT ê¸°ìˆ  ì§€ì› ì „ìš© ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤**

ì£„ì†¡í•©ë‹ˆë‹¤. ì´ ì„œë¹„ìŠ¤ëŠ” **IT/ì „ì‚°/ì‹œìŠ¤í…œ ê¸°ìˆ  ë¬¸ì œ**ì— ëŒ€í•œ ì „ë¬¸ ì§€ì›ë§Œ ì œê³µí•©ë‹ˆë‹¤.

**ì§€ì› ê°€ëŠ¥í•œ ë¶„ì•¼:**
â€¢ ğŸ–¥ï¸ ì»´í“¨í„°, ì„œë²„, ë„¤íŠ¸ì›Œí¬ ë¬¸ì œ
â€¢ ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤, ì†Œí”„íŠ¸ì›¨ì–´ ê´€ë ¨
â€¢ ğŸŒ ì›¹ì„œë¹„ìŠ¤, API, í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤  
â€¢ ğŸ”§ ì‹œìŠ¤í…œ ì¥ì• , ì„¤ì •, íŠ¸ëŸ¬ë¸”ìŠˆíŒ…
â€¢ ğŸ’» í”„ë¡œê·¸ë˜ë°, ê°œë°œ í™˜ê²½ ë¬¸ì œ
â€¢ ğŸ”’ ë³´ì•ˆ, ì¸í”„ë¼ ê´€ë ¨ ë¬¸ì˜

**IT ê¸°ìˆ  ê´€ë ¨ ì§ˆë¬¸ ì˜ˆì‹œ:**
â€¢ "ì›¹ì„œë²„ ì ‘ì†ë¶ˆê°€ í•´ê²°ë°©ë²• ì•Œë ¤ì¤˜"
â€¢ "ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì˜¤ë¥˜ ì›ì¸ì´ ë­ì•¼?"  
â€¢ "Docker ì»¨í…Œì´ë„ˆ ì„¤ì • ë°©ë²•ì€?"
â€¢ "API ì‘ë‹µì§€ì—° ë¬¸ì œ í•´ê²°ì±…ì€?"

IT ê¸°ìˆ  ê´€ë ¨ ì§ˆë¬¸ìœ¼ë¡œ ë‹¤ì‹œ ë¬¸ì˜í•´ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.
"""
        
        with st.chat_message("assistant"):
            st.write(non_it_response)
        
        # ì›¹ ë²„ì „ ì „ìš© ì„¸ì…˜ì— ê±°ë¶€ ë©”ì‹œì§€ ì €ì¥
        st.session_state[self.messages_key].append({"role": "assistant", "content": non_it_response})

    def classify_query_type_with_llm(self, query):
        """LLMì„ ì‚¬ìš©í•˜ì—¬ ì¿¼ë¦¬ íƒ€ì…ì„ ìë™ìœ¼ë¡œ ë¶„ë¥˜"""
        try:
            classification_prompt = f"""
ë‹¤ìŒ ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.

**ë¶„ë¥˜ ê¸°ì¤€:**
1. **repair**: ë¬¸ì œ í•´ê²°ë°©ë²•, ë³µêµ¬ë°©ë²•, ìˆ˜ë¦¬ë°©ë²•ì„ ìš”ì²­í•˜ëŠ” ë¬¸ì˜
   - ì˜ˆ: "ì ‘ì†ë¶ˆê°€ í•´ê²°ë°©ë²•", "ì˜¤ë¥˜ ìˆ˜ì • ë°©ë²•", "ì‹œìŠ¤í…œ ë³µêµ¬í•˜ëŠ” ë°©ë²•"
   
2. **cause**: ì¥ì• ì›ì¸, ë¬¸ì œì›ì¸ ë¶„ì„ì´ë‚˜ ì›ì¸ íŒŒì•…ì„ ìš”ì²­í•˜ëŠ” ë¬¸ì˜
   - ì˜ˆ: "ì ‘ì†ë¶ˆê°€ ì›ì¸ì´ ë­ì•¼?", "ì™œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´?", "ë¬¸ì œ ì›ì¸ ë¶„ì„"
   
3. **similar**: ìœ ì‚¬ì‚¬ë¡€, ë¹„ìŠ·í•œ ë¬¸ì œ ì‚¬ë¡€ë¥¼ ìš”ì²­í•˜ëŠ” ë¬¸ì˜
   - ì˜ˆ: "ë¹„ìŠ·í•œ ë¬¸ì œ ì‚¬ë¡€", "ìœ ì‚¬í•œ ì˜¤ë¥˜ ê²½í—˜", "ê°™ì€ í˜„ìƒ í•´ê²°ì‚¬ë¡€"
   
4. **default**: ê·¸ ì™¸ì˜ ëª¨ë“  ê²½ìš° (ì¼ë°˜ ë¬¸ì˜, ì •ë³´ ìš”ì²­ ë“±)
   - ì˜ˆ: "ì„¤ì • ë°©ë²•", "ì‚¬ìš©ë²•", "ê°œë… ì„¤ëª…", "ë¹„êµ ë¶„ì„"

**ì‚¬ìš©ì ì§ˆë¬¸:** {query}

**ì‘ë‹µ í˜•ì‹:** repair, cause, similar, default ì¤‘ í•˜ë‚˜ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
"""

            response = self.azure_openai_client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ IT ì§ˆë¬¸ì„ ë¶„ë¥˜í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì§ˆë¬¸ì„ ì •í™•íˆ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”."},
                    {"role": "user", "content": classification_prompt}
                ],
                temperature=0.1,
                max_tokens=50
            )
            
            query_type = response.choices[0].message.content.strip().lower()
            
            # ìœ íš¨í•œ íƒ€ì…ì¸ì§€ í™•ì¸
            if query_type not in ['repair', 'cause', 'similar', 'default']:
                query_type = 'default'
                
            return query_type
            
        except Exception as e:
            if self.debug_mode:
                st.warning(f"ì¿¼ë¦¬ ë¶„ë¥˜ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: {str(e)}")
            return 'default'

    def extract_service_name_from_query(self, query):
        """ì¿¼ë¦¬ì—ì„œ ì„œë¹„ìŠ¤ëª… ì¶”ì¶œ (ê°„ë‹¨í•œ íŒ¨í„´ ê¸°ë°˜)"""
        # ì¼ë°˜ì ì¸ ì„œë¹„ìŠ¤ëª… íŒ¨í„´ë“¤
        service_patterns = [
            r'([A-Za-z][A-Za-z0-9_\-/\+\(\)\s]*[A-Za-z0-9_\-/\+\)])\s+(?:ì¥ì• |í˜„ìƒ|ë³µêµ¬|ì„œë¹„ìŠ¤|ì˜¤ë¥˜|ë¬¸ì œ)',
            r'ì„œë¹„ìŠ¤.*?([A-Za-z][A-Za-z0-9_\-/\+\(\)\s]*[A-Za-z0-9_\-/\+\)])',
            r'^([A-Za-z][A-Za-z0-9_\-/\+\(\)\s]*[A-Za-z0-9_\-/\+\)])\s+',
            r'["\']([A-Za-z][A-Za-z0-9_\-/\+\(\)\s]*[A-Za-z0-9_\-/\+\)])["\']',
            r'\(([A-Za-z][A-Za-z0-9_\-/\+\s]*[A-Za-z0-9_\-/\+])\)',
            r'\b([A-Za-z][A-Za-z0-9_\-/\+\(\)]{3,}(?:\s+[A-Za-z0-9_\-/\+\(\)]+)*)\b'
        ]
        
        for pattern in service_patterns:
            matches = re.findall(pattern, query, re.IGNORECASE)
            for match in matches:
                service_name = match.strip()
                if self.is_valid_service_name(service_name):
                    return service_name
        
        return None
    
    def is_valid_service_name(self, service_name):
        """ì„œë¹„ìŠ¤ëª…ì´ ìœ íš¨í•œì§€ ê²€ì¦"""
        # ê¸°ë³¸ ì¡°ê±´: ìµœì†Œ ê¸¸ì´ ì²´í¬
        if len(service_name) < 3:
            return False
        
        # ì˜ë¬¸ìë¡œ ì‹œì‘í•´ì•¼ í•¨
        if not service_name[0].isalpha():
            return False
        
        # ì œì™¸í•  ì¼ë°˜ì ì¸ ë‹¨ì–´ë“¤
        excluded_words = [
            'service', 'system', 'server', 'client', 'application', 'app',
            'website', 'web', 'platform', 'portal', 'interface', 'api',
            'database', 'data', 'file', 'log', 'error', 'issue', 'problem',
            'http', 'https', 'www', 'com', 'org', 'net',
            'ì¥ì• ', 'í˜„ìƒ', 'ë³µêµ¬', 'í†µê³„', 'ë°œìƒ'
        ]
        
        clean_name = re.sub(r'[\(\)/\+_\-\s]', '', service_name).lower()
        if clean_name in excluded_words:
            return False
        
        return True

    def _generate_web_search_response(self, query, target_service_name, query_type, type_labels):
        """ì›¹ ê²€ìƒ‰ ê¸°ë°˜ ì‘ë‹µ ìƒì„± (DEBUG ëª¨ë“œ ì§€ì›)"""
        try:
            # ì›¹ ê²€ìƒ‰ ìˆ˜í–‰
            search_spinner_text = "ğŸ” ì›¹ì—ì„œ ê´€ë ¨ ì •ë³´ ê²€ìƒ‰ ì¤‘..." if not self.debug_mode else "ğŸ” DEBUG: ì›¹ì—ì„œ ê´€ë ¨ ì •ë³´ ê²€ìƒ‰ ì¤‘..."
            with st.spinner(search_spinner_text):
                # ì¿¼ë¦¬ íƒ€ì…ë³„ ê²€ìƒ‰ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
                search_settings = self.config.get_search_quality_settings(query_type)
                
                # ì›¹ ê²€ìƒ‰ ì‹¤í–‰
                search_results = self.internet_search.search_google(
                    query, 
                    service_name=target_service_name, 
                    num_results=search_settings['max_results']
                )
                
                if search_results:
                    # ê²€ìƒ‰ ê²°ê³¼ í’ˆì§ˆ ê²€ì¦
                    reliability_assessment = self.internet_search.assess_search_reliability(search_results, query)
                    
                    # DEBUG ëª¨ë“œì—ì„œë§Œ ê²€ìƒ‰ ê²°ê³¼ ìƒì„¸ í‘œì‹œ
                    if self.debug_mode:
                        with st.expander(f"ğŸ” ì›¹ ê²€ìƒ‰ ê²°ê³¼ ({len(search_results)}ê°œ)", expanded=False):
                            st.info(f"ğŸ¯ ê²€ìƒ‰ í‚¤ì›Œë“œ: {self.internet_search.extract_search_keywords(query, target_service_name)}")
                            st.markdown("---")
                            
                            for i, result in enumerate(search_results, 1):
                                st.markdown(f"#### ğŸ”— ê²€ìƒ‰ ê²°ê³¼ {i}")
                                st.markdown(f"**ì œëª©**: {result['title']}")
                                st.markdown(f"**ì¶œì²˜**: {result['source']}")
                                st.markdown(f"**ë‚´ìš©**: {result['snippet']}")
                                st.markdown(f"**ë§í¬**: [ë°”ë¡œê°€ê¸°]({result['link']})")
                                if i < len(search_results):
                                    st.divider()
                    
                    # AI ë‹µë³€ ìƒì„± ë° í‘œì‹œ
                    answer_spinner_text = "ğŸ¤– ì›¹ ê²€ìƒ‰ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ AI ë‹µë³€ ìƒì„± ì¤‘..." if not self.debug_mode else "ğŸ¤– DEBUG: AI ë‹µë³€ ìƒì„± ì¤‘..."
                    with st.spinner(answer_spinner_text):
                        internet_response = self.internet_search.generate_internet_search_response(
                            self.azure_openai_client, query, target_service_name, 
                            search_results, self.model_name, query_type
                        )
                        
                        # ë‹µë³€ í‘œì‹œ
                        with st.expander("ğŸ¤– AI ë‹µë³€ë³´ê¸° (ì›¹ ê²€ìƒ‰ ê¸°ë°˜)", expanded=True):
                            st.write(internet_response)
                            search_purpose = self._get_search_purpose(query_type)
                            type_info = type_labels.get(query_type, 'ì¼ë°˜ ë¬¸ì˜')
                            
                            reliability_level = reliability_assessment['reliability_level']
                            if reliability_level == 'high':
                                st.success(f"ğŸŒ ì´ ë‹µë³€ì€ ì‹ ë¢°í•  ë§Œí•œ ì›¹ ì†ŒìŠ¤ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ **{type_info}** í˜•íƒœì˜ ì „ë¬¸ ë¶„ì„ì…ë‹ˆë‹¤.")
                            elif reliability_level == 'medium':
                                st.info(f"ğŸŒ ì´ ë‹µë³€ì€ ì›¹ ê²€ìƒ‰ ì •ë³´ë¥¼ ì¢…í•©í•œ **{type_info}** í˜•íƒœì˜ ë¶„ì„ì…ë‹ˆë‹¤.")
                            else:
                                st.warning(f"ğŸŒ ì´ ë‹µë³€ì€ ì œí•œì ì¸ ì›¹ ì •ë³´ë¥¼ ì¼ë°˜ì ì¸ IT ì§€ì‹ìœ¼ë¡œ ë³´ì™„í•œ **{type_info}** í˜•íƒœì˜ ë¶„ì„ì…ë‹ˆë‹¤.")
                        
                        # ì›¹ ë²„ì „ ì „ìš© ì„¸ì…˜ì— ë‹µë³€ ì €ì¥
                        search_purpose = self._get_search_purpose(query_type)
                        final_response = f"""
**[ğŸŒ ì›¹ ê²€ìƒ‰ ê¸°ë°˜ {search_purpose}]**

{internet_response}

â€» ì´ ë‹µë³€ì€ ì›¹ ê²€ìƒ‰ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìœ¼ë©°, ì‹¤ì œ í™˜ê²½ì— ì ìš© ì‹œ í•´ë‹¹ ì‹œìŠ¤í…œì˜ íŠ¹ì„±ì„ ê³ ë ¤í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.
"""
                        st.session_state[self.messages_key].append({"role": "assistant", "content": final_response})
                        
                else:
                    # ê²€ìƒ‰ ê²°ê³¼ ì—†ì„ ë•Œ
                    if self.debug_mode:
                        st.warning("ğŸŒ DEBUG: ê´€ë ¨ ì›¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        st.info("ğŸŒ ê´€ë ¨ ì›¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ì¼ë°˜ì ì¸ IT ì§€ì‹ìœ¼ë¡œ ë‹µë³€ë“œë¦½ë‹ˆë‹¤.")
                    
                    # ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒì—ë„ ì¼ë°˜ì ì¸ ë‹µë³€ ì œê³µ
                    with st.spinner("ğŸ¤– ì¼ë°˜ì ì¸ IT ì§€ì‹ìœ¼ë¡œ ë‹µë³€ ìƒì„± ì¤‘..."):
                        general_response = self._generate_fallback_response(query, query_type, type_labels)
                        
                        with st.expander("ğŸ¤– AI ë‹µë³€ë³´ê¸° (ì¼ë°˜ IT ì§€ì‹)", expanded=True):
                            st.write(general_response)
                            search_purpose = self._get_search_purpose(query_type)
                            type_info = type_labels.get(query_type, 'ì¼ë°˜ ë¬¸ì˜')
                            st.info(f"ğŸŒ ì´ ë‹µë³€ì€ ì¼ë°˜ì ì¸ IT ì „ë¬¸ê°€ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ í•œ **{type_info}** í˜•íƒœì˜ ë¶„ì„ì…ë‹ˆë‹¤.")
                            st.warning("âš ï¸ êµ¬ì²´ì ì¸ í™˜ê²½ ì •ë³´ì™€ í•¨ê»˜ ë¬¸ì˜í•˜ì‹œë©´ ë” ì •í™•í•œ ë‹µë³€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                    
                    # ì¼ë°˜ì ì¸ ë‹µë³€ë„ ì›¹ ë²„ì „ ì „ìš© ì„¸ì…˜ì— ì €ì¥
                    search_purpose = self._get_search_purpose(query_type)
                    no_results_response = f"""
**[ğŸŒ ì¼ë°˜ IT ì§€ì‹ ê¸°ë°˜ {search_purpose}]**

{general_response}

â€» ì›¹ ê²€ìƒ‰ ì •ë³´ ë¶€ì¡±ìœ¼ë¡œ ì¼ë°˜ì ì¸ IT ì „ë¬¸ê°€ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ì œê³µë˜ì—ˆìŠµë‹ˆë‹¤.
â€» êµ¬ì²´ì ì¸ í™˜ê²½ ì •ë³´ì™€ í•¨ê»˜ ë¬¸ì˜í•˜ì‹œë©´ ë” ì •í™•í•œ ë‹µë³€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
"""
                    st.session_state[self.messages_key].append({"role": "assistant", "content": no_results_response})
                    
        except Exception as e:
            if self.debug_mode:
                st.error(f"ğŸŒ DEBUG: ì›¹ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            else:
                st.error("ğŸŒ ì›¹ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”.")
            
            # ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ ì¼ë°˜ì ì¸ ë‹µë³€ ì‹œë„
            try:
                with st.spinner("ğŸ¤– ì¼ë°˜ì ì¸ IT ì§€ì‹ìœ¼ë¡œ ë‹µë³€ ìƒì„± ì¤‘..."):
                    error_response = self._generate_fallback_response(query, query_type, type_labels)
                    
                    with st.expander("ğŸ¤– AI ë‹µë³€ë³´ê¸° (ì¼ë°˜ IT ì§€ì‹)", expanded=True):
                        st.write(error_response)
                        st.warning("âš ï¸ ì›¹ ê²€ìƒ‰ ì˜¤ë¥˜ë¡œ ì¸í•´ ì¼ë°˜ì ì¸ IT ì§€ì‹ìœ¼ë¡œë§Œ ë‹µë³€ë“œë¦½ë‹ˆë‹¤.")
                
                # ì˜¤ë¥˜ ì‹œ ì¼ë°˜ ë‹µë³€ë„ ì›¹ ë²„ì „ ì „ìš© ì„¸ì…˜ì— ì €ì¥
                search_purpose = self._get_search_purpose(query_type)
                error_fallback_response = f"""
**[ğŸŒ ì¼ë°˜ IT ì§€ì‹ ê¸°ë°˜ {search_purpose}]**

{error_response}

â€» ì›¹ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì—¬ ì¼ë°˜ì ì¸ IT ì „ë¬¸ê°€ ì§€ì‹ìœ¼ë¡œ ë‹µë³€ë“œë ¸ìŠµë‹ˆë‹¤.
â€» êµ¬ì²´ì ì¸ í™˜ê²½ ì •ë³´ì™€ í•¨ê»˜ ì¬ë¬¸ì˜í•˜ì‹œë©´ ë” ì •í™•í•œ ë‹µë³€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
"""
                st.session_state[self.messages_key].append({"role": "assistant", "content": error_fallback_response})
                
            except Exception as inner_e:
                # ì¼ë°˜ ë‹µë³€ ìƒì„±ë„ ì‹¤íŒ¨í•œ ê²½ìš°
                final_error_response = f"""
**[ğŸŒ ì›¹ ê²€ìƒ‰ ì˜¤ë¥˜]**

âš ï¸ **ì •ë³´ê°€ ë¶€ì¡±í•˜ì—¬ ì¼ë°˜ì ì¸ ë‚´ìš©ìœ¼ë¡œ ë‹µë³€ë“œë¦½ë‹ˆë‹¤.**

ì›¹ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.

**ì¼ë°˜ì ì¸ IT ë¬¸ì œ í•´ê²° ì ‘ê·¼ë²•:**
1. **ë¬¸ì œ ìƒí™© ì •í™•íˆ íŒŒì•…**: ì˜¤ë¥˜ ë©”ì‹œì§€, ë¡œê·¸, ë°œìƒ ì‹œì  í™•ì¸
2. **ê¸°ë³¸ ì ê²€**: ë„¤íŠ¸ì›Œí¬ ì—°ê²°, ì„œë¹„ìŠ¤ ìƒíƒœ, ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ í™•ì¸  
3. **ë‹¨ê³„ì  ì§„ë‹¨**: ê°„ë‹¨í•œ í•´ê²°ì±…ë¶€í„° ë³µì¡í•œ ë°©ë²•ê¹Œì§€ ìˆœì°¨ ì ìš©
4. **ì „ë¬¸ê°€ ìƒë‹´**: ë³µì¡í•œ ë¬¸ì œëŠ” í•´ë‹¹ ë¶„ì•¼ ì „ë¬¸ê°€ì™€ í˜‘ì˜

â€» êµ¬ì²´ì ì¸ í™˜ê²½ ì •ë³´ì™€ í•¨ê»˜ ë‹¤ì‹œ ë¬¸ì˜í•˜ì‹œë©´ ë” ì •í™•í•œ ë‹µë³€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
"""
                st.session_state[self.messages_key].append({"role": "assistant", "content": final_error_response})

    def _generate_fallback_response(self, query, query_type, type_labels):
        """ì›¹ ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ì¼ë°˜ì ì¸ IT ì§€ì‹ ê¸°ë°˜ ë‹µë³€ ìƒì„±"""
        try:
            system_prompt = SystemPrompts.get_prompt(query_type)
            
            user_prompt = f"""
ì›¹ ê²€ìƒ‰ ì •ë³´ê°€ ì—†ì–´ ì¼ë°˜ì ì¸ IT ì „ë¬¸ê°€ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:

ì§ˆë¬¸: {query}

ë‹µë³€ ìš”êµ¬ì‚¬í•­:
1. ì¼ë°˜ì ì¸ IT ì›ì¹™ê³¼ ëª¨ë²” ì‚¬ë¡€ ì¤‘ì‹¬ìœ¼ë¡œ ë‹µë³€
2. ì£¼ìš” í¬ì¸íŠ¸ëŠ” **êµµì€ ê¸€ì”¨**ë¡œ ê°•ì¡°
3. ì‹¤ë¬´ì—ì„œ ì ìš© ê°€ëŠ¥í•œ ë‹¨ê³„ì  ì ‘ê·¼ë²• ì œì‹œ
4. ì¶”ê°€ í™•ì¸ì´ í•„ìš”í•œ ì‚¬í•­ë“¤ ëª…ì‹œ
5. ë‹µë³€ ë§ˆì§€ë§‰ì— "â€» ì´ ë‹µë³€ì€ ì¼ë°˜ì ì¸ IT ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤." ì¶”ê°€

ë‹µë³€:"""

            response = self.azure_openai_client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.3,
                max_tokens=2000
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            error_detail = str(e) if self.debug_mode else "ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤"
            return f"""âš ï¸ **ì¼ë°˜ì ì¸ IT ë¬¸ì œ í•´ê²° ì ‘ê·¼ë²•:**

ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error_detail}

**ê¸°ë³¸ì ì¸ ë¬¸ì œ í•´ê²° ë‹¨ê³„:**
1. **ë¬¸ì œ ìƒí™© íŒŒì•…**: ì •í™•í•œ ì˜¤ë¥˜ ë©”ì‹œì§€ì™€ ë°œìƒ ì¡°ê±´ í™•ì¸
2. **ê¸°ë³¸ ì ê²€**: ì‹œìŠ¤í…œ ìƒíƒœ, ë„¤íŠ¸ì›Œí¬ ì—°ê²°, ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
3. **ë¡œê·¸ ë¶„ì„**: ê´€ë ¨ ë¡œê·¸ íŒŒì¼ì—ì„œ ì˜¤ë¥˜ ì›ì¸ ì¶”ì 
4. **ë‹¨ê³„ì  í•´ê²°**: ê°„ë‹¨í•œ ë°©ë²•ë¶€í„° ë³µì¡í•œ í•´ê²°ì±…ê¹Œì§€ ìˆœì°¨ ì ìš©
5. **ë¬¸ì„œí™”**: í•´ê²° ê³¼ì •ê³¼ ê²°ê³¼ë¥¼ ê¸°ë¡í•˜ì—¬ í–¥í›„ ì°¸ì¡°

â€» êµ¬ì²´ì ì¸ í™˜ê²½ ì •ë³´ì™€ í•¨ê»˜ ë‹¤ì‹œ ë¬¸ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."""

    def _get_search_purpose(self, query_type):
        """ì¿¼ë¦¬ íƒ€ì…ì— ë”°ë¥¸ ê²€ìƒ‰ ëª©ì  ë°˜í™˜"""
        purposes = {
            'repair': 'í•´ê²°ë°©ë²•',
            'cause': 'ì›ì¸ë¶„ì„',
            'similar': 'ìœ ì‚¬ì‚¬ë¡€',
            'default': 'ê´€ë ¨ì •ë³´'
        }
        return purposes.get(query_type, purposes['default'])

    def process_query(self, query, query_type=None):
        """ì›¹ ê²€ìƒ‰ ê¸°ë°˜ ì¿¼ë¦¬ ì²˜ë¦¬ (IT ê´€ë ¨ ì§ˆë¬¸ë§Œ ì²˜ë¦¬, DEBUG ëª¨ë“œ ì§€ì›, ì„¸ì…˜ ë¶„ë¦¬)"""
        with st.chat_message("assistant"):
            # 1ë‹¨ê³„: IT ê´€ë ¨ ì§ˆë¬¸ì¸ì§€ ë¨¼ì € í™•ì¸
            validation_spinner_text = "ğŸ” ì§ˆë¬¸ ìœ í˜• ê²€ì¦ ì¤‘..." if not self.debug_mode else "ğŸ” DEBUG: IT ê´€ë ¨ì„± ê²€ì¦ ì¤‘..."
            with st.spinner(validation_spinner_text):
                if not self.is_it_related_query(query):
                    # IT ê´€ë ¨ì´ ì•„ë‹Œ ê²½ìš° ê±°ë¶€ ë©”ì‹œì§€ í‘œì‹œ í›„ ì²˜ë¦¬ ì¤‘ë‹¨
                    self.show_non_it_response(query)
                    return
            
            # IT ê´€ë ¨ ì§ˆë¬¸ìœ¼ë¡œ í™•ì¸ë¨ - ê¸°ì¡´ ì²˜ë¦¬ ë¡œì§ ê³„ì† ì§„í–‰
            if self.debug_mode:
                st.success("âœ… DEBUG: IT ê´€ë ¨ ì§ˆë¬¸ìœ¼ë¡œ í™•ì¸ë¨")

            # LLM ê¸°ë°˜ ì¿¼ë¦¬ íƒ€ì… ìë™ ë¶„ë¥˜
            if query_type is None:
                classify_spinner_text = "ğŸ¤– ì§ˆë¬¸ ìœ í˜• ë¶„ì„ ì¤‘..." if not self.debug_mode else "ğŸ¤– DEBUG: ì§ˆë¬¸ ìœ í˜• ë¶„ì„ ì¤‘..."
                with st.spinner(classify_spinner_text):
                    query_type = self.classify_query_type_with_llm(query)
                    
                    # ë¶„ë¥˜ ê²°ê³¼ í‘œì‹œ
                    type_labels = {
                        'repair': 'ğŸ”§ ë¬¸ì œ í•´ê²°ë°©ë²•',
                        'cause': 'ğŸ” ì›ì¸ ë¶„ì„',
                        'similar': 'ğŸ“„ ìœ ì‚¬ì‚¬ë¡€ ì°¸ì¡°', 
                        'default': 'ğŸ“‹ ì¼ë°˜ ë¬¸ì˜'
                    }
                    
                    # DEBUG ëª¨ë“œì—ì„œë§Œ ìƒì„¸ ë¶„ë¥˜ ì •ë³´ í‘œì‹œ
                    if self.debug_mode:
                        st.info(f"ğŸ“‹ DEBUG: ì§ˆë¬¸ ìœ í˜• ë¶„ì„ ê²°ê³¼ - **{type_labels.get(query_type, 'ğŸ“‹ ì¼ë°˜ ë¬¸ì˜')}**")
            else:
                type_labels = {
                    'repair': 'ğŸ”§ ë¬¸ì œ í•´ê²°ë°©ë²•',
                    'cause': 'ğŸ” ì›ì¸ ë¶„ì„',
                    'similar': 'ğŸ“„ ìœ ì‚¬ì‚¬ë¡€ ì°¸ì¡°', 
                    'default': 'ğŸ“‹ ì¼ë°˜ ë¬¸ì˜'
                }
            
            # ì„œë¹„ìŠ¤ëª… ì¶”ì¶œ
            target_service_name = self.extract_service_name_from_query(query)
            
            if target_service_name:
                if self.debug_mode:
                    st.success(f"ğŸ¯ DEBUG: ê°ì§€ëœ ëŒ€ìƒ ì„œë¹„ìŠ¤ - **{target_service_name}**")
            
            # SerpApi ì„¤ì • í™•ì¸
            if not self.internet_search.is_available():
                st.error("ğŸŒ SerpApi í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                st.info("ì›¹ ê²€ìƒ‰ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ .env íŒŒì¼ì— SERPAPI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
                
                # SerpApi ì—†ì´ë„ ì¼ë°˜ì ì¸ ë‹µë³€ ì œê³µ
                with st.spinner("ğŸ¤– ì¼ë°˜ì ì¸ IT ì§€ì‹ìœ¼ë¡œ ë‹µë³€ ìƒì„± ì¤‘..."):
                    fallback_response = self._generate_fallback_response(query, query_type, type_labels)
                    
                    with st.expander("ğŸ¤– AI ë‹µë³€ë³´ê¸° (ì¼ë°˜ IT ì§€ì‹)", expanded=True):
                        st.write(fallback_response)
                        search_purpose = self._get_search_purpose(query_type)
                        type_info = type_labels.get(query_type, 'ì¼ë°˜ ë¬¸ì˜')
                        st.warning(f"âš ï¸ ì›¹ ê²€ìƒ‰ ë¶ˆê°€ë¡œ ì¼ë°˜ì ì¸ IT ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ í•œ **{type_info}** í˜•íƒœì˜ ë‹µë³€ì…ë‹ˆë‹¤.")
                
                # ë‹µë³€ ì›¹ ë²„ì „ ì „ìš© ì„¸ì…˜ì— ì €ì¥
                search_purpose = self._get_search_purpose(query_type)
                no_serpapi_response = f"""
**[ğŸŒ ì¼ë°˜ IT ì§€ì‹ ê¸°ë°˜ {search_purpose}]**

{fallback_response}

â€» SerpApi ì„¤ì •ì´ ì—†ì–´ ì›¹ ê²€ìƒ‰ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
â€» ì›¹ ê²€ìƒ‰ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ SERPAPI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.
"""
                st.session_state[self.messages_key].append({"role": "assistant", "content": no_serpapi_response})
                return
            
            # ì›¹ ê²€ìƒ‰ ê¸°ë°˜ ì‘ë‹µ ìƒì„±
            self._generate_web_search_response(query, target_service_name, query_type, type_labels)